{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    #pre-processing to calculate outside good shares\n",
    "    shares = data[['Market_ID',name]].copy()\n",
    "\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data = comp_outside_good(data,'Inside Good Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first estimate using logit\n",
    "class logit(GMM):\n",
    "    \n",
    "    def __init__(self, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        super(logit, self).__init__(*args, **kwds)\n",
    "\n",
    "        \n",
    "    def momcond(self, params):\n",
    "        #unwrap stuff\n",
    "        shares = np.array(self.endog).transpose()\n",
    "        exog = np.array(self.exog)\n",
    "        instr = np.array(self.instrument)\n",
    "        \n",
    "        lshare = np.log(shares[0]) -  np.log(shares[1])\n",
    "        lshare = lshare.transpose()\n",
    "       \n",
    "        lshare_fit = np.matmul(exog,params) #linear equation    \n",
    "        \n",
    "        xi = lshare_fit - lshare\n",
    "        g = instr * xi[:, np.newaxis]\n",
    "        \n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use dummy variables for the plan as my instrument. When regressing these dummy variables on plan, as a result my model has the form \n",
    "\n",
    "$$p_{jm} = p_j + \\epsilon_{jm}$$ \n",
    "\n",
    "as is standard where $\\epsilon_{jm}$ is a market specific shock. I estimated a model with the other exogeneous characteristics (i.e. Network score, Satisfaction, PPO) in the instrument. However, the model coefficients where similar, so for simplicitiy I use the dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate hausmann insturments\n",
    "mkt_dum = pd.get_dummies(data['Market_ID'],prefix='mkt',drop_first=True)\n",
    "plan_dum = pd.get_dummies(data['Plan_ID'],prefix='plan',drop_first=True)\n",
    "hausman_instr = plan_dum\n",
    "\n",
    "#set up x and y\n",
    "y = data[['Inside Good Share','Outside Good Share']]\n",
    "x =  data[['Network Score','Satisfaction Score','PPO','Premium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000008\n",
      "         Iterations: 292\n",
      "         Function evaluations: 497\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005149\n",
      "         Iterations: 139\n",
      "         Function evaluations: 249\n",
      "                                             logit Results                                             \n",
      "=======================================================================================================\n",
      "Dep. Variable:     ['Inside Good Share', 'Outside Good Share']   Hansen J:                        16.99\n",
      "Model:                                                   logit   Prob (Hansen J):                 0.108\n",
      "Method:                                                    GMM                                         \n",
      "Date:                                         Sat, 13 Oct 2018                                         \n",
      "Time:                                                 16:34:52                                         \n",
      "No. Observations:                                         3300                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Network Score          3.5117      0.124     28.301      0.000       3.268       3.755\n",
      "Satisfaction Score     2.0384      0.072     28.355      0.000       1.897       2.179\n",
      "PPO                    0.8185      0.011     76.023      0.000       0.797       0.840\n",
      "Premium               -2.0615      0.040    -52.076      0.000      -2.139      -1.984\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "#set up initial est\n",
    "beta_init = np.full(len(x.columns),1)\n",
    "\n",
    "#set up model\n",
    "model = logit(y , x, hausman_instr)\n",
    "\n",
    "result = model.fit(beta_init, maxiter=2, optim_method='nm', wargs=dict(centered=False))\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Elasticities and Markups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticities\n",
    "\n",
    "Below are the formulas for elasticity\n",
    "\n",
    "Own price : $$-\\alpha (1-s_{jm}) p_{jm}$$\n",
    "Cross price (good $j$, price $k$): $$-\\alpha s_{km} p_{km}$$\n",
    "\n",
    "The logit has a very inflexible substitution pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_shares(x,p,alpha,beta,labels=False):\n",
    "    #compute exp(delta_j)\n",
    "    x = x.copy()\n",
    "    x['exp_delta'] =  np.exp ( np.matmul(x[['Network Score','Satisfaction Score','PPO']],beta) - alpha*p )\n",
    "    #print x['exp_delta']\n",
    "    \n",
    "    #compute 1 + sum_j exp(delta_j)\n",
    "    sum_delta = x.groupby('Market_ID').sum()\n",
    "    sum_delta['sum_exp_delta'] = 1 + sum_delta['exp_delta'] \n",
    "    \n",
    "    x = pd.merge(x, sum_delta[['sum_exp_delta']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "\n",
    "    #compute s_j\n",
    "    x['fitted_share'] = x['exp_delta']/x['sum_exp_delta']\n",
    "    \n",
    "    if labels: \n",
    "        return x[['Plan_ID','Market_ID','fitted_share']]\n",
    "    \n",
    "    return np.array(x['fitted_share']).squeeze()\n",
    "        \n",
    "\n",
    "#set up parameters \n",
    "observ = data[['Plan_ID','Market_ID','Network Score','Satisfaction Score','PPO']]\n",
    "prices = np.array( data['Premium'] ) #needed for later...\n",
    "\n",
    "beta = result.params[:-1]\n",
    "alpha = abs(result.params[3])\n",
    "\n",
    "shares = comp_shares(observ,prices,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_elasticity(shares, prices, alpha):\n",
    "    #set up matrix skeleton\n",
    "    own_price = np.identity(len(shares))\n",
    "    cross_price = 1 - own_price\n",
    "\n",
    "    #actually calculate elasticity\n",
    "    cross_elasticity = shares * alpha * prices\n",
    "    own_elasticity  = -(1-shares) * alpha * prices\n",
    "\n",
    "    return cross_price*cross_elasticity + own_price *own_elasticity\n",
    "\n",
    "\n",
    "#agregate elasticities\n",
    "elasticity = comp_elasticity(shares, prices, alpha)\n",
    "\n",
    "#average elasticity\n",
    "avg_shares =  np.array( comp_shares(observ,prices,alpha,beta,\n",
    "                                    labels=True).groupby('Plan_ID').mean()['fitted_share']).squeeze()\n",
    "avg_price = np.array( data[['Plan_ID','Premium']].groupby('Plan_ID').mean() ).squeeze()\n",
    "avg_elasticity = comp_elasticity(avg_shares, avg_price, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the model's implied elasticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -4.326559  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "1   1.015659 -4.308597  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "2   1.015659  0.555455 -4.287062  0.826840  0.571207  0.714491  1.002820   \n",
      "3   1.015659  0.555455  1.089161 -4.377314  0.571207  0.714491  1.002820   \n",
      "4   1.015659  0.555455  1.089161  0.826840 -4.252885  0.714491  1.002820   \n",
      "5   1.015659  0.555455  1.089161  0.826840  0.571207 -4.141574  1.002820   \n",
      "6   1.015659  0.555455  1.089161  0.826840  0.571207  0.714491 -4.347902   \n",
      "7   1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "8   1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "9   1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "10  1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "11  1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "12  1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "13  1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "14  1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "15  1.015659  0.555455  1.089161  0.826840  0.571207  0.714491  1.002820   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "1   0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "2   0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "3   0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "4   0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "5   0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "6   0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "7  -4.224041  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "8   0.744205 -4.381367  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "9   0.744205  0.837122 -4.359683  0.599199  1.002649  0.766805  0.670567   \n",
      "10  0.744205  0.837122  0.459171 -4.192579  1.002649  0.766805  0.670567   \n",
      "11  0.744205  0.837122  0.459171  0.599199 -4.358498  0.766805  0.670567   \n",
      "12  0.744205  0.837122  0.459171  0.599199  1.002649 -4.431036  0.670567   \n",
      "13  0.744205  0.837122  0.459171  0.599199  1.002649  0.766805 -4.299402   \n",
      "14  0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "15  0.744205  0.837122  0.459171  0.599199  1.002649  0.766805  0.670567   \n",
      "\n",
      "          14        15  \n",
      "0   1.077874  0.676515  \n",
      "1   1.077874  0.676515  \n",
      "2   1.077874  0.676515  \n",
      "3   1.077874  0.676515  \n",
      "4   1.077874  0.676515  \n",
      "5   1.077874  0.676515  \n",
      "6   1.077874  0.676515  \n",
      "7   1.077874  0.676515  \n",
      "8   1.077874  0.676515  \n",
      "9   1.077874  0.676515  \n",
      "10  1.077874  0.676515  \n",
      "11  1.077874  0.676515  \n",
      "12  1.077874  0.676515  \n",
      "13  1.077874  0.676515  \n",
      "14 -4.274734  0.676515  \n",
      "15  1.077874 -4.200969  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(avg_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note indexing starts at 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markups\n",
    "\n",
    "The following formula relates marginal costs with prices:\n",
    "\n",
    "$$\\hat{mc}_i = pi - (\\dfrac{ \\partial s_i} { \\partial p_i})^{-1} s_i$$\n",
    "\n",
    "We can use it to calculate the markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Markup\n",
      "Plan_ID          \n",
      "1        0.600929\n",
      "2        0.548763\n",
      "3        0.610518\n",
      "4        0.578164\n",
      "5        0.551221\n",
      "6        0.570263\n",
      "7        0.599144\n",
      "8        0.572002\n",
      "9        0.579314\n",
      "10       0.536959\n",
      "11       0.555631\n",
      "12       0.598772\n",
      "13       0.570590\n",
      "14       0.562080\n",
      "15       0.609716\n",
      "16       0.564715\n"
     ]
    }
   ],
   "source": [
    "#solve for marginal costs\n",
    "def comp_markup(shares):\n",
    "    shares_vector = np.array([shares])\n",
    "    \n",
    "    #set up matrix    \n",
    "    own_price = np.identity(len(shares))\n",
    "\n",
    "    #caclulate formula\n",
    "    own_deriv  = - alpha * (1-shares)  * shares\n",
    "    \n",
    "    derivative = own_price *own_deriv\n",
    "    #take inverse and calc markup\n",
    "    inv_derivative = np.linalg.inv(derivative)\n",
    "\n",
    "    markup = - np.matmul(inv_derivative, shares_vector.transpose()) \n",
    "    return markup.transpose()[0]\n",
    "\n",
    "\n",
    "markup = comp_markup(shares)\n",
    "mc = prices - markup\n",
    "\n",
    "data['Markup'] = markup\n",
    "print data[['Plan_ID','Markup']].groupby('Plan_ID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the markups are lower than with the nested logit. It is possible this is related to the more strict substititon patterns imposed without the nest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Marginal Costs vs Plan Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 6.770e+05\n",
      "Date:                Sat, 13 Oct 2018   Prob (F-statistic):               0.00\n",
      "Time:                        16:35:02   Log-Likelihood:                 3812.1\n",
      "No. Observations:                3300   AIC:                            -7618.\n",
      "Df Residuals:                    3297   BIC:                            -7600.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Network Score          1.9018      0.032     58.896      0.000       1.838       1.965\n",
      "Satisfaction Score     0.1661      0.034      4.946      0.000       0.100       0.232\n",
      "PPO                    0.1840      0.003     68.729      0.000       0.179       0.189\n",
      "==============================================================================\n",
      "Omnibus:                      899.404   Durbin-Watson:                   1.904\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3696.578\n",
      "Skew:                           1.279   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.511   Cond. No.                         46.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_q3 = sm.OLS(data['Premium'] - data['Markup'], data[['Network Score','Satisfaction Score','PPO']])\n",
    "result_q3 = model_q3.fit()\n",
    "print result_q3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4  - Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mc = mc +.25\n",
    "new_prices = np.genfromtxt('prices.csv', delimiter=',') \n",
    "\n",
    "def comp_foc(p, costs = new_mc, x = observ, a = alpha, b = beta):\n",
    "    shares = comp_shares(x,p,a,b)\n",
    "    new_markup = comp_markup(shares)\n",
    "    print new_markup - (p - costs)\n",
    "    return new_markup - (p - costs)\n",
    "\n",
    "new_prices = fsolve(comp_foc, new_prices,epsfcn = 1e-3,xtol=1e-3)\n",
    "np.savetxt(\"prices2.csv\", new_prices, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through to solve profits\n",
    "new_prices = np.empty(len(prices))\n",
    "\n",
    "for i in range(len(prices)): \n",
    "    \n",
    "    def profits(p, all_prices=prices.copy(), x=observ, mc = mc, beta=beta, rebate=.25,):\n",
    "        all_prices[i] = p\n",
    "        shares = comp_shares(x, all_prices, alpha, beta)\n",
    "        return - shares[i]*(p - mc[i] + rebate)      \n",
    "    \n",
    "    res = minimize(profits, prices[i], method='BFGS', options={'disp': False})\n",
    "    new_prices[i]=res.x\n",
    "\n",
    "new_prices = np.array(new_prices).squeeze()\n",
    "np.savetxt(\"prices.csv\", new_prices, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prices = np.genfromtxt('prices.csv', delimiter=',') #avoid caclulating everytime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Unisurance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside Good (Before Rebate): 0.134505918182\n",
      "Outside Good (After Rebate): 0.0978925678369\n"
     ]
    }
   ],
   "source": [
    "#outside good shares\n",
    "new_data = data[['Market_ID']].copy()\n",
    "new_data['New Inside Good'] =  comp_shares(observ, new_prices, alpha, beta)\n",
    "new_data = comp_outside_good(new_data,'New Inside Good')\n",
    "\n",
    "#compare the mean outside good before and after the rebate. It decreases.\n",
    "print 'Outside Good (Before Rebate): %s'%data['Outside Good Share'].mean()\n",
    "print 'Outside Good (After Rebate): %s'%new_data['Outside Good Share'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Change in Profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry Profits (Before Rebate): 297.54396984209365\n",
      "Industry Profits (After Rebate): 313.4992352234833\n",
      "\n",
      "\n",
      "Per Enrollee (Before Rebate): 0.5752567331174229\n",
      "Per Enrollee (After Rebate): 0.6208741043229968\n"
     ]
    }
   ],
   "source": [
    "def industry_profits(x, p, alpha, beta, mc):\n",
    "    \"\"\"computes agregate profits\"\"\"\n",
    "    shares = comp_shares(x, p, alpha, beta)\n",
    "    return np.matmul(shares, np.array([prices - mc]).transpose())\n",
    "\n",
    "#industry wide profits\n",
    "print 'Industry Profits (Before Rebate): %s'%industry_profits(observ, prices, alpha, beta , mc)[0]\n",
    "print 'Industry Profits (After Rebate): %s'%industry_profits(observ, new_prices, alpha, beta , mc)[0]\n",
    "print '\\n'\n",
    "\n",
    "#profits per enrollee, comparision\n",
    "print 'Per Enrollee (Before Rebate): %s'%(prices - mc).mean()\n",
    "print 'Per Enrollee (After Rebate): %s'%(new_prices + .25 - mc).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Change in Consumer Surplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Train Ch. 3 \n",
    "\n",
    "$$\\Delta E(CS) = \\dfrac{1}{\\alpha} [ln(\\sum_{j} e^{\\delta'_jm} ) - ln(\\sum_{j} e^{\\delta_jm} )  ]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20320784022358307\n"
     ]
    }
   ],
   "source": [
    "def comp_surplus(x,p1,p2,alpha,beta,labels=False):\n",
    "    #compute exp(delta_j)\n",
    "    x = x.copy()\n",
    "    x['exp_delta1'] =  np.exp ( np.matmul(x[['Network Score','Satisfaction Score','PPO']],beta) - alpha*p1 )\n",
    "    x['exp_delta2'] =  np.exp ( np.matmul(x[['Network Score','Satisfaction Score','PPO']],beta) - alpha*p2 )\n",
    "    \n",
    "    #1/alpha *  ( sum(np.exp(delta1_j)) - sum(np.exp(delta0_j)) )\n",
    "    utility_ratio = x['exp_delta2'].sum()/x['exp_delta1'].sum()\n",
    "    return 1/alpha * np.log( utility_ratio )\n",
    "\n",
    "\n",
    "print comp_surplus(x,prices,new_prices,alpha,beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
