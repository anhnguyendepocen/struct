{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    #pre-processing to calculate outside good shares\n",
    "    shares = data[['Market_ID',name]].copy()\n",
    "\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data = comp_outside_good(data,'Inside Good Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first estimate using logit\n",
    "class logit(GMM):\n",
    "    \n",
    "    def __init__(self, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        super(logit, self).__init__(*args, **kwds)\n",
    "\n",
    "        \n",
    "    def momcond(self, params):\n",
    "        #unwrap stuff\n",
    "        shares = np.array(self.endog).transpose()\n",
    "        exog = np.array(self.exog)\n",
    "        instr = np.array(self.instrument)\n",
    "        \n",
    "        lshare = np.log(shares[0]) -  np.log(shares[1])\n",
    "        lshare = lshare.transpose()\n",
    "       \n",
    "        lshare_fit = np.matmul(exog,params) #linear equation    \n",
    "        \n",
    "        xi = lshare_fit - lshare\n",
    "        g = instr * xi[:, np.newaxis]\n",
    "        \n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use dummy variables for the plan as my instrument. When regressing these dummy variables on plan, my model has the form \n",
    "\n",
    "$$p_{jm} = p_j + \\epsilon_{jm}$$ \n",
    "\n",
    "as is standard where $\\epsilon_{jm}$ is a market specific shock for product $j$. The idea is that the average price of plan $j$ varies exogenously to each market. I estimated a model with the other exogeneous characteristics (i.e. Network score, Satisfaction, PPO) in the instrument. However, the model coefficients where similar, so for simplicitiy I just use the dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate hausmann insturments\n",
    "mkt_dum = pd.get_dummies(data['Market_ID'],prefix='mkt',drop_first=True)\n",
    "plan_dum = pd.get_dummies(data['Plan_ID'],prefix='plan',drop_first=True)\n",
    "hausman_instr = plan_dum\n",
    "\n",
    "#set up x and y\n",
    "y = data[['Inside Good Share','Outside Good Share']]\n",
    "x =  data[['Network Score','Satisfaction Score','PPO','Premium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000008\n",
      "         Iterations: 292\n",
      "         Function evaluations: 497\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005149\n",
      "         Iterations: 139\n",
      "         Function evaluations: 249\n",
      "                                             logit Results                                             \n",
      "=======================================================================================================\n",
      "Dep. Variable:     ['Inside Good Share', 'Outside Good Share']   Hansen J:                        16.99\n",
      "Model:                                                   logit   Prob (Hansen J):                 0.108\n",
      "Method:                                                    GMM                                         \n",
      "Date:                                         Sun, 14 Oct 2018                                         \n",
      "Time:                                                 12:48:34                                         \n",
      "No. Observations:                                         3300                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Network Score          3.5117      0.124     28.301      0.000       3.268       3.755\n",
      "Satisfaction Score     2.0384      0.072     28.355      0.000       1.897       2.179\n",
      "PPO                    0.8185      0.011     76.023      0.000       0.797       0.840\n",
      "Premium               -2.0615      0.040    -52.076      0.000      -2.139      -1.984\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "#set up initial est\n",
    "beta_init = np.full(len(x.columns),1)\n",
    "\n",
    "#set up model\n",
    "model = logit(y , x, hausman_instr)\n",
    "\n",
    "result = model.fit(beta_init, maxiter=2, optim_method='nm', \n",
    "                   wargs=dict(centered=False))\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Xi'] = (np.log(y['Inside Good Share']) - np.log(y['Outside Good Share']) \n",
    "              - np.matmul(np.array(x),result.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Elasticities and Markups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticities\n",
    "\n",
    "Below are the formulas for elasticity\n",
    "\n",
    "Own price : $$-\\alpha (1-s_{jm}) p_{jm}$$\n",
    "Cross price (good $j$, price $k$): $$-\\alpha s_{km} p_{km}$$\n",
    "\n",
    "The logit has a very inflexible substitution pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.77555756e-17  5.55111512e-17  5.55111512e-17 ... -1.38777878e-17\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "def comp_shares(x,p,alpha,beta,labels=False):\n",
    "    #compute exp(delta_j)\n",
    "    x = x.copy()\n",
    "    x['exp_delta'] =  np.exp ( np.matmul(x[['Network Score',\n",
    "                                            'Satisfaction Score','PPO']],\n",
    "                                         beta) - alpha*p + x['Xi'])\n",
    "    #print x['exp_delta']\n",
    "    \n",
    "    #compute 1 + sum_j exp(delta_j)\n",
    "    sum_delta = x.groupby('Market_ID').sum()\n",
    "    sum_delta['sum_exp_delta'] = 1 + sum_delta['exp_delta'] \n",
    "    \n",
    "    x = pd.merge(x, sum_delta[['sum_exp_delta']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "\n",
    "    #compute s_j\n",
    "    x['fitted_share'] = x['exp_delta']/x['sum_exp_delta']\n",
    "    \n",
    "    if labels: \n",
    "        return x[['Plan_ID','Market_ID','fitted_share']]\n",
    "    \n",
    "    return np.array(x['fitted_share']).squeeze()\n",
    "        \n",
    "\n",
    "#set up parameters \n",
    "observ = data[['Plan_ID','Market_ID','Network Score','Satisfaction Score','PPO','Xi']]\n",
    "prices = np.array( data['Premium'] )\n",
    "\n",
    "beta = result.params[:-1]\n",
    "alpha = abs(result.params[3])\n",
    "\n",
    "shares = comp_shares(observ,prices,alpha,beta)\n",
    "\n",
    "print shares - np.array(data['Inside Good Share']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_elasticity(shares, prices, alpha):\n",
    "    #set up matrix skeleton\n",
    "    own_price = np.identity(len(shares))\n",
    "    cross_price = 1 - own_price\n",
    "\n",
    "    #actually calculate elasticity\n",
    "    cross_elasticity = shares * alpha * prices\n",
    "    own_elasticity  = -(1-shares) * alpha * prices\n",
    "\n",
    "    return cross_price*cross_elasticity + own_price *own_elasticity\n",
    "\n",
    "\n",
    "#agregate elasticities\n",
    "elasticity = comp_elasticity(shares, prices, alpha)\n",
    "\n",
    "#average elasticity\n",
    "avg_shares =  np.array( comp_shares(observ,prices,alpha,beta,\n",
    "                                    labels=True).groupby(\n",
    "    'Plan_ID').mean()['fitted_share']).squeeze()\n",
    "avg_price = np.array( data[['Plan_ID','Premium']].groupby(\n",
    "    'Plan_ID').mean() ).squeeze()\n",
    "avg_elasticity = comp_elasticity(avg_shares, avg_price, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the model's implied elasticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -4.300662  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "1   1.041556 -4.319348  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "2   1.041556  0.544704 -4.253176  0.838574  0.566958  0.732122  1.030922   \n",
      "3   1.041556  0.544704  1.123047 -4.365580  0.566958  0.732122  1.030922   \n",
      "4   1.041556  0.544704  1.123047  0.838574 -4.257134  0.732122  1.030922   \n",
      "5   1.041556  0.544704  1.123047  0.838574  0.566958 -4.123943  1.030922   \n",
      "6   1.041556  0.544704  1.123047  0.838574  0.566958  0.732122 -4.319801   \n",
      "7   1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "8   1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "9   1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "10  1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "11  1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "12  1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "13  1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "14  1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "15  1.041556  0.544704  1.123047  0.838574  0.566958  0.732122  1.030922   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "1   0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "2   0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "3   0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "4   0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "5   0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "6   0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "7  -4.206426  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "8   0.761820 -4.370936  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "9   0.761820  0.847553 -4.373922  0.595128  1.018355  0.768825  0.681183   \n",
      "10  0.761820  0.847553  0.444932 -4.196650  1.018355  0.768825  0.681183   \n",
      "11  0.761820  0.847553  0.444932  0.595128 -4.342792  0.768825  0.681183   \n",
      "12  0.761820  0.847553  0.444932  0.595128  1.018355 -4.429016  0.681183   \n",
      "13  0.761820  0.847553  0.444932  0.595128  1.018355  0.768825 -4.288786   \n",
      "14  0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "15  0.761820  0.847553  0.444932  0.595128  1.018355  0.768825  0.681183   \n",
      "\n",
      "          14        15  \n",
      "0   1.117074  0.682031  \n",
      "1   1.117074  0.682031  \n",
      "2   1.117074  0.682031  \n",
      "3   1.117074  0.682031  \n",
      "4   1.117074  0.682031  \n",
      "5   1.117074  0.682031  \n",
      "6   1.117074  0.682031  \n",
      "7   1.117074  0.682031  \n",
      "8   1.117074  0.682031  \n",
      "9   1.117074  0.682031  \n",
      "10  1.117074  0.682031  \n",
      "11  1.117074  0.682031  \n",
      "12  1.117074  0.682031  \n",
      "13  1.117074  0.682031  \n",
      "14 -4.235533  0.682031  \n",
      "15  1.117074 -4.195453  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(avg_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note indexing starts at 0. We can see the elasticities are higher in the Logit than in the nested logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markups\n",
    "\n",
    "The following formula relates marginal costs with prices:\n",
    "\n",
    "$$\\hat{mc}_i = pi - (\\dfrac{ \\partial s_i} { \\partial p_i})^{-1} s_i$$\n",
    "\n",
    "We can use it to calculate the markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Markup\n",
      "Plan_ID          \n",
      "1        0.605243\n",
      "2        0.547706\n",
      "3        0.616228\n",
      "4        0.580313\n",
      "5        0.550945\n",
      "6        0.573316\n",
      "7        0.604003\n",
      "8        0.574877\n",
      "9        0.581282\n",
      "10       0.535394\n",
      "11       0.555452\n",
      "12       0.601756\n",
      "13       0.571446\n",
      "14       0.563932\n",
      "15       0.616249\n",
      "16       0.566054\n"
     ]
    }
   ],
   "source": [
    "#solve for marginal costs\n",
    "def comp_markup(shares):\n",
    "    shares_vector = np.array([shares])\n",
    "    \n",
    "    #set up matrix    \n",
    "    own_price = np.identity(len(shares))\n",
    "\n",
    "    #caclulate formula\n",
    "    own_deriv  = - alpha * (1-shares)  * shares\n",
    "    \n",
    "    derivative = own_price *own_deriv\n",
    "    #take inverse and calc markup\n",
    "    inv_derivative = np.linalg.inv(derivative)\n",
    "\n",
    "    markup = - np.matmul(inv_derivative, shares_vector.transpose()) \n",
    "    return markup.transpose()[0]\n",
    "\n",
    "\n",
    "markup = comp_markup(shares)\n",
    "mc = prices - markup\n",
    "\n",
    "data['Markup'] = markup\n",
    "print data[['Plan_ID','Markup']].groupby('Plan_ID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the markups are lower than with the nested logit. This follows because without the nest, there is more competition between firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Markup   R-squared:                       0.908\n",
      "Model:                            OLS   Adj. R-squared:                  0.908\n",
      "Method:                 Least Squares   F-statistic:                     5907.\n",
      "Date:                Sun, 14 Oct 2018   Prob (F-statistic):          3.98e-312\n",
      "Time:                        12:48:45   Log-Likelihood:                 1807.3\n",
      "No. Observations:                 600   AIC:                            -3611.\n",
      "Df Residuals:                     598   BIC:                            -3602.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Plan_ID       -0.0219      0.000    -76.859      0.000      -0.022      -0.021\n",
      "Constant       0.7095      0.002    432.341      0.000       0.706       0.713\n",
      "==============================================================================\n",
      "Omnibus:                      351.572   Durbin-Watson:                   0.078\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               58.911\n",
      "Skew:                           0.495   Prob(JB):                     1.61e-13\n",
      "Kurtosis:                       1.827   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mean_markup = data[['Market_ID','Markup']].groupby('Market_ID').mean()\n",
    "no_firms = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "\n",
    "model_q2 = sm.OLS(mean_markup,sm.add_constant(no_firms))\n",
    "result_q2 = model_q2.fit()\n",
    "print result_q2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the Markup is decreasing in the number of firms in the market, like with the nested logit (see `nest_logit` output for more details...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Marginal Costs vs Plan Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.779\n",
      "Model:                            OLS   Adj. R-squared:                  0.779\n",
      "Method:                 Least Squares   F-statistic:                     3875.\n",
      "Date:                Sun, 14 Oct 2018   Prob (F-statistic):               0.00\n",
      "Time:                        12:48:47   Log-Likelihood:                 5512.2\n",
      "No. Observations:                3300   AIC:                        -1.102e+04\n",
      "Df Residuals:                    3296   BIC:                        -1.099e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  1.4255      0.018     78.465      0.000       1.390       1.461\n",
      "Network Score          0.3540      0.028     12.803      0.000       0.300       0.408\n",
      "Satisfaction Score     0.0844      0.020      4.203      0.000       0.045       0.124\n",
      "PPO                    0.1688      0.002    105.022      0.000       0.166       0.172\n",
      "==============================================================================\n",
      "Omnibus:                     2699.109   Durbin-Watson:                   1.942\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           101285.096\n",
      "Skew:                           3.642   Prob(JB):                         0.00\n",
      "Kurtosis:                      29.145   Cond. No.                         69.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_q3 = sm.OLS(data['Premium'] - data['Markup'], \n",
    "                   sm.add_constant(data[['Network Score','Satisfaction Score','PPO']]))\n",
    "result_q3 = model_q3.fit()\n",
    "print result_q3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4  - Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up function to calc FOC for Nash Bargainining\n",
    "def comp_foc(p, costs, x, alpha, beta):\n",
    "    shares = comp_shares(x,p,alpha, beta)\n",
    "    new_markup = comp_markup(shares)\n",
    "    return new_markup - (p - costs)\n",
    "\n",
    "\n",
    "max_mkt = data.groupby('Market_ID').count().shape[0]\n",
    "new_prices = [[]] * max_mkt\n",
    "\n",
    "#numerically solve on a market by market basis\n",
    "for i in range(1,max_mkt+1):\n",
    "    \n",
    "    #set up mkt level variables\n",
    "    mkt_data = data[data['Market_ID'] == i]\n",
    "    mkt_prices = np.array(mkt_data['Premium']).squeeze()\n",
    "    mkt_markup = np.array(mkt_data['Markup']).squeeze()\n",
    "    mkt_mc = mkt_prices - mkt_markup - .25 #the rebate reduces MC\n",
    "    mkt_x = mkt_data[['Plan_ID','Market_ID','Network Score','Satisfaction Score','PPO','Xi']]\n",
    "   \n",
    "    #calculate FOCs\n",
    "    mkt_new_prices = fsolve(comp_foc, mkt_prices, args= (mkt_mc, mkt_x, alpha, beta) )\n",
    "    new_prices[i-1] = mkt_new_prices\n",
    "    \n",
    "#flatten result to 1d array\n",
    "new_prices = np.array([ p for  mkt_new_prices in new_prices for p in  mkt_new_prices ])\n",
    "\n",
    "#write to file\n",
    "np.savetxt(\"prices2.csv\", new_prices, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid caclulating everytime\n",
    "new_prices = np.genfromtxt('prices2.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Unisurance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside Good (Before Rebate): 0.134505918182\n",
      "Outside Good (After Rebate): 0.0866271205604\n"
     ]
    }
   ],
   "source": [
    "#outside good shares\n",
    "new_data = data[['Market_ID']].copy()\n",
    "new_data['New Inside Good'] =  comp_shares(observ, new_prices, alpha, beta)\n",
    "new_data = comp_outside_good(new_data,'New Inside Good')\n",
    "\n",
    "#compare the mean outside good before and after the rebate. It decreases.\n",
    "print 'Outside Good (Before Rebate): %s'%data['Outside Good Share'].mean()\n",
    "print 'Outside Good (After Rebate): %s'%new_data['Outside Good Share'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Change in Profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry Profits (Before Rebate): 304.7568008664531\n",
      "Industry Profits (After Rebate): 323.06702291696183\n",
      "Per Enrollee (Before Rebate): 0.5774424394884409\n",
      "Per Enrollee (After Rebate): 0.5844861247221862\n"
     ]
    }
   ],
   "source": [
    "def industry_profits(x, p, alpha, beta, mc):\n",
    "    \"\"\"computes agregate profits\"\"\"\n",
    "    shares = comp_shares(x, p, alpha, beta)\n",
    "    return np.matmul(shares, np.array([prices - mc]).transpose())\n",
    "\n",
    "#industry wide profits\n",
    "print 'Industry Profits (Before Rebate): %s'%industry_profits(observ,\n",
    "                                                              prices, \n",
    "                                                              alpha, beta , mc)[0]\n",
    "print 'Industry Profits (After Rebate): %s'%industry_profits(observ,\n",
    "                                                             new_prices,\n",
    "                                                             alpha, beta , mc)[0]\n",
    "\n",
    "#profits per enrollee, comparision\n",
    "print 'Per Enrollee (Before Rebate): %s'%(prices - mc).mean()\n",
    "print 'Per Enrollee (After Rebate): %s'%(new_prices + .25 - mc).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Change in Consumer Surplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Train Ch. 3 \n",
    "\n",
    "$$\\Delta E(CS) = \\dfrac{1}{\\alpha} [ln(\\sum_{j} e^{\\delta'_{jm}} ) - ln(\\sum_{j} e^{\\delta_{jm}} )  ]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24304126881360041\n"
     ]
    }
   ],
   "source": [
    "def comp_surplus(x,p1,p2,alpha,beta,labels=False):\n",
    "    #compute exp(delta_j)\n",
    "    x = x.copy()\n",
    "    x['exp_delta1'] =  np.exp ( np.matmul(x[['Network Score',\n",
    "                                             'Satisfaction Score','PPO']],\n",
    "                                          beta) - alpha*p1)\n",
    "    x['exp_delta2'] =  np.exp ( np.matmul(x[['Network Score',\n",
    "                                             'Satisfaction Score','PPO']],\n",
    "                                          beta) - alpha*p2) \n",
    "    #note the xi's cancel out in the formula\n",
    "    \n",
    "    #1/alpha *  ( sum(np.exp(delta1_j)) - sum(np.exp(delta0_j)) )\n",
    "    utility_ratio = x['exp_delta2'].sum()/x['exp_delta1'].sum()\n",
    "    return 1/alpha * np.log( utility_ratio )\n",
    "\n",
    "\n",
    "print comp_surplus(x,prices,new_prices,alpha,beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
