{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    \"\"\"pre-processing to calculate outside good shares\"\"\"\n",
    "    shares = data[['Market_ID',name,'PPO']].copy()\n",
    "\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "\n",
    "def comp_nest_shares(x,name):\n",
    "    \"\"\"calculate shares within nest\"\"\"\n",
    "    nest_x = x[['Market_ID',name,'PPO']].copy()\n",
    "    nest_x['ppo_share'] = nest_x[name] * nest_x['PPO']\n",
    "    nest_x['hmo_share'] = nest_x[name] * (1 - nest_x['PPO'])\n",
    "    \n",
    "    group_shares = nest_x.groupby('Market_ID').sum()\n",
    "    \n",
    "    x = pd.merge(x, group_shares[['hmo_share','ppo_share']], right_index=True, left_on = 'Market_ID')\n",
    "    \n",
    "    x['nest_size'] =   x['PPO'] * x['ppo_share'] + (1 - x['PPO']) * x['hmo_share']\n",
    "    x = x.drop(labels=['ppo_share','hmo_share'],axis=1)\n",
    "    return x\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data = comp_outside_good(data,'Inside Good Share')\n",
    "data = comp_nest_shares(data,'Inside Good Share')\n",
    "data['ln(Within Nest Share)'] = np.log( data['Inside Good Share']/data['nest_size'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first estimate using logit\n",
    "class logit(GMM):\n",
    "    \n",
    "    def __init__(self, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        super(logit, self).__init__(*args, **kwds)\n",
    "\n",
    "        \n",
    "    def momcond(self, params):\n",
    "        #unwrap stuff\n",
    "        shares = np.array(self.endog).transpose()\n",
    "        exog = np.array(self.exog)\n",
    "        instr = np.array(self.instrument)\n",
    "        \n",
    "        lshare = np.log(shares[0]) -  np.log(shares[1])\n",
    "        lshare = lshare.transpose()\n",
    "       \n",
    "        lshare_fit = np.matmul(exog,params) #linear equation    \n",
    "        \n",
    "        xi = lshare_fit - lshare\n",
    "        g = instr * xi[:, np.newaxis]\n",
    "        \n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Estimate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate hausmann insturments\n",
    "plan_dum = pd.get_dummies(data['Plan_ID'], prefix='plan',drop_first=True)\n",
    "mkt_dum = pd.get_dummies(data['Market_ID'], prefix='plan',drop_first=True)\n",
    "#hausman_instr =  pd.concat( [data[['Network Score','Satisfaction Score','PPO']], mkt_dum],axis=1)\n",
    "\n",
    "hausman_instr = plan_dum #unsure if this is right...\n",
    "\n",
    "#set up data for logit\n",
    "y = data[['Inside Good Share','Outside Good Share']]\n",
    "\n",
    "# add ln(inside good share) as regressor like formula\n",
    "x_nested = data[['Network Score','Satisfaction Score','PPO','Premium','ln(Within Nest Share)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use dummy variables for the plan as my instrument. When regressing these dummy variables on plan, as a result my model has the form \n",
    "\n",
    "$$p_{jm} = p_j + \\epsilon_{jm}$$ \n",
    "\n",
    "as is standard where $\\epsilon_{jm}$ is a market specific shock. I estimated a model with the other exogeneous characteristics (i.e. Network score, Satisfaction, PPO) in the instrument. However, the model coefficients where similar, so for simplicitiy I use the dummy variables.\n",
    "\n",
    "\n",
    "Additionally, I agrue these dummies are also valid instruments for nest share, as \n",
    "\n",
    "$$ln(s_{jm|g}) = ln(s_{jm|g}) + \\epsilon_{jm}$$\n",
    "\n",
    "It is plausible that average nested share accross markets will be exogenous from the total share. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000006\n",
      "         Iterations: 571\n",
      "         Function evaluations: 928\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005680\n",
      "         Iterations: 235\n",
      "         Function evaluations: 380\n",
      "                                             logit Results                                             \n",
      "=======================================================================================================\n",
      "Dep. Variable:     ['Inside Good Share', 'Outside Good Share']   Hansen J:                        18.74\n",
      "Model:                                                   logit   Prob (Hansen J):                0.0437\n",
      "Method:                                                    GMM                                         \n",
      "Date:                                         Sat, 13 Oct 2018                                         \n",
      "Time:                                                 15:18:49                                         \n",
      "No. Observations:                                         3300                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Network Score             2.2683      0.360      6.304      0.000       1.563       2.974\n",
      "Satisfaction Score        1.1985      0.228      5.266      0.000       0.752       1.645\n",
      "PPO                       0.6065      0.059     10.220      0.000       0.490       0.723\n",
      "Premium                  -1.0951      0.270     -4.059      0.000      -1.624      -0.566\n",
      "ln(Within Nest Share)     0.4254      0.123      3.466      0.001       0.185       0.666\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "#set up and run model\n",
    "beta_nested = np.full(len(x_nested.columns),1)\n",
    "model = logit(y , x_nested, hausman_instr)\n",
    "result = model.fit(beta_nested, maxiter=2, optim_method='nm', wargs=dict(centered=False))\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute market shares\n",
    "\n",
    "def comp_shares(x,beta,sigma):\n",
    "    x = x.copy()\n",
    "    characs = np.array(x[['Network Score','Satisfaction Score','PPO','Premium']])\n",
    "    x['exp_delta'] = np.exp(np.matmul(characs,beta)/(1-sigma))\n",
    "    \n",
    "    #compute Dg = sum_j|g exp(delta_j)\n",
    "    shares = x[['Market_ID','exp_delta','PPO']].copy()\n",
    "    shares['PPO_delta'] = x['exp_delta'] * x['PPO']\n",
    "    shares['HMO_delta'] = x['exp_delta'] * (1 - x['PPO'])\n",
    "    \n",
    "    group_shares =  shares.groupby('Market_ID').sum()\n",
    "    group_shares['PP0_delta_sigma'] = group_shares['PPO_delta']**(sigma)\n",
    "    group_shares['HMO_delta_sigma'] = group_shares['HMO_delta']**(sigma)\n",
    "    group_shares['sum_g'] = group_shares['PPO_delta']**(1-sigma) + group_shares['HMO_delta']**(1-sigma) + 1\n",
    "    #not sure if there should be a 1 at the end of this... (for outside good?)\n",
    "    x = pd.merge(x,group_shares[['PPO_delta','HMO_delta','PP0_delta_sigma','sum_g']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "\n",
    "    #compute sum_g Dg^(1-sigma)\n",
    "    x['denom'] = ( (1 - x['PPO'])*x['HMO_delta']**sigma + x['PPO']*x['PPO_delta']**sigma) * (x['sum_g'])\n",
    "    x['fitted_share'] = x['exp_delta']/x['denom']\n",
    "    return x[['Market_ID','Plan_ID','PPO','fitted_share']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize parameters and compute fitted shares\n",
    "characs = data[['Market_ID','Plan_ID','Network Score','Satisfaction Score','PPO','Premium']]\n",
    "beta = result.params[:-1]\n",
    "alpha = abs(beta[3])\n",
    "sigma = abs(result.params[-1])\n",
    "\n",
    "fitted_shares = comp_shares(characs,beta,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute total share of each nest\n",
    "fitted_shares = comp_nest_shares(fitted_shares,'fitted_share')\n",
    "fitted_shares['nest_shares'] = fitted_shares['fitted_share']/fitted_shares['nest_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characteristics of the fitted shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.155548188548 0.40061093912208035\n"
     ]
    }
   ],
   "source": [
    "print fitted_shares['fitted_share'].mean(), fitted_shares['fitted_share'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Compute Elasticities, Markups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticities\n",
    "\n",
    "Below are the formulas for the elasticities in the Nested logit\n",
    "\n",
    "Own Price: $$-\\alpha p_{jm} ( \\dfrac{1}{1-\\sigma} -  \\dfrac{1}{1-\\sigma}s_{jm|g} -s_{jm} ) $$\n",
    "Cross Prices Same Nest (good $j$, price $k$): $$\\alpha \\dfrac{p_{km}}{s_{jm}} s_{km} (\\dfrac{\\sigma}{1-\\sigma}s_{jm|g} + s_{jm} )$$\n",
    "Cross Prices Different Nest (good $j$, price $k$): $$-\\alpha s_{km} p_{km}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate elasticities\n",
    "fitted_shares['Premium'] = data['Premium']\n",
    "\n",
    "fitted_shares = fitted_shares.groupby('Plan_ID').mean()\n",
    "\n",
    "#diagonal formula\n",
    "nest_shares = np.array(fitted_shares['nest_shares'])\n",
    "shares = np.array(fitted_shares['fitted_share'])\n",
    "prices = np.array(fitted_shares['Premium'])\n",
    "ppo = np.array([fitted_shares['PPO']]) #this one is a matrix\n",
    "\n",
    "#selector matrices\n",
    "own_price = np.identity(len(shares))\n",
    "inside_nest = np.matmul(ppo.transpose(),ppo) + np.matmul((1-ppo.transpose()),(1-ppo)) - own_price\n",
    "outside_nest = 1 - inside_nest - own_price\n",
    "\n",
    "\n",
    "#elasticity variables\n",
    "inside_elasticity = np.matmul( np.array( [ (sigma/(1-sigma) * nest_shares + shares)/shares ] ).transpose(),\n",
    "          np.array([alpha*prices*shares]))\n",
    "\n",
    "own_elasticity = -alpha*((1/(1-sigma)) - sigma/(1-sigma) * nest_shares - shares)*prices\n",
    "\n",
    "outside_elasticity =  shares * alpha * prices\n",
    "\n",
    "nest_elasticity = own_price*own_elasticity + inside_nest*inside_elasticity + outside_nest*outside_elasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the elasticities from the nested logit. Note that the indexing starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -3.328889  0.407455  1.405408  1.119572  0.421476  0.453460  1.518383   \n",
      "1   0.602507 -4.223542  0.635154  0.505975  1.141629  1.228261  0.686212   \n",
      "2   1.337650  0.407455 -3.216209  1.123335  0.421476  0.453460  1.523485   \n",
      "3   1.368524  0.407455  1.442678 -3.483610  0.421476  0.453460  1.558648   \n",
      "4   0.602507  1.119553  0.635154  0.505975 -4.110862  1.245958  0.686212   \n",
      "5   0.602507  1.080868  0.635154  0.505975  1.118061 -3.374918  0.686212   \n",
      "6   1.335640  0.407455  1.408012  1.121647  0.421476  0.453460 -3.792145   \n",
      "7   0.602507  1.107726  0.635154  0.505975  1.145845  1.232797  0.686212   \n",
      "8   1.354812  0.407455  1.428223  1.137747  0.421476  0.453460  1.543031   \n",
      "9   0.602507  1.130796  0.635154  0.505975  1.169708  1.258471  0.686212   \n",
      "10  0.602507  1.109928  0.635154  0.505975  1.148122  1.235247  0.686212   \n",
      "11  1.341294  0.407455  1.413972  1.126395  0.421476  0.453460  1.527635   \n",
      "12  1.400124  0.407455  1.475990  1.175799  0.421476  0.453460  1.594638   \n",
      "13  0.602507  1.099585  0.635154  0.505975  1.137423  1.223735  0.686212   \n",
      "14  1.334681  0.407455  1.407001  1.120842  0.421476  0.453460  1.520104   \n",
      "15  0.602507  1.083899  0.635154  0.505975  1.121198  1.206279  0.686212   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.487812  1.182064  0.306248  0.419665  1.450435  1.028330  0.459507   \n",
      "1   1.321307  0.534217  0.829516  1.136722  0.655503  0.464739  1.244639   \n",
      "2   0.487812  1.186036  0.306248  0.419665  1.455309  1.031786  0.459507   \n",
      "3   0.487812  1.213411  0.306248  0.419665  1.488898  1.055600  0.459507   \n",
      "4   1.340346  0.534217  0.841469  1.153101  0.655503  0.464739  1.262573   \n",
      "5   1.294031  0.534217  0.812392  1.113256  0.655503  0.464739  1.218946   \n",
      "6   0.487812  1.184254  0.306248  0.419665  1.453122  1.030236  0.459507   \n",
      "7  -3.417662  0.534217  0.832580  1.140920  0.655503  0.464739  1.249236   \n",
      "8   0.487812 -3.705668  0.306248  0.419665  1.473980  1.045023  0.459507   \n",
      "9   1.353806  0.534217 -3.859853  1.164681  0.655503  0.464739  1.275253   \n",
      "10  1.328823  0.534217  0.834234 -3.886710  0.655503  0.464739  1.251718   \n",
      "11  0.487812  1.189267  0.306248  0.419665 -3.701956  1.034596  0.459507   \n",
      "12  0.487812  1.241429  0.306248  0.419665  1.523278 -3.458357  0.459507   \n",
      "13  1.316439  0.534217  0.826460  1.132534  0.655503  0.464739 -3.696934   \n",
      "14  0.487812  1.183404  0.306248  0.419665  1.452079  1.029496  0.459507   \n",
      "15  1.297661  0.534217  0.814671  1.116379  0.655503  0.464739  1.222365   \n",
      "\n",
      "          14        15  \n",
      "0   1.419159  0.487247  \n",
      "1   0.641369  1.319778  \n",
      "2   1.423928  0.487247  \n",
      "3   1.456793  0.487247  \n",
      "4   0.641369  1.338794  \n",
      "5   0.641369  1.292533  \n",
      "6   1.421789  0.487247  \n",
      "7   0.641369  1.324652  \n",
      "8   1.442197  0.487247  \n",
      "9   0.641369  1.352239  \n",
      "10  0.641369  1.327284  \n",
      "11  1.427807  0.487247  \n",
      "12  1.490431  0.487247  \n",
      "13  0.641369  1.314916  \n",
      "14 -3.182256  0.487247  \n",
      "15  0.641369 -3.934994  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(nest_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Markup\n",
      "Plan_ID          \n",
      "1        0.735307\n",
      "2        0.662997\n",
      "3        0.759405\n",
      "4        0.704811\n",
      "5        0.678888\n",
      "6        0.716631\n",
      "7        0.740775\n",
      "8        0.732038\n",
      "9        0.700068\n",
      "10       0.645045\n",
      "11       0.683945\n",
      "12       0.736005\n",
      "13       0.704012\n",
      "14       0.703164\n",
      "15       0.768211\n",
      "16       0.698950\n"
     ]
    }
   ],
   "source": [
    "#solve for marginal costs\n",
    "def comp_markup(shares,nest_shares):\n",
    "    shares_vector = np.array([shares])\n",
    "    \n",
    "    #set up matrix    \n",
    "    own_price = np.identity(len(shares))\n",
    "\n",
    "    #caclulate formula\n",
    "    own_deriv  =  -alpha*((1/(1-sigma)) - sigma/(1-sigma) * nest_shares - shares)*shares\n",
    "    \n",
    "    derivative = own_price *own_deriv\n",
    "    #take inverse and calc markup\n",
    "    inv_derivative = np.linalg.inv(derivative)\n",
    "\n",
    "    markup = - np.matmul(inv_derivative, shares_vector.transpose()) \n",
    "    return markup.transpose()[0]\n",
    "\n",
    "\n",
    "\n",
    "fitted_shares =  comp_shares(characs,beta,sigma)\n",
    "fitted_shares = comp_nest_shares(fitted_shares,'fitted_share')\n",
    "fitted_shares['nest_shares'] = fitted_shares['fitted_share']/fitted_shares['nest_size']\n",
    "\n",
    "\n",
    "nest_shares = np.array(fitted_shares['nest_shares']).squeeze()\n",
    "shares = np.array(fitted_shares['fitted_share']).squeeze()\n",
    "prices = np.array(data['Premium']).squeeze()\n",
    "\n",
    "data['Markup'] = comp_markup(shares,nest_shares)\n",
    "print data[['Plan_ID','Markup']].groupby('Plan_ID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the markups are higher than with the pure logit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Marginal Costs against Plan Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 7.914e+05\n",
      "Date:                Sat, 13 Oct 2018   Prob (F-statistic):               0.00\n",
      "Time:                        15:49:48   Log-Likelihood:                 3257.8\n",
      "No. Observations:                3300   AIC:                            -6510.\n",
      "Df Residuals:                    3297   BIC:                            -6491.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Network Score          2.4226      0.038     63.425      0.000       2.348       2.498\n",
      "Satisfaction Score     0.2400      0.040      6.040      0.000       0.162       0.318\n",
      "PPO                    0.2069      0.003     65.318      0.000       0.201       0.213\n",
      "==============================================================================\n",
      "Omnibus:                      512.810   Durbin-Watson:                   1.862\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1077.543\n",
      "Skew:                           0.924   Prob(JB):                    1.03e-234\n",
      "Kurtosis:                       5.104   Cond. No.                         46.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_q3 = sm.OLS(data['Premium'] - data['Markup'], data[['Network Score','Satisfaction Score','PPO']])\n",
    "result_q3 = model_q3.fit()\n",
    "print result_q3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
