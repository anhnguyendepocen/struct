{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    \"\"\"pre-processing to calculate outside good shares\"\"\"\n",
    "    shares = data[['Market_ID',name,'PPO']].copy()\n",
    "\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "\n",
    "def comp_nest_shares(x,name):\n",
    "    \"\"\"calculate shares within nest\"\"\"\n",
    "    nest_x = x[['Market_ID',name,'PPO']].copy()\n",
    "    nest_x['ppo_share'] = nest_x[name] * nest_x['PPO']\n",
    "    nest_x['hmo_share'] = nest_x[name] * (1 - nest_x['PPO'])\n",
    "    \n",
    "    group_shares = nest_x.groupby('Market_ID').sum()\n",
    "    \n",
    "    x = pd.merge(x, group_shares[['hmo_share','ppo_share']], right_index=True,\n",
    "                 left_on = 'Market_ID')\n",
    "    \n",
    "    x['nest_size'] =   x['PPO'] * x['ppo_share'] + (1 - x['PPO']) * x['hmo_share']\n",
    "    x = x.drop(labels=['ppo_share','hmo_share'],axis=1)\n",
    "    return x\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data = comp_outside_good(data,'Inside Good Share')\n",
    "data = comp_nest_shares(data,'Inside Good Share')\n",
    "data['ln(Within Nest Share)'] = np.log( data['Inside Good Share']/data['nest_size'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first estimate using logit\n",
    "class logit(GMM):\n",
    "    \n",
    "    def __init__(self, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        super(logit, self).__init__(*args, **kwds)\n",
    "\n",
    "        \n",
    "    def momcond(self, params):\n",
    "        #unwrap stuff\n",
    "        shares = np.array(self.endog).transpose()\n",
    "        exog = np.array(self.exog)\n",
    "        instr = np.array(self.instrument)\n",
    "        \n",
    "        lshare = np.log(shares[0]) -  np.log(shares[1])\n",
    "        lshare = lshare.transpose()\n",
    "       \n",
    "        lshare_fit = np.matmul(exog,params) #linear equation    \n",
    "        \n",
    "        xi = lshare_fit - lshare\n",
    "        g = instr * xi[:, np.newaxis]\n",
    "        \n",
    "        return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Estimate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate hausmann insturments\n",
    "plan_dum = pd.get_dummies(data['Plan_ID'], prefix='plan',drop_first=True)\n",
    "mkt_dum = pd.get_dummies(data['Market_ID'], prefix='plan',drop_first=True)\n",
    "#hausman_instr =  pd.concat( [data[['Network Score','Satisfaction Score','PPO']],\n",
    "#                               mkt_dum],axis=1)\n",
    "\n",
    "hausman_instr = plan_dum\n",
    "\n",
    "#set up data for logit\n",
    "y = data[['Inside Good Share','Outside Good Share']]\n",
    "\n",
    "# add ln(inside good share) as regressor like formula\n",
    "x_nested = data[['Network Score','Satisfaction Score','PPO',\n",
    "                 'Premium','ln(Within Nest Share)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use dummy variables for the plan as my instrument. When regressing these dummy variables on plan, my model has the form \n",
    "\n",
    "$$p_{jm} = p_j + \\epsilon_{jm}$$ \n",
    "\n",
    "as is standard where $\\epsilon_{jm}$ is a market specific shock for product $j$. I estimated a model with the other exogeneous characteristics (i.e. Network score, Satisfaction, PPO) in the instrument. However, the model coefficients where similar, so for simplicitiy I just use the dummy variables.\n",
    "\n",
    "\n",
    "Additionally, I agrue these dummies are also valid instruments for nest share\n",
    "\n",
    "$$ln(s_{jm|g}) = ln(s_{j|g}) + \\epsilon_{jm}$$\n",
    "\n",
    "It is plausible that average nested share accross markets will be exogenous from the share in any given market. This would true if roughly the same proportion of consumers prefer plan $j$ in each market (for its exogenous characteristics), but the plans available in each market are differ(as is the case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000006\n",
      "         Iterations: 571\n",
      "         Function evaluations: 928\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005680\n",
      "         Iterations: 235\n",
      "         Function evaluations: 380\n",
      "                                             logit Results                                             \n",
      "=======================================================================================================\n",
      "Dep. Variable:     ['Inside Good Share', 'Outside Good Share']   Hansen J:                        18.74\n",
      "Model:                                                   logit   Prob (Hansen J):                0.0437\n",
      "Method:                                                    GMM                                         \n",
      "Date:                                         Sun, 14 Oct 2018                                         \n",
      "Time:                                                 12:46:55                                         \n",
      "No. Observations:                                         3300                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Network Score             2.2683      0.360      6.304      0.000       1.563       2.974\n",
      "Satisfaction Score        1.1985      0.228      5.266      0.000       0.752       1.645\n",
      "PPO                       0.6065      0.059     10.220      0.000       0.490       0.723\n",
      "Premium                  -1.0951      0.270     -4.059      0.000      -1.624      -0.566\n",
      "ln(Within Nest Share)     0.4254      0.123      3.466      0.001       0.185       0.666\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "#set up and run model\n",
    "beta_nested = np.full(len(x_nested.columns),1)\n",
    "model = logit(y , x_nested, hausman_instr)\n",
    "result = model.fit(beta_nested, maxiter=2, optim_method='nm',\n",
    "                   wargs=dict(centered=False))\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc unobservables\n",
    "data['Xi'] = (np.log(y['Inside Good Share']) - np.log(y['Outside Good Share']) \n",
    "              - np.matmul(np.array(x_nested),result.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute market shares\n",
    "\n",
    "def comp_shares(x,beta,sigma):\n",
    "    x = x.copy()\n",
    "    characs = np.array(x[['Network Score','Satisfaction Score','PPO','Premium']])\n",
    "    x['exp_delta'] = np.exp(( np.matmul(characs,beta) +x['Xi'])/(1-sigma))\n",
    "    \n",
    "    #compute Dg = sum_j|g exp(delta_j)\n",
    "    shares = x[['Market_ID','exp_delta','PPO']].copy()\n",
    "    shares['PPO_delta'] = x['exp_delta'] * x['PPO']\n",
    "    shares['HMO_delta'] = x['exp_delta'] * (1 - x['PPO'])\n",
    "    \n",
    "    group_shares =  shares.groupby('Market_ID').sum()\n",
    "    group_shares['PP0_delta_sigma'] = group_shares['PPO_delta']**(sigma)\n",
    "    group_shares['HMO_delta_sigma'] = group_shares['HMO_delta']**(sigma)\n",
    "    group_shares['sum_g'] = (group_shares['PPO_delta']**(1-sigma) \n",
    "                             + group_shares['HMO_delta']**(1-sigma) + 1)\n",
    "    \n",
    "    x = pd.merge(x,group_shares[['PPO_delta','HMO_delta','PP0_delta_sigma','sum_g']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "\n",
    "    #compute sum_g Dg^(1-sigma)\n",
    "    x['denom'] = ( (1 - x['PPO'])*x['HMO_delta']**sigma + \n",
    "                  x['PPO']*x['PPO_delta']**sigma) * (x['sum_g'])\n",
    "    x['fitted_share'] = x['exp_delta']/x['denom']\n",
    "    return x[['Market_ID','Plan_ID','PPO','fitted_share']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize parameters and compute fitted shares\n",
    "characs = data[['Market_ID','Plan_ID','Network Score',\n",
    "                'Satisfaction Score','PPO','Premium','Xi']]\n",
    "beta = result.params[:-1]\n",
    "alpha = abs(beta[3])\n",
    "sigma = abs(result.params[-1])\n",
    "\n",
    "fitted_shares = comp_shares(characs,beta,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute total share of each nest\n",
    "fitted_shares = comp_nest_shares(fitted_shares,'fitted_share')\n",
    "fitted_shares['nest_shares'] = (fitted_shares['fitted_share']/\n",
    "                                fitted_shares['nest_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characteristics of the fitted shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.155440963636\n",
      "Max: 0.35561000000000004\n",
      "Min: 0.03767\n"
     ]
    }
   ],
   "source": [
    "print 'Mean: %s'%fitted_shares['fitted_share'].mean()\n",
    "print 'Max: %s'%fitted_shares['fitted_share'].max()\n",
    "print 'Min: %s'%fitted_shares['fitted_share'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Compute Elasticities, Markups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticities\n",
    "\n",
    "Below are the formulas for the elasticities in the Nested logit\n",
    "\n",
    "Own Price: $$-\\alpha p_{jm} ( \\dfrac{1}{1-\\sigma} -  \\dfrac{1}{1-\\sigma}s_{jm|g} -s_{jm} ) $$\n",
    "Cross Prices Same Nest (good $j$, price $k$): $$\\alpha \\dfrac{p_{km}}{s_{jm}} s_{km} (\\dfrac{\\sigma}{1-\\sigma}s_{jm|g} + s_{jm} )$$\n",
    "Cross Prices Different Nest (good $j$, price $k$): $$-\\alpha s_{km} p_{km}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate elasticities\n",
    "fitted_shares['Premium'] = data['Premium']\n",
    "\n",
    "fitted_shares = fitted_shares.groupby('Plan_ID').mean()\n",
    "\n",
    "#diagonal formula\n",
    "nest_shares = np.array(fitted_shares['nest_shares'])\n",
    "shares = np.array(fitted_shares['fitted_share'])\n",
    "prices = np.array(fitted_shares['Premium'])\n",
    "ppo = np.array([fitted_shares['PPO']]) #this one is a matrix\n",
    "\n",
    "#selector matrices\n",
    "own_price = np.identity(len(shares))\n",
    "inside_nest = (np.matmul(ppo.transpose(),ppo) + \n",
    "               np.matmul((1-ppo.transpose()),(1-ppo)) - own_price)\n",
    "outside_nest = (1 - inside_nest) - own_price\n",
    "\n",
    "\n",
    "#elasticity variables\n",
    "inside_elasticity = np.matmul( np.array( [ (sigma/(1-sigma)* nest_shares\n",
    "                                            + shares)/shares ] ).transpose(),\n",
    "          np.array([alpha*prices*shares]))\n",
    "\n",
    "own_elasticity = -alpha*((1/(1-sigma)) - sigma/(1-sigma) * \n",
    "                         nest_shares - shares)*prices\n",
    "\n",
    "outside_elasticity =  shares * alpha * prices\n",
    "\n",
    "nest_elasticity = (own_price*own_elasticity + \n",
    "                   inside_nest*inside_elasticity + \n",
    "                   outside_nest*outside_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the elasticities from the nested logit. Note that the indexing starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -3.614758  0.289348  1.427780  1.066116  0.301170  0.388905  1.310656   \n",
      "1   0.553277 -3.625294  0.596565  0.445453  0.907179  1.171454  0.547628   \n",
      "2   1.326098  0.289348 -3.540520  1.067664  0.301170  0.388905  1.312559   \n",
      "3   1.387476  0.289348  1.496032 -3.694212  0.301170  0.388905  1.373310   \n",
      "4   0.553277  0.888736  0.596565  0.445453 -3.534876  1.194525  0.547628   \n",
      "5   0.553277  0.843088  0.596565  0.445453  0.877533 -3.356309  0.547628   \n",
      "6   1.335440  0.289348  1.439925  1.075185  0.301170  0.388905 -3.624992   \n",
      "7   0.553277  0.871988  0.596565  0.445453  0.907614  1.172015  0.547628   \n",
      "8   1.360937  0.289348  1.467417  1.095713  0.301170  0.388905  1.347042   \n",
      "9   0.553277  0.910438  0.596565  0.445453  0.947634  1.223694  0.547628   \n",
      "10  0.553277  0.875027  0.596565  0.445453  0.910777  1.176100  0.547628   \n",
      "11  1.336768  0.289348  1.441356  1.076254  0.301170  0.388905  1.323119   \n",
      "12  1.440995  0.289348  1.553738  1.160169  0.301170  0.388905  1.426282   \n",
      "13  0.553277  0.867251  0.596565  0.445453  0.902683  1.165648  0.547628   \n",
      "14  1.335680  0.289348  1.440183  1.075378  0.301170  0.388905  1.322042   \n",
      "15  0.553277  0.847084  0.596565  0.445453  0.881692  1.138542  0.547628   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.404680  1.077531  0.236349  0.316133  1.294680  0.977441  0.361846   \n",
      "1   1.218973  0.450222  0.711927  0.952252  0.540953  0.408402  1.089947   \n",
      "2   0.404680  1.079095  0.236349  0.316133  1.296559  0.978860  0.361846   \n",
      "3   0.404680  1.129040  0.236349  0.316133  1.356570  1.024166  0.361846   \n",
      "4   1.242980  0.450222  0.725948  0.971006  0.540953  0.408402  1.111413   \n",
      "5   1.179138  0.450222  0.688662  0.921133  0.540953  0.408402  1.054328   \n",
      "6   0.404680  1.086697  0.236349  0.316133  1.305693  0.985755  0.361846   \n",
      "7  -3.373637  0.450222  0.712268  0.952708  0.540953  0.408402  1.090469   \n",
      "8   0.404680 -3.717100  0.236349  0.316133  1.330622  1.004576  0.361846   \n",
      "9   1.273332  0.450222 -3.711404  0.994717  0.540953  0.408402  1.138553   \n",
      "10  1.223807  0.450222  0.714751 -3.474018  0.540953  0.408402  1.094270   \n",
      "11  0.404680  1.087777  0.236349  0.316133 -3.649444  0.986735  0.361846   \n",
      "12  0.404680  1.172591  0.236349  0.316133  1.408896 -3.741786  0.361846   \n",
      "13  1.212931  0.450222  0.708399  0.947533  0.540953  0.408402 -3.510241   \n",
      "14  0.404680  1.086892  0.236349  0.316133  1.305927  0.985932  0.361846   \n",
      "15  1.184726  0.450222  0.691926  0.925499  0.540953  0.408402  1.059325   \n",
      "\n",
      "          14        15  \n",
      "0   1.420186  0.362297  \n",
      "1   0.593393  1.091306  \n",
      "2   1.422248  0.362297  \n",
      "3   1.488075  0.362297  \n",
      "4   0.593393  1.112798  \n",
      "5   0.593393  1.055642  \n",
      "6   1.432266  0.362297  \n",
      "7   0.593393  1.091828  \n",
      "8   1.459612  0.362297  \n",
      "9   0.593393  1.139972  \n",
      "10  0.593393  1.095633  \n",
      "11  1.433691  0.362297  \n",
      "12  1.545474  0.362297  \n",
      "13  0.593393  1.085897  \n",
      "14 -3.516016  0.362297  \n",
      "15  0.593393 -3.448638  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(nest_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the elasticities fall relative to the simple logit within the nest, this is because you are restricted to buying within the nest. Conversely, the between nest elasticities go up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Markup\n",
      "Plan_ID          \n",
      "1        0.731614\n",
      "2        0.660008\n",
      "3        0.755827\n",
      "4        0.699635\n",
      "5        0.675452\n",
      "6        0.717732\n",
      "7        0.735489\n",
      "8        0.729162\n",
      "9        0.696208\n",
      "10       0.639947\n",
      "11       0.682427\n",
      "12       0.730343\n",
      "13       0.695612\n",
      "14       0.699386\n",
      "15       0.761726\n",
      "16       0.698719\n"
     ]
    }
   ],
   "source": [
    "#solve for marginal costs\n",
    "def comp_markup(shares,nest_shares):\n",
    "    shares_vector = np.array([shares])\n",
    "    \n",
    "    #set up matrix    \n",
    "    own_price = np.identity(len(shares))\n",
    "\n",
    "    #caclulate formula\n",
    "    own_deriv  =  -alpha*((1/(1-sigma)) - sigma/(1-sigma) * nest_shares\n",
    "                          - shares)*shares\n",
    "    \n",
    "    derivative = own_price *own_deriv\n",
    "    #take inverse and calc markup\n",
    "    inv_derivative = np.linalg.inv(derivative)\n",
    "\n",
    "    markup = - np.matmul(inv_derivative, shares_vector.transpose()) \n",
    "    return markup.transpose()[0]\n",
    "\n",
    "\n",
    "\n",
    "fitted_shares =  comp_shares(characs,beta,sigma)\n",
    "fitted_shares = comp_nest_shares(fitted_shares,'fitted_share')\n",
    "fitted_shares['nest_shares'] = fitted_shares['fitted_share']/fitted_shares['nest_size']\n",
    "\n",
    "nest_shares = np.array(fitted_shares['nest_shares']).squeeze()\n",
    "shares = np.array(fitted_shares['fitted_share']).squeeze()\n",
    "prices = np.array(data['Premium']).squeeze()\n",
    "\n",
    "data['Markup'] = comp_markup(shares,nest_shares)\n",
    "print data[['Plan_ID','Markup']].groupby('Plan_ID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the markups are higher than with the pure logit model. This is because there is less competition within the nest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Markup   R-squared:                       0.749\n",
      "Model:                            OLS   Adj. R-squared:                  0.749\n",
      "Method:                 Least Squares   F-statistic:                     1784.\n",
      "Date:                Sun, 14 Oct 2018   Prob (F-statistic):          1.30e-181\n",
      "Time:                        12:51:22   Log-Likelihood:                 906.08\n",
      "No. Observations:                 600   AIC:                            -1808.\n",
      "Df Residuals:                     598   BIC:                            -1799.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0326      0.007    140.103      0.000       1.018       1.047\n",
      "Plan_ID       -0.0541      0.001    -42.235      0.000      -0.057      -0.052\n",
      "==============================================================================\n",
      "Omnibus:                        9.600   Durbin-Watson:                   1.259\n",
      "Prob(Omnibus):                  0.008   Jarque-Bera (JB):               15.364\n",
      "Skew:                           0.045   Prob(JB):                     0.000461\n",
      "Kurtosis:                       3.779   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mean_markup = data[['Market_ID','Markup']].groupby('Market_ID').mean()\n",
    "no_firms = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "\n",
    "\n",
    "model_q2 = sm.OLS(mean_markup,sm.add_constant(no_firms))\n",
    "result_q2 = model_q2.fit()\n",
    "print result_q2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the Markup is decreasing in the number of firms in the market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Marginal Costs against Plan Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.383\n",
      "Model:                            OLS   Adj. R-squared:                  0.383\n",
      "Method:                 Least Squares   F-statistic:                     682.2\n",
      "Date:                Sun, 14 Oct 2018   Prob (F-statistic):               0.00\n",
      "Time:                        12:47:03   Log-Likelihood:                 2672.2\n",
      "No. Observations:                3300   AIC:                            -5336.\n",
      "Df Residuals:                    3296   BIC:                            -5312.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  1.5074      0.043     35.090      0.000       1.423       1.592\n",
      "Network Score          0.2681      0.065      4.100      0.000       0.140       0.396\n",
      "Satisfaction Score    -0.0785      0.047     -1.653      0.098      -0.172       0.015\n",
      "PPO                    0.1708      0.004     44.940      0.000       0.163       0.178\n",
      "==============================================================================\n",
      "Omnibus:                     1573.922   Durbin-Watson:                   1.746\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12671.486\n",
      "Skew:                          -2.104   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.628   Cond. No.                         69.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_q3 = sm.OLS(data['Premium'] - data['Markup'], \n",
    "                   sm.add_constant(data[['Network Score','Satisfaction Score','PPO']]))\n",
    "result_q3 = model_q3.fit()\n",
    "print result_q3.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
