{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.interpolate import interp1d #pre written interpolation function\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "\n",
    "# add state as parameters\n",
    "# figure out max x using function\n",
    "#does state start at 0 or at 1?\n",
    "\n",
    "# parametrize cost function correctly\n",
    "# what is the correct measure of distance\n",
    "# fix class to extend generic likelihood model\n",
    "# \n",
    " \n",
    "# dropping data\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below references the following two sources.\n",
    "\n",
    "John Rust's website:\n",
    "https://editorialexpress.com/jrust/nfxp.html\n",
    "\n",
    "Victor Aguirregabiria and Pedro Mira's website:\n",
    "http://individual.utoronto.ca/vaguirre/wpapers/program_code_survey_joe_2008.html\n",
    "\n",
    "Victor Aguirregabiria and Pedro Mira's 2004 paper\n",
    "https://www.jstor.org/stable/3082006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the bus .dat because Aguirregabiria and Mira hate everyone\n",
    "data = np.fromfile('bus1234.dat')\n",
    "data = data.reshape(len(data)/6,6)\n",
    "data = pd.DataFrame(data,columns=['id','group','year','month','replace','miles'])\n",
    "\n",
    "#save to .csv so other people don't need to be confused\n",
    "data.to_csv(\"bus1234.csv\")\n",
    "\n",
    "#switch to date time for ease \n",
    "data['date'] = pd.to_datetime(data[['year', 'month']].assign(Day=1))\n",
    "data = data[['id','group','date','replace','miles']]\n",
    "\n",
    "#lag date\n",
    "date_lag = data.copy()\n",
    "date_lag['date'] = date_lag['date'] - pd.DateOffset(months=1)\n",
    "data = data.merge(date_lag, how='left', on=['id','group','date'] , suffixes=('','_next'))\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "BETA = .97\n",
    "GAMMA = .5772 #euler's constant\n",
    "\n",
    "#size of step in discretization\n",
    "STEP = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miles_pdf(i_obs, x_obs, x_next):\n",
    "    \"\"\"non-parametric estimation of mileage pdf.\n",
    "    in other words, the probability of jumping dx states\n",
    "    next period\n",
    "    \n",
    "    this corresponds to pdfdx in AM's code\"\"\"\n",
    "    \n",
    "    #figure out max number of steps\n",
    "    dx = (1-i_obs)*(x_next - x_obs) + i_obs*x_obs \n",
    "    discrete = (dx/STEP).astype(int)\n",
    "    \n",
    "    #make a dataframe with the discrete 'jumps' in mileage\n",
    "    frame = np.array([discrete, i_obs]).transpose()\n",
    "    frame = pd.DataFrame(frame, columns=('dx','i'))\n",
    "\n",
    "    #non-parametrically group jumps to make pdf\n",
    "    pdfdx = frame.groupby('dx')\n",
    "    pdfdx = pdfdx.count()/pdfdx.count().sum()\n",
    "    return  np.array(pdfdx)\n",
    "\n",
    "\n",
    "MILES_PDF = miles_pdf(data['replace'], data['miles'], data['miles_next'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_1(i_obs, x_obs , x_next):\n",
    "    \"\"\"calculate transitions probabilities,\n",
    "    non-parametrically\n",
    "    \n",
    "    this corresponds to fmat1 and fmat2 in AM's code\"\"\"\n",
    "    \n",
    "    #transitions when i=1\n",
    "    num_states = (x_obs.max()/STEP).astype(int) + 1\n",
    "    pdfdx = miles_pdf(i_obs, x_obs, x_next).transpose()\n",
    "    \n",
    "    #zero probability of transitioning to large states\n",
    "    zeros = np.zeros( (num_states,num_states-pdfdx.shape[1]) )\n",
    "    \n",
    "    #transitioning to first state and 'jumping' dx states\n",
    "    fmat1 = np.tile(pdfdx,(num_states,1))\n",
    "    fmat1 = np.concatenate( (fmat1, zeros), axis=1 )\n",
    "\n",
    "    return fmat1\n",
    "\n",
    "FMAT1 = transition_1(data['replace'], data['miles'],data['miles_next'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_0(i_obs, x_obs , x_next):\n",
    "    \"\"\"calculate transitions probabilities,\n",
    "    non-parametrically\n",
    "    \n",
    "    this corresponds to fmat1 and fmat2 in AM's code\"\"\"\n",
    "    \n",
    "    \n",
    "    num_states = (x_obs.max()/STEP).astype(int) + 1\n",
    "    pdfdx = miles_pdf(i_obs, x_obs, x_next).transpose()\n",
    "    \n",
    "    #initialize fmat array, transitions when i=0\n",
    "    end_zeros = np.zeros((1,num_states -pdfdx.shape[1]))\n",
    "    fmat0 = np.concatenate( (pdfdx,end_zeros), axis=1 )\n",
    "\n",
    "    for row in range(1,num_states):\n",
    "        \n",
    "        #this corresponds to colz i think\n",
    "        cutoff = (num_states - row - pdfdx.shape[1] )\n",
    "        \n",
    "        #case 1 far enough from the 'end' of the matrix\n",
    "        if cutoff >= 0:\n",
    "            start_zeros = np.zeros((1,row))\n",
    "            end_zeros = np.zeros((1,num_states -pdfdx.shape[1] - row))\n",
    "            fmat_new = np.concatenate( (start_zeros,pdfdx,end_zeros), axis=1 )\n",
    "            fmat0 = np.concatenate((fmat0,fmat_new))\n",
    "       \n",
    "        #case 2, too far from the end and need to adjust probs\n",
    "        else:\n",
    "            pdf_adj = pdfdx[:,0:cutoff]\n",
    "            pdf_adj = pdf_adj/pdf_adj.sum(axis=1)\n",
    "            \n",
    "            start_zeros = np.zeros((1,row))\n",
    "            fmat_new = np.concatenate( (start_zeros,pdf_adj), axis=1 )\n",
    "            fmat0 = np.concatenate((fmat0,fmat_new))\n",
    "\n",
    "\n",
    "    return fmat0\n",
    "\n",
    "FMAT0 = transition_0(data['replace'],data['miles'],data['miles_next'])\n",
    "\n",
    "PR_TRANS = FMAT0, FMAT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_initial_pr(i_obs, x_obs):\n",
    "    \"\"\"truly non-parametric\n",
    "    initial the probability of view a given state\n",
    "    May delete later\"\"\"\n",
    "    \n",
    "    num_states = ( x_obs.max()/STEP).astype(int) + 1\n",
    "    discrete = (x_obs/STEP).astype(int)\n",
    "    \n",
    "    df = np.array([discrete, i_obs]).transpose()\n",
    "    df = pd.DataFrame(df, columns=('x','i'))\n",
    "    pr_obs = df.groupby('x')\n",
    "    pr_obs = pr_obs.sum()/(1.*pr_obs.count())\n",
    "\n",
    "    return  np.array(pr_obs)\n",
    "\n",
    "PR_OBS = np_initial_pr(data['replace'], data['miles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.036201\n",
      "         Iterations 14\n"
     ]
    }
   ],
   "source": [
    "def initial_pr(i_obs, x_obs):\n",
    "    \"\"\"initial the probability of view a given state following AM.\n",
    "    Seems like it just involves logit to predict\"\"\"\n",
    "    \n",
    "    X = np.array([x_obs, x_obs**2, x_obs**3]).transpose()\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    model = sm.Logit(i_obs,X)\n",
    "    fit = model.fit()\n",
    "    #print fit.summary()\n",
    "    \n",
    "    states = np.arange(x_obs.min(),x_obs.max(), STEP)\n",
    "    \n",
    "    states = np.array([states, states**2, states**3]).transpose()\n",
    "    states = sm.add_constant(states)\n",
    "    \n",
    "    return fit.predict(states)\n",
    "\n",
    "PR_OBS = initial_pr(data['replace'], data['miles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hm_value(theta1, cost, i_obs, x_obs, pr_obs, pr_trans):\n",
    "    \"\"\"calculate value function using hotz miller approach\"\"\"\n",
    "    \n",
    "    #set up matrices, transition is deterministic\n",
    "    trans0, trans1 = pr_trans\n",
    "    \n",
    "    #should probably make these class parameters\n",
    "    num_states = ( x_obs.max()/STEP).astype(int) + 1\n",
    "    x = np.arange(x_obs.min(),x_obs.max(), STEP)\n",
    "\n",
    "    #calculate value function for all state\n",
    "    pr_tile = np.tile( pr_obs.reshape(num_states,1), (1,num_states))\n",
    "    \n",
    "    denom = (np.identity(num_states) - BETA*(1-pr_tile)*trans0 - BETA*trans1*pr_tile)\n",
    "    \n",
    "    numer = ( (1-pr_obs)*(theta1*x  + GAMMA - np.log(1-pr_obs)) + \n",
    "                 pr_obs*(cost+ GAMMA - np.log(pr_obs) ) )\n",
    "    \n",
    "    value = np.linalg.inv(denom).dot(numer)\n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "#hm_value(-.000058, -.001047, data['replace'], data['miles'], PR_OBS, PR_TRANS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-2494563\n",
    "-3360878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hm_prob(theta1, cost, i_obs, x_obs, pr_obs, pr_trans):\n",
    "    \"\"\"calculate kappa using value function\"\"\"\n",
    "    \n",
    "    value = hm_value(theta1, cost, i_obs, x_obs, pr_obs, pr_trans)\n",
    "    trans0, trans1 = pr_trans\n",
    "    \n",
    "    #should probably make these class parameters\n",
    "    num_states = ( x_obs.max()/STEP).astype(int) + 1\n",
    "    x = np.arange(x_obs.min(),x_obs.max(), STEP)\n",
    "    \n",
    "    delta1 = np.exp( cost + BETA*trans1.dot(value))\n",
    "    delta0 = np.exp( x*theta1 + BETA*trans0.dot(value) )\n",
    "    \n",
    "    return delta1/(delta1+delta0)\n",
    "\n",
    "\n",
    "hm_prob(-.000058, -.001047, data['replace'], data['miles'], PR_OBS, PR_TRANS).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.036201\n",
      "         Iterations 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erichschulman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " theta_1:-0.0077, R:-10.3026\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "class HotzMiller():\n",
    "    \"\"\"class for estimating the values of R and theta\n",
    "    using the Hotz Miller routine and the helper functions\n",
    "    above\"\"\"\n",
    "    \n",
    "    def __init__(self, i, x, x_next):\n",
    "        \n",
    "        #transitions\n",
    "        self.pr_obs = initial_pr(i, x)\n",
    "        self.trans =  transition_1(i,x,x_next), transition_1(i,x,x_next)\n",
    "        \n",
    "        #should probably make these class parameters\n",
    "        self.num_states = ( x.max()/STEP).astype(int) + 1\n",
    "        self.states = np.arange(x.min(),x.max(), STEP)\n",
    "        \n",
    "        #data\n",
    "        self.x = x\n",
    "        self.x_next = x\n",
    "        self.i = i\n",
    "        \n",
    "        #parameters\n",
    "        self.theta1 = 0\n",
    "        self.R = 0\n",
    "        \n",
    "        \n",
    "    def likelihood(self, params): \n",
    "        theta1, R = params\n",
    "        \n",
    "        # Input our data into the model\n",
    "        i = self.i\n",
    "        x = (self.x/STEP).astype(int)\n",
    "        \n",
    "        #set up hm state pr\n",
    "        prob = hm_prob(theta1, R, self.i, self.x, self.pr_obs, self.trans).transpose()\n",
    "        prob = interp1d(self.states, prob, fill_value=\"extrapolate\")\n",
    "        \n",
    "        log_likelihood = (1-i)*np.log(1-prob(x)) + i*np.log(prob(x))\n",
    "        \n",
    "        return -log_likelihood.sum()\n",
    "    \n",
    "    \n",
    "    def fit(self):\n",
    "        result = minimize(self.likelihood, [-1e-5,-3], method = 'Nelder-Mead', options={'disp': False})\n",
    "        self.theta1, self.R = result.x\n",
    "\n",
    "        \n",
    "model_hm = HotzMiller(data['replace'], data['miles'],data['miles_next'])\n",
    "model_hm.fit()\n",
    "\n",
    "\n",
    "print '\\n theta_1:%s, R:%s'%(round(model_hm.theta1,4) , round(model_hm.R,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
