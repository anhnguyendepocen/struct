{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Assignment 3: Structural Econometrics\n",
    "## Eric Schulman\n",
    "\n",
    "Solutions to ECO 388E assignment 3 at the University of Texas written by Eric Schulman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.interpolate import interp1d #pre written interpolation function\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "The dynamic program for the firm maximizing future profits is expressed below:\n",
    "\n",
    "$$V(a_t,i_t,\\epsilon_{0t},\\epsilon_{1t}) = \\pi(a_t, i_t, \\epsilon_{1t}, \\epsilon_{0t}) + max_{i_{t+1}} \\beta E(V(a_{t+1},i_{t+1},\\epsilon_{0t+1},\\epsilon_{1t+1}) |a_t, i_t; \\theta)$$\n",
    "\n",
    "Because of the conditional independence assumption $\\epsilon_{it}$ is not serially correlated.\n",
    "\n",
    "### Part 2\n",
    "\n",
    "In class, $x_t$ was continuous. Here $a_t$ is discrete. Additionally, we did not parameterize $c(x_t, \\theta)$. Here $c(a_t,\\theta) = \\theta a_t$, As a result, $c(0,\\theta) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "The code below is designed to calculate the value function using forward recursion. We determine the initial value using a contraction mapping iterating forward until it converges.\n",
    "\n",
    "The value function is a 5x2 array. The rows contain the values when the state is $a_t$. The columns contain the value based on $i_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BETA = .9\n",
    "GAMMA = .5772 #euler's constant\n",
    "\n",
    "def value_helper(a, theta1, cost, v_init):\n",
    "    \"\"\"helper function for calculating value function.\n",
    "    \n",
    "    given the value for the first period, calculate forward \n",
    "    'a' periods\"\"\"\n",
    "    if a <= 0: #initial period\n",
    "        return  v_init  \n",
    "    else:\n",
    "        v_next = value_helper(a-1, theta1, cost, v_init)\n",
    "        v_0 = a*theta1 + BETA*(GAMMA + np.log( np.exp(v_next[-1][0]) + np.exp(v_next[-1][1]) ))  \n",
    "        v_1 = cost + BETA*(GAMMA + np.log(  np.exp(v_next[-1][0]) + np.exp(v_next[-1][1]) )) \n",
    "        \n",
    "        return np.concatenate( ( v_next,[[v_0,v_1]]) )\n",
    "\n",
    "\n",
    "v = value_helper(5, -1, -3, [[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.65524822  -5.65524822]\n",
      " [ -4.65600819  -5.65600819]\n",
      " [ -6.38899185  -6.38899185]\n",
      " [ -8.60678021  -7.60678021]\n",
      " [-11.04468667  -9.04468667]]\n"
     ]
    }
   ],
   "source": [
    "def value_function(a, theta1, cost, v_init, error, maxiter):\n",
    "    \"\"\"solve for the first period of the value function\n",
    "    with the contraction mapping loop\n",
    "    \n",
    "    You can choose how far into the future it goes by setting max_periods\"\"\"\n",
    "    \n",
    "    #only need to iterate 1 periods into the future\n",
    "    v = value_helper(1, theta1, cost, v_init)\n",
    "    \n",
    "    #stop iterating when the last two periods look the same\n",
    "    while ( maxiter >= 0  \n",
    "           and ( abs(  v[1,0] - v[0,0] )  > error\n",
    "           or abs(  v[1,1] - v[0,1] )  > error) ):\n",
    "        \n",
    "        #recompute value function until convergence\n",
    "        return value_function(a, theta1, cost, [v[1,:]], error, maxiter-1)  \n",
    "    \n",
    "    return value_helper(a, theta1, cost, [v[1,:]])[1:,:]\n",
    "\n",
    "\n",
    "print value_function(5, -1, -3, [[0,0]],.001, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "* Below I solve the model when $\\theta_1 = -1$ and $R = -3$. \n",
    "\n",
    "* When $a_t = 2$, we can see that $V(2,0) - V(2,1) = 1$ so the firm chooses not to replace the engine. If the value of $\\epsilon_{0t} - \\epsilon_{1t}$ exceeds 1, then the firm will choose to replace the engine in period 2.\n",
    "\n",
    "* I calculate the probability of this difference below using the exterme value distribution.\n",
    "\n",
    "* Below I also calulate the value function when $a_t = 4$, $\\epsilon_{0t} = 1$ and $\\epsilon_{1t} =-1.5$. It is still cheaper to replace this period than to wait until period 5 to replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Value Function:\n",
      "           0         1\n",
      "0  -3.655248 -5.655248\n",
      "1  -4.656008 -5.656008\n",
      "2  -6.388992 -6.388992\n",
      "3  -8.606780 -7.606780\n",
      "4 -11.044687 -9.044687\n",
      "\n",
      "2. V(2,0) - V(2,1) = 1.0\n",
      "\n",
      "3. Likelihood: 0.2689414213699951\n",
      "\n",
      "4. PDV: -9.74610218495787\n"
     ]
    }
   ],
   "source": [
    "v = value_function(5, -1, -3, [[0,0]] , .001 , 100)\n",
    "print '1. Value Function:'\n",
    "print pd.DataFrame(v)\n",
    "\n",
    "#difference between e0 and e1\n",
    "diff = v[1,0] - v[1,1]\n",
    "print '\\n2. V(2,0) - V(2,1) = %s'%diff\n",
    "\n",
    "#probability of this different\n",
    "print '\\n3. Likelihood: %s'%( np.exp(-diff)/(1+np.exp(-diff)) )\n",
    "\n",
    "#PDV a = 4, e0= 1, e1=-1.5\n",
    "print '\\n4. PDV: %s'%np.maximum(-3 + 1 + BETA*v[3,0], -4 + -1.5 +BETA*v[3,1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 - 6 \n",
    "\n",
    "Below I calculate the value of $\\theta_1$ and $R$ and standard errors. \n",
    "\n",
    "The likelihood of $i_t$ is conditional on $a_t$ because my decision to replace this period depends on how old the engine is. The expected future costs, which I base my decision on, depend on the current age of the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into memory for part 5\n",
    "data = np.loadtxt(\"data.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.425320\n",
      "         Iterations: 55\n",
      "         Function evaluations: 104\n",
      "                                 Rust Results                                 \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -425.32\n",
      "Model:                           Rust   AIC:                             852.6\n",
      "Method:            Maximum Likelihood   BIC:                             857.5\n",
      "Date:                Wed, 19 Dec 2018                                         \n",
      "Time:                        18:56:00                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     999                                         \n",
      "Df Model:                           0                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_1       -1.3833      0.082    -16.843      0.000      -1.544      -1.222\n",
      "R             -3.3137      0.219    -15.115      0.000      -3.743      -2.884\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class Rust(GenericLikelihoodModel):\n",
    "    \"\"\"class for estimating the values of R and theta\"\"\"\n",
    "    \n",
    "    def nloglikeobs(self, params, v=False):\n",
    "        \n",
    "        theta1, R = params\n",
    "        \n",
    "        # Input our data into the model\n",
    "        i = self.exog[:,0] #reshape\n",
    "        a = self.endog.astype(int)\n",
    "        \n",
    "        #solve value function based on params\n",
    "        v = value_function(5, theta1, R, [[0,0]] , .01 , 100)\n",
    "        \n",
    "        #interpolate using scipy (easier than indexing)\n",
    "        v0 = interp1d(range(1,6), v[:,0],fill_value=\"extrapolate\")\n",
    "        v1 = interp1d(range(1,6), v[:,1],fill_value=\"extrapolate\")\n",
    "        \n",
    "        diff = v1(a) - v0(a)\n",
    "    \n",
    "        #calculate likelihood of each obs\n",
    "        pr0 = 1/(1+np.exp(diff))\n",
    "        pr1 = np.exp(diff)/(1+np.exp(diff))\n",
    "\n",
    "        likelihood = (1-i)*pr0 + i*pr1\n",
    "        return -np.log(likelihood).sum()\n",
    "    \n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=1000, maxfun=5000, **kwds):\n",
    "        if start_params == None:\n",
    "            start_params = [1,1]\n",
    "        return super(Rust, self).fit(start_params=start_params,\n",
    "                                       maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "    \n",
    "    \n",
    "model = Rust(data[:,0],data[:,1])\n",
    "\n",
    "result = model.fit()\n",
    "print(result.summary(xname=['theta_1', 'R']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7\n",
    "\n",
    "A) To accomodate $\\theta_{1A}$ and $\\theta_{2A}$ we would need to modify the dynamic program as follows\n",
    "\n",
    "$$V(a_t,i_t,\\epsilon_{jt}) = \\pi(a_t, i_t, \\epsilon_{it}) + max_{i_{t+1}} \\beta E(V(a_{t+1},i_{t+1},\\epsilon_{jt+1}) |a_t, \\epsilon_{jt}, i_t; \\theta_i)$$\n",
    "\n",
    "\n",
    "\n",
    "B) We would still have unobserved heterogeneity. However we could calculate the value of $\\epsilon_{it-1}$ and include it in the likelihood function\n",
    "\n",
    "$ L_{it} = Prob(i_{tj} | a_t, \\epsilon_{jt-1} )$\n",
    "\n",
    "C) If machines differ, then we can use fixed effects instead of making $\\epsilon_{it}$ a state variable.\n",
    "\n",
    "$L_{it} =  Prob(i_{tj} | a_t, \\alpha{j} )$. We could simulate the $\\alpha_j$'s\n",
    "\n",
    "D) One way to solve it would be simulating back to period 1\n",
    "\n",
    "E) Most there is not enough information to identify $\\lambda$ seperately from $\\alpha$\n",
    "\n",
    "### Part 8\n",
    "\n",
    "Below I estimate the model using the Hotz-Miller algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21002378]\n",
      " [0.60351455]\n",
      " [0.88742366]\n",
      " [0.97989181]\n",
      " [0.99250737]]\n"
     ]
    }
   ],
   "source": [
    "def hm_prob(a_obs, i_obs):\n",
    "    \"\"\"calculate state pr\"\"\"\n",
    "    \n",
    "    df = np.array([a_obs,i_obs]).transpose()\n",
    "    df = pd.DataFrame(df, columns=('a','i'))\n",
    "    pr_state = df.groupby('a')\n",
    "    pr_state = pr_state.count()/data.shape[0]\n",
    "\n",
    "    return  np.array(pr_state)\n",
    "    \n",
    "    \n",
    "def hm_transitions(a_max):\n",
    "    \"\"\"calculate transitions, deterministic\n",
    "    in this case\"\"\"\n",
    "    \n",
    "    trans1 = np.zeros((a_max,a_max))\n",
    "    trans1[:,0] = np.ones(a_max)\n",
    "    \n",
    "    trans0 = np.vstack( (np.identity(a_max-1), np.zeros(a_max-1)))\n",
    "    trans0 = np.hstack( ( np.zeros((a_max,1)), trans0 ))\n",
    "    trans0[a_max-1][a_max-1] = 1\n",
    "    \n",
    "    return trans0,trans1\n",
    "    \n",
    "    \n",
    "def hm_value(a_max, theta1, cost, a_obs, i_obs, pr_state):\n",
    "    \"\"\"calculate value function using hotz miller approach\"\"\"\n",
    "    #set up matrices, transition is deterministic\n",
    "    #pr_state = hm_prob(a_max, a_obs, i_obs)\n",
    "    trans0,trans1 = hm_transitions(a_max)\n",
    "            \n",
    "    #calculate value function for all state\n",
    "    denom = (np.identity(a_max) - BETA*trans0.dot(1-pr_state) - BETA*trans1.dot(pr_state))\n",
    "    \n",
    "    a = np.arange(1,a_max+1).reshape(a_max,1)\n",
    "    numer = ( (1-pr_state)*(theta1*a  + GAMMA - np.log(1-pr_state)) + \n",
    "                 pr_state*(cost+ GAMMA - np.log(pr_state) ) )\n",
    "        \n",
    "    value = np.linalg.inv(denom).dot(numer)\n",
    "    return value\n",
    "    \n",
    "    \n",
    "def hm_state_pr(a_max, theta1, cost, a_obs, i_obs, pr_state):\n",
    "    \"\"\"calculate kappa using value function\"\"\"\n",
    "    \n",
    "    value = hm_value(a_max, theta1, cost, a_obs, i_obs, pr_state)\n",
    "    trans0,trans1 = hm_transitions(a_max)\n",
    "    a = np.arange(1,a_max+1).reshape(a_max,1)\n",
    "    \n",
    "    \n",
    "    delta1 = np.exp(cost + BETA*trans1.dot(value))\n",
    "    delta0 = np.exp(a*theta1 + BETA*trans0.dot(value))\n",
    "    \n",
    "    return delta1/(delta1+delta0)\n",
    "\n",
    "\n",
    "print hm_state_pr(5, -1, -3, data[:,0], data[:,1], hm_prob(data[:,0], data[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.422985\n",
      "         Iterations: 55\n",
      "         Function evaluations: 106\n",
      "                              HotzMiller Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -422.99\n",
      "Model:                     HotzMiller   AIC:                             848.0\n",
      "Method:            Maximum Likelihood   BIC:                             852.9\n",
      "Date:                Wed, 19 Dec 2018                                         \n",
      "Time:                        19:24:55                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     999                                         \n",
      "Df Model:                           0                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_1       -0.8413      0.050    -16.858      0.000      -0.939      -0.743\n",
      "R             -3.3812      0.219    -15.408      0.000      -3.811      -2.951\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class HotzMiller(GenericLikelihoodModel):\n",
    "    \"\"\"class for estimating the values of R and theta\"\"\"\n",
    "    \n",
    "    def __init__(self, a_max, pr_state, *args, **kwargs):\n",
    "        super(HotzMiller, self).__init__( *args, **kwargs)\n",
    "        self.a_max = a_max\n",
    "        self.pr_state = pr_state\n",
    "        \n",
    "        \n",
    "    def nloglikeobs(self, params): \n",
    "        theta1, R = params\n",
    "        \n",
    "        # Input our data into the model\n",
    "        i = self.exog[:,0] #reshape\n",
    "        a = self.endog.astype(int)\n",
    "        \n",
    "        #set up hm state pr\n",
    "        state_pr = hm_state_pr(self.a_max, theta1, R, a, i, self.pr_state).transpose()[0]\n",
    "        state_pr = interp1d(range(1,self.a_max+1), state_pr,fill_value=\"extrapolate\")\n",
    "        \n",
    "        log_likelihood = i*np.log(state_pr(a)) + (1-i)*np.log(1-state_pr(a))\n",
    "        \n",
    "        return -log_likelihood.sum()\n",
    "    \n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=1000, maxfun=5000, **kwds):\n",
    "        if start_params == None:\n",
    "            start_params = [1,1]\n",
    "        return super(HotzMiller, self).fit(start_params=start_params,\n",
    "                                       maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "\n",
    "#initialize state probabilities\n",
    "pr_state = hm_prob(data[:,0],data[:,1])\n",
    "model_hm = HotzMiller(5, pr_state, data[:,0],data[:,1])\n",
    "result_hm = model_hm.fit()\n",
    "print(result_hm.summary(xname=['theta_1', 'R']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              HotzMiller Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -422.99\n",
      "Model:                     HotzMiller   AIC:                             848.0\n",
      "Method:            Maximum Likelihood   BIC:                             852.9\n",
      "Date:                Wed, 19 Dec 2018                                         \n",
      "Time:                        19:32:07                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     999                                         \n",
      "Df Model:                           0                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_1       -0.8413      0.050    -16.858      0.000      -0.939      -0.743\n",
      "R             -3.3812      0.219    -15.408      0.000      -3.811      -2.951\n",
      "==============================================================================\n",
      "yo\n",
      "[[0.242]\n",
      " [0.2  ]\n",
      " [0.192]\n",
      " [0.199]\n",
      " [0.167]]\n",
      "[[0.11953902]\n",
      " [0.36971297]\n",
      " [0.70140595]\n",
      " [0.91440097]\n",
      " [0.96120313]]\n",
      "[[10.67902464]\n",
      " [ 4.99297164]\n",
      " [ 1.03842567]\n",
      " [-0.2128002 ]\n",
      " [-0.37433162]]\n",
      "                              HotzMiller Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -484.12\n",
      "Model:                     HotzMiller   AIC:                             970.2\n",
      "Method:            Maximum Likelihood   BIC:                             975.1\n",
      "Date:                Wed, 19 Dec 2018                                         \n",
      "Time:                        19:32:07                                         \n",
      "No. Observations:                1000                                         \n",
      "Df Residuals:                     999                                         \n",
      "Df Model:                           0                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_1       -0.0888      0.093     -0.956      0.339      -0.271       0.093\n",
      "R             -1.9939      0.242     -8.240      0.000      -2.468      -1.520\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class AM():\n",
    "    \"\"\"A class for doing the AM contraction mapping\"\"\"\n",
    "    def __init__(self,a_max, data):\n",
    "        self.i = data[:,1]\n",
    "        self.a = data[:,0]\n",
    "        self.a_max = a_max\n",
    "        \n",
    "        #initilize pr using state\n",
    "        self.pr_state =  hm_prob(self.a, self.i)\n",
    "        self.model = HotzMiller(self.a_max, self.pr_state, self.a, self.i)\n",
    "        self.result = self.model.fit(disp=0)\n",
    "        self.theta1, self.cost = self.result.params\n",
    "        \n",
    "\n",
    "        \n",
    "    def iterate(self,numiter):\n",
    "        i = 0\n",
    "        \n",
    "        while(i < numiter):\n",
    "            print self.pr_state\n",
    "            self.pr_state = hm_state_pr(self.a_max, self.theta1, self.cost,\n",
    "                                        self.a, self.i, self.pr_state)\n",
    "            print self.pr_state\n",
    "            \n",
    "            self.model = HotzMiller(self.a_max, self.pr_state, self.a, self.i)\n",
    "            \n",
    "            print hm_value(self.a_max, self.theta1, self.cost,\n",
    "                                        self.a, self.i, self.pr_state)\n",
    "            \n",
    "            self.result = self.model.fit(disp=0)\n",
    "            \n",
    "            self.theta1, self.cost = self.result.params \n",
    "            \n",
    "            i = i +1\n",
    "    \n",
    "\n",
    "model_am = AM(5,data)\n",
    "print model_am.result.summary(xname=['theta_1', 'R'])\n",
    "model_am.iterate(1)\n",
    "print model_am.result.summary(xname=['theta_1', 'R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
