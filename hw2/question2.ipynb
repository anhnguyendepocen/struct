{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Structural Econometrics: Question 2\n",
    "## November 9, 2018 \n",
    "## Eric Schulman "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y      0.568393\n",
      "x1    42.537849\n",
      "x2    12.286853\n",
      "z      9.029880\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#load data into memory\n",
    "data = pd.DataFrame(data = np.genfromtxt('ps2.dat', delimiter='  '), columns=['y','x1','x2','z'])\n",
    "\n",
    "print data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a\n",
    "\n",
    "An economic story where $x_{2i}$ is correlated with $\\epsilon_i$ involves simultaneity between a woman's decision of an education level and years she wants to work. Women who intend work may select more education. If women make this decision simultaneously, you would expect correlation between $x_{2i}$ and $\\epsilon_i$ and an upward bias on $\\theta_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "\n",
    "If $x_{2i}$ is exogenous, we have $\\rho = 0$. This is because\n",
    "\n",
    "$$E(x_{2i} \\epsilon_i) = E(\\eta_i \\epsilon_i) = \\rho$$\n",
    "\n",
    "Since we believe $x_{2i}$ is endogoenous, I would expect $\\rho > 0$.  One might expect parents education to be positively related to your education (i.e. your parents can serve as a role model).\n",
    "\n",
    "Assuming that $z_i$ does not directly determine $y_i$ is the exclusion restriction. Without this restriction, $\\theta_2$ would not be identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d\n",
    "\n",
    "In order to estimate the model we must derive the likelihood function.\n",
    "\n",
    "$$p(y_i,x_{2i} | x_{1i}, z_i, \\theta) = p(x_{2i} | x_{1i}, z_i, \\theta) p(y_i | x_{1i},x_{2i}, z_i, \\theta)  = p(x_{2i} | x_{1i}, z_i, \\theta) p(y_i | x_{1i},x_{2i}, z_i, \\eta_i, \\theta)$$\n",
    "\n",
    "Preforming a change of variable of $\\eta_i$ for $x_{2i}$, we can write\n",
    "\n",
    "$$p(x_{2i} | x_{1i}, z_i, \\theta) = p(\\eta_i|x_i,z_i,\\theta)\\dfrac{dx_{2i}}{d\\eta_i} = \\phi(\\dfrac{\\eta_i}{\\sigma_\\eta})  \\dfrac{1}{\\sigma_\\eta}$$\n",
    "\n",
    "We can derive an analytic experession for  $p(y_i | x_{1i},x_{2i}, z_i, \\theta)$ below:\n",
    "\n",
    "For notational convenience let, $\\gamma_i = \\theta_2 \\eta_i + \\theta_0 + \\theta_2\\theta_3 + (\\theta_1 + \\theta_2\\theta_4) + \\theta_2\\theta_5 z_i$\n",
    "\n",
    "When $y_i =1$, we have $p(y_i | x_{1i},x_{2i}, z_i, \\theta) = 1 - P(\\epsilon_i + \\gamma_i > 0) $\n",
    "\n",
    "When $y_i = 0$, we have $p(y_i | x_{1i},x_{2i}, z_i, \\theta) =   P(\\epsilon_i + \\gamma_i > 0) $\n",
    "\n",
    "So, we have \n",
    "\n",
    "$$p(y_i | x_{1i},x_{2i}, z_i, \\theta) = (1-y_i) P(\\epsilon_i + \\gamma_i > 0) + y_i (1 - P(\\epsilon_i + \\gamma_i > 0) ) $$\n",
    "\n",
    "Using results about the distribution of conditional normals we know\n",
    "\n",
    "$\\epsilon_i|\\eta_i \\sim N(\\eta_i \\dfrac{\\rho}{\\sigma_\\eta^2}, 1 - \\dfrac{\\rho^2}{\\sigma_\\eta^2})$\n",
    "\n",
    "\n",
    "So, $p(y_i | x_{1i},x_{2i}, z_i, \\theta) = y_i (1 -\\Phi(\\dfrac{- \\gamma_i - \\frac{\\rho}{\\sigma_\\eta^2}}{1 - \\frac{\\rho^2}{\\sigma_\\eta^2}})) + (1-y_i)\\Phi(\\dfrac{- \\gamma_i - \\frac{\\rho}{\\sigma_\\eta^2}}{1 - \\frac{\\rho^2}{\\sigma_\\eta^2}}) $\n",
    "\n",
    "Now we can write\n",
    "\n",
    "$$L = \\sum_i log(p(x_{2i} | x_{1i}, z_i, \\theta)) + log(p(y_i | x_{1i},x_{2i}, z_i, \\eta_i, \\theta))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2.765785\n",
      "         Iterations: 1171\n",
      "         Function evaluations: 1699\n",
      "                                part_d Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:            ['y', 'x2']   Log-Likelihood:                -2082.6\n",
      "Model:                         part_d   AIC:                             4169.\n",
      "Method:            Maximum Likelihood   BIC:                             4179.\n",
      "Date:                Wed, 07 Nov 2018                                         \n",
      "Time:                        14:46:51                                         \n",
      "No. Observations:                 753                                         \n",
      "Df Residuals:                     751                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_0       -0.3913      0.641     -0.611      0.541      -1.647       0.864\n",
      "theta_1       -0.0100      0.006     -1.688      0.091      -0.022       0.002\n",
      "theta_2        0.0808      0.043      1.863      0.063      -0.004       0.166\n",
      "theta_3        9.1254      0.492     18.544      0.000       8.161      10.090\n",
      "theta_4       -0.0031      0.009     -0.342      0.732      -0.021       0.015\n",
      "theta_5        0.3649      0.024     15.167      0.000       0.318       0.412\n",
      "rho            0.1172      0.190      0.615      0.538      -0.256       0.491\n",
      "sigma          1.9799      0.051     38.807      0.000       1.880       2.080\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class part_d(GenericLikelihoodModel):\n",
    "    \"\"\"class for evaluating question 1 part b\"\"\"\n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        \"\"\"evaluate the likelihood function as derived above\"\"\"\n",
    "        t0,t1,t2,t3,t4,t5,rho,sigma = params\n",
    "\n",
    "        y,x2 = self.endog.transpose()\n",
    "        x1,z = self.exog.transpose()\n",
    "        \n",
    "        eta = x2 - t3 - t4*x1 - t5*z\n",
    "        \n",
    "        mu_epsilon = (rho/sigma**2)*eta\n",
    "        var_epsilon = np.sqrt( abs(1 - (rho/sigma)**2) )\n",
    "        \n",
    "        #pr(eta | ... )\n",
    "        pr_eta = norm(0,sigma).pdf(eta)\n",
    "        \n",
    "        #pr(y|x2 ... )\n",
    "        gamma = t0 + t2*t3 + (t1 + t2*t4)*x1 + t2*t5*z + t2*eta\n",
    "        \n",
    "        pr_epsilon = (y*(1 - norm(mu_epsilon,var_epsilon).cdf(-gamma))\n",
    "                      + (1-y)*norm(mu_epsilon,var_epsilon).cdf(-gamma))\n",
    "        \n",
    "        likelihood = np.log( pr_epsilon*pr_eta )\n",
    "\n",
    "        return -( likelihood.sum() ) \n",
    "    \n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=2000, maxfun=5000, **kwds):\n",
    "        \"\"\"fit the likelihood function using the right start parameters\"\"\"\n",
    "        # we have one additional parameter and we need to add it for summary\n",
    "        if start_params == None:\n",
    "            start_params = [-.39,.01,.08,9.1, 0.0, .36, .11, 1.9]\n",
    "            \n",
    "        return super(part_d, self).fit(start_params=start_params,\n",
    "                                       maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "\n",
    "    \n",
    "model_d = part_d(data[['y','x2']],data[['x1','z']])\n",
    "\n",
    "result_d = model_d.fit()\n",
    "print(result_d.summary(xname=['theta_0', 'theta_1', 'theta_2',\n",
    "                              'theta_3','theta_4','theta_5',\n",
    "                              'rho', 'sigma']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part e\n",
    "\n",
    "Using results from the table above, we can see that $\\rho$ is roughly .12 and it's standard error is .19. As a result, we fail to reject the null hypothesis beyond a .50 confidence level. Either $x_{2i}$ is exogenous or $z_i$ is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part f\n",
    "\n",
    "$\\tau_i$ is a random coefficeint on $x_{2i}$ to capture a heterogenous response in labor force participation to education. Simply put, education might make a bigger difference for some people's labor force participation than others. If this is the case, you should include a random coefficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part g\n",
    "\n",
    "As in part d)\n",
    "\n",
    "$$p(y_i,x_{2i} | x_{1i}, z_i, \\theta) = p(x_{2i} | x_{1i}, z_i, \\theta) p(y_i | x_{1i},x_{2i}, z_i, \\theta)  = p(x_{2i} | x_{1i}, z_i, \\theta) p(y_i | x_{1i},x_{2i}, z_i, \\eta_i, \\theta)$$\n",
    "\n",
    "This holds because $p(x_{2i} | x_{1i}, z_i, \\tau_i, \\theta) = p(x_{2i} | x_{1i}, z_i, \\theta) $\n",
    "Now, we can write \n",
    "\n",
    "$$p(y_i | x_{1i},x_{2i}, z_i, \\eta_i, \\theta) = \\int p(y_i | x_{1i},x_{2i}, \\tau_i, z_i, \\eta_i, \\theta)p(\\tau_i)d \\tau'_i$$ and simulate to get\n",
    "\n",
    "$$p(y_i | x_{1i},x_{2i}, z_i, \\eta_i, \\theta) = \\frac{1}{S} \\sum_s p(y_i | x_{1i},x_{2i}, \\tau_{i,s}, z_i, \\eta_i, \\theta)$$\n",
    "\n",
    "We can modify $\\gamma_i(\\tau_i)$ from before to include the simulated $\\tau_i$. Specifically,\n",
    "\n",
    "$$\\gamma_i(\\tau_i) = (\\theta_2 + \\sigma_\\tau \\tau_i) \\eta_i + \\theta_0 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_3 + (\\theta_1 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_4) + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_5 z_i$$\n",
    "\n",
    "Now we can write\n",
    "\n",
    "$$L = \\sum_i log(p(x_{2i} | x_{1i}, z_i, \\theta)) + log(p(y_i | x_{1i},x_{2i}, z_i, \\eta_i, \\theta))$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$p(x_{2i} | x_{1i}, z_i, \\theta) = p(\\eta_i|x_i,z_i,\\theta)\\dfrac{dx_{2i}}{d\\eta_i} = \\phi(\\dfrac{\\eta_i}{\\sigma_\\eta})  \\dfrac{1}{\\sigma_\\eta}$$\n",
    "\n",
    "\n",
    "$$p(y_i | x_{1i},x_{2i}, z_i, \\eta_i, \\theta) = \\frac{1}{S} \\sum_s y_i (1 -\\Phi(\\dfrac{- \\gamma_i(\\tau_i) - \\frac{\\rho}{\\sigma_\\eta^2}}{1 - \\frac{\\rho^2}{\\sigma_\\eta^2}})) + (1-y_i)\\Phi(\\dfrac{- \\gamma_i(\\tau_i) - \\frac{\\rho}{\\sigma_\\eta^2}}{1 - \\frac{\\rho^2}{\\sigma_\\eta^2}})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part h\n",
    "\n",
    "\n",
    "We can use the following conditions\n",
    "\n",
    "1. $E(\\eta_i) = 0$\n",
    "2. $E(\\eta_i x_{1i}) = 0$\n",
    "3. $E(\\eta_i z_i) = 0$\n",
    "\n",
    "\n",
    "Now letting,\n",
    "\n",
    "$$E( g( x_{i1}, x_{i2}, z{i}) ) = \\frac{1}{S} \\sum \\sum_s \\textbf{1}( (\\theta_2 + \\sigma_\\tau \\tau_i) \\eta_i + \\theta_0 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_3 + (\\theta_1 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_4) + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_5 z_i  + \\epsilon_i > 0)$$\n",
    "\n",
    "Where $S$ reflects simualtions of both $\\tau_i$ and $\\epsilon_i$ using the conditional distribution of $\\epsilon_i$ derived in part d)\n",
    "\n",
    "4. $E(  y_i - g(x_{i1}, x_{i2}, z{i}) ) = 0$\n",
    "5. $E( ( y_i - g(x_{i1}, x_{i2}, z{i})) x_{1i} ) = 0$\n",
    "6. $E( ( y_i - g(x_{i1}, x_{i2}, z{i})) z_{i} ) = 0$\n",
    "\n",
    "The following moments will help idetnify $\\rho$ aand $\\sigma_\\eta$\n",
    "\n",
    "7. $E(\\eta_i x_{1i}^2) = 0$\n",
    "8. $E(\\eta_i z_i^2) = 0$\n",
    "9. $E(( y_i - g(x_{i1}, x_{i2}, z{i})) x_{1i}^2 ) = 0$\n",
    "10. $E( ( y_i - g(x_{i1}, x_{i2}, z{i})) z_{i}^2 ) = 0$\n",
    "\n",
    "From class we know that\n",
    "\n",
    "$$m^{opt}(z_i) =  E( \\dfrac{ \\partial g^{-1}(x_i,y_i,\\theta)}{\\partial \\theta} )$$\n",
    "\n",
    "Squaring $z_i$, and $x_{i1}$ are the most 'direct' way to make inferences about $\\rho$ and $\\sigma_\\eta$. This is because the squared terms interact directly with these parameters in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part i\n",
    "\n",
    "* Compared to MSM, SML will require more simulation draws because assymptotically we assume that $S \\rightarrow \\infty$. MSM is consistent reguardless of the number of simulations.  The efficiency is still related to the number of simulations. Also, technically MSM does not rely on a distributional assumption on $\\eta_i$\n",
    "\n",
    "* On the other hand, we only need to simulate $\\tau_i$ in SML. As shown in part d) we can derive an analytic distribution for the likelihood of $\\epsilon_i$ conditional on $\\eta_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part j\n",
    "\n",
    "No they are not smooth in $\\theta_2$. We could simulate $E( g( x_{i1}, x_{i2}, z{i}) )$ using importance sampling to make the functions smooth.\n",
    "\n",
    "This would involve letting\n",
    "\n",
    "$$E( g( x_{i1}, x_{i2}, z{i}) )= $$ \n",
    "\n",
    "$$ \\int \\int \\textbf{1}( (\\theta_2 + \\sigma_\\tau \\tau_i) \\eta_i + \\theta_0 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_3 + (\\theta_1 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_4) + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_5 z_i  + \\epsilon_i > 0) p(\\epsilon_i | \\eta_i ) p(\\tau_i)  d\\tau'_i d \\epsilon'_i $$\n",
    "\n",
    "$$ = \\int \\int \\textbf{1}( (\\theta_2 + \\sigma_\\tau \\tau_i) \\eta_i + \\theta_0 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_3 + (\\theta_1 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_4) + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_5 z_i  + \\epsilon_i > 0) \\dfrac{  p(\\epsilon_i | \\eta_i ) p(\\tau_i) h(\\eta_i) } {h(\\eta_i)}  d\\tau'_i d \\epsilon'_i $$\n",
    "\n",
    "Let $h(\\eta_i) = \\dfrac{1}{p(\\eta_i)}$\n",
    "\n",
    "Since $p(\\epsilon_i | \\eta_i ) = \\dfrac{p(\\epsilon_i, \\eta_i)}{p(\\eta_i)}$, \n",
    "\n",
    "$$ \\int \\int \\textbf{1}( (\\theta_2 + \\sigma_\\tau \\tau_i) \\eta_i + \\theta_0 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_3 + (\\theta_1 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_4) + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_5 z_i  + \\epsilon_i > 0) \\dfrac{p(\\epsilon_i, \\eta_i)}{p(\\eta_i)} p(\\tau_i)  d\\tau'_i d \\epsilon'_i $$\n",
    "\n",
    "Instead of simulating from  $p(\\epsilon_i | \\eta_i )$ we can simulate from $p(\\epsilon_i, \\eta_i)$\n",
    "\n",
    "$$ = \\frac{1}{S} \\sum \\sum_s  \\textbf{1}( (\\theta_2 + \\sigma_\\tau \\tau_i) \\eta_i + \\theta_0 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_3 + (\\theta_1 + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_4) + (\\theta_2+ \\sigma_\\tau \\tau_i)\\theta_5 z_i  + \\epsilon_i > 0) \\dfrac{1}{p(\\eta_i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part k\n",
    "\n",
    "This assumption may not be reasonable. If education and labor force partiticipation are simultaneously determined, then you would expect the error $\\eta_i$ to reflect this simultaneous decision. Additionally, an individual's $\\tau_i$ would influence this simultaneous decision. As a result you would expect $\\tau_i$ and $\\eta_i$ to be positively correlated and $\\sigma_\\tau$ to be biased downward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part l\n",
    "\n",
    "In order to produce consistent estimates, “ivprobit” requires\n",
    "\n",
    "* The endogenous regressors are continuous.\n",
    "* The error term inside the indicator function, $\\epsilon_i$, is homoskedastic. If it is heteroskedastic, point estimates will be inconsistent as with most other probit models.\n",
    "* ($\\epsilon_i$, $\\eta_i$) is i.i.d. multivariate normal $\\forall i$.\n",
    "\n",
    "\n",
    "This command cannot estimate the model in part f) because the estimate for $\\sigma_\\eta$ and $\\tau_i$  will depend on $x_{2i}$. As a result, including $\\tau_i$ in the model will violate our assumption about homoskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
