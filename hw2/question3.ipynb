{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into memory\n",
    "data = pd.DataFrame(data = np.genfromtxt('sim3.dat', delimiter='  '), columns=['i','t','y_t','p_t'])\n",
    "\n",
    "#set up lag\n",
    "shift_data = data[['i','y_t','p_t']]\n",
    "shift_data['t'] = data['t'] + 1\n",
    "data = data.merge(shift_data,how='left',on=['i','t'],suffixes=['','-1'])\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 19\n",
      "(19, 30, 100)\n"
     ]
    }
   ],
   "source": [
    "NSIM = 30\n",
    "T = int(data.groupby('i').count().max()['t'])#data is nicely formatted\n",
    "I = len(data.i.unique())\n",
    "\n",
    "print I, T\n",
    "\n",
    "alpha = np.random.normal(0,1 ,(NSIM, I))\n",
    "alpha = alpha.reshape( (1, NSIM, I) )\n",
    "alpha = np.tile(alpha, (T, 1,1))\n",
    "print alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index = data[['i']]\n",
    "#alpha = np.array([data.i.unique()]).transpose()\n",
    "#sims = np.random.normal(0,1 ,(len(alpha), NO_SIMS))\n",
    "#alpha =  np.concatenate( (alpha, sims), axis = 1 )\n",
    "#colnames = ['i']+ [i for i in range(20)]\n",
    "#alpha = pd.DataFrame(alpha, columns = colnames)\n",
    "#alpha = data[['i']].merge(alpha, how='left', on='i', right_index=False, suffixes=('', '_sim') )\n",
    "#alpha = np.array(alpha)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 30, 100)\n"
     ]
    }
   ],
   "source": [
    "def shape_data(x):\n",
    "    \"\"\" format data to make working with it easier\"\"\"\n",
    "    x = np.array([x])\n",
    "    x = x.reshape(I,1,T)\n",
    "    x = np.tile(x ,(1,NSIM,1)).transpose() \n",
    "    return x\n",
    "\n",
    "print shape_data(data['y_t']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.622177\n",
      "         Iterations: 113\n",
      "         Function evaluations: 200\n",
      "                                part_d Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                    y_t   Log-Likelihood:                -1182.1\n",
      "Model:                         part_d   AIC:                             2368.\n",
      "Method:            Maximum Likelihood   BIC:                             2379.\n",
      "Date:                Sun, 04 Nov 2018                                         \n",
      "Time:                        14:58:54                                         \n",
      "No. Observations:                1900                                         \n",
      "Df Residuals:                    1898                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_0       -0.8200      0.215     -3.809      0.000      -1.242      -0.398\n",
      "theta_1        0.9031      0.184      4.907      0.000       0.542       1.264\n",
      "theta_2        0.5483      0.114      4.789      0.000       0.324       0.773\n",
      "sigma          0.8634      0.099      8.685      0.000       0.669       1.058\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#fix alpha ahead of time\n",
    "\n",
    "#global variables\n",
    "\n",
    "class part_d(GenericLikelihoodModel):\n",
    "    \"\"\"class for evaluating question 3 part d\"\"\"\n",
    "    \n",
    "    def __init__(self, sims, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        super(part_d, self).__init__(*args, **kwds)\n",
    "        self.sims = sims\n",
    "    \n",
    "    def nloglikeobs(self, params, v=False):\n",
    "        t0, t1, t2, sigma = params\n",
    "        y = shape_data(self.endog)\n",
    "        \n",
    "        p = shape_data(self.exog.transpose()[0])\n",
    "        y_lag = shape_data(self.exog.transpose()[1])\n",
    "        alpha = self.sims\n",
    "        \n",
    "        #calculate the mean 'delta' for the inside good\n",
    "        U1 = np.exp(t0 + t1*p + t2*y_lag + sigma*alpha)\n",
    "     \n",
    "        #calculate ll, for each simulation\n",
    "        like =  y*U1/(1+U1) + (1-y)/(1+U1)\n",
    "        like =  1./NSIM * (like.prod(axis=0)).sum(axis=0)\n",
    "        like = np.log(like).sum(axis = 0)\n",
    "\n",
    "        if v: raise Exception('Stop drop and roll')\n",
    "        return - like\n",
    "\n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=1000, maxfun=5000, **kwds):\n",
    "        # we have one additional parameter and we need to add it for summary\n",
    "        if start_params == None:\n",
    "            start_params = [-.798,.5,.5,.5]\n",
    "        return super(part_d, self).fit(start_params=start_params,\n",
    "                                       maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "    \n",
    "\n",
    "model_d = part_d(alpha, data['y_t'] ,data[['p_t','y_t-1']])\n",
    "\n",
    "result_d = model_d.fit()\n",
    "print(result_d.summary(xname=['theta_0', 'theta_1', 'theta_2', 'sigma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.643884\n",
      "         Iterations: 84\n",
      "         Function evaluations: 148\n",
      "                                part_f Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                    y_t   Log-Likelihood:                -1223.4\n",
      "Model:                         part_f   AIC:                             2451.\n",
      "Method:            Maximum Likelihood   BIC:                             2462.\n",
      "Date:                Thu, 25 Oct 2018                                         \n",
      "Time:                        16:31:57                                         \n",
      "No. Observations:                1900                                         \n",
      "Df Residuals:                    1898                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_0       -0.9758      0.183     -5.339      0.000      -1.334      -0.618\n",
      "theta_1        0.7079      0.169      4.201      0.000       0.378       1.038\n",
      "theta_2        1.0602      0.097     10.920      0.000       0.870       1.251\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class part_f(GenericLikelihoodModel):\n",
    "    \"\"\"class for evaluating question 3 part f\"\"\"\n",
    "    \n",
    "    def nloglikeobs(self, params, v=False):\n",
    "        t0, t1, t2 = params\n",
    "        y = self.endog\n",
    "        p,y_lag = self.exog.transpose()\n",
    "    \n",
    "        #calculate the mean 'delta' for the inside good\n",
    "        U1 = t0 + t1*p + t2*y_lag\n",
    "        U1 = np.exp(U1)\n",
    "        \n",
    "        #calculate ll, for each simulation\n",
    "        likelihood_sims = np.log(y*U1/(1+U1) + (1-y)/(1+U1))\n",
    "        likelihood = likelihood_sims.sum(axis=0)\n",
    "        \n",
    "        if v: raise Exception('Stop drop and roll')\n",
    "        return - likelihood.sum()\n",
    "\n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=1000, maxfun=5000, **kwds):\n",
    "        # we have one additional parameter and we need to add it for summary\n",
    "        if start_params == None:\n",
    "            start_params = [-.948,.5,.5]\n",
    "        return super(part_f, self).fit(start_params=start_params,\n",
    "                                       maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "    \n",
    "\n",
    "model_f = part_f(data['y_t'],data[['p_t','y_t-1']])\n",
    "\n",
    "result_f = model_f.fit()\n",
    "print(result_f.summary(xname=['theta_0', 'theta_1', 'theta_2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
