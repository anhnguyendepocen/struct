{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into memory\n",
    "data1 = np.genfromtxt('data1.dat', delimiter='  ')\n",
    "data1 = data1.transpose()\n",
    "\n",
    "#partition correctly\n",
    "y = data1[0]\n",
    "x = sm.add_constant(data1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.799\n",
      "Model:                            OLS   Adj. R-squared:                  0.799\n",
      "Method:                 Least Squares   F-statistic:                     1979.\n",
      "Date:                Thu, 27 Sep 2018   Prob (F-statistic):          1.33e-175\n",
      "Time:                        17:53:51   Log-Likelihood:                -362.72\n",
      "No. Observations:                 500   AIC:                             729.4\n",
      "Df Residuals:                     498   BIC:                             737.9\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0055      0.022      0.245      0.807      -0.039       0.050\n",
      "x1             1.0105      0.023     44.486      0.000       0.966       1.055\n",
      "==============================================================================\n",
      "Omnibus:                        0.044   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.978   Jarque-Bera (JB):                0.120\n",
      "Skew:                           0.002   Prob(JB):                        0.942\n",
      "Kurtosis:                       2.924   Cond. No.                         1.09\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#part a - estimate using OLS\n",
    "part_a = sm.OLS(y,x).fit()\n",
    "print part_a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.725432\n",
      "         Iterations: 69\n",
      "         Function evaluations: 131\n",
      "                                part_b Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -362.72\n",
      "Model:                         part_b   AIC:                             727.4\n",
      "Method:            Maximum Likelihood   BIC:                             731.6\n",
      "Date:                Thu, 27 Sep 2018                                         \n",
      "Time:                        17:53:52                                         \n",
      "No. Observations:                 500                                         \n",
      "Df Residuals:                     499                                         \n",
      "Df Model:                           0                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_1        0.0055      0.022      0.246      0.806      -0.038       0.049\n",
      "theta_2        1.0105      0.023     44.572      0.000       0.966       1.055\n",
      "sigma          0.4999      0.016     31.619      0.000       0.469       0.531\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#part b - MLE\n",
    "\n",
    "class part_b(GenericLikelihoodModel):\n",
    "    \"\"\"class for evaluating question 1 part b\"\"\"\n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        t1, t2, sigma = params\n",
    "        endog, exog = self.endog, self.exog.squeeze()\n",
    "        eps = endog - t1 - t2*exog\n",
    "        return - norm(0,sigma).logpdf(eps).sum()\n",
    "    \n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n",
    "        # we have one additional parameter and we need to add it for summary\n",
    "        if start_params == None:\n",
    "            start_params = start_params = [.5, .5,.5]\n",
    "        return super(part_b, self).fit(start_params=start_params,\n",
    "                                       maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "\n",
    "    \n",
    "model_b = part_b(data1[0],data1[1])\n",
    "result_b = model_b.fit()\n",
    "print(result_b.summary(xname=['theta_1', 'theta_2', 'sigma']))\n",
    "\n",
    "\n",
    "#sources: \n",
    "#http://www.statsmodels.org/0.6.1/examples/notebooks/generated/generic_mle.html\n",
    "#http://rlhick.people.wm.edu/posts/estimating-custom-mle.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 37\n",
      "         Function evaluations: 70\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 13\n",
      "         Function evaluations: 26\n",
      "                                part_c Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Hansen J:                    1.288e-06\n",
      "Model:                         part_c   Prob (Hansen J):                   nan\n",
      "Method:                           GMM                                         \n",
      "Date:                Thu, 27 Sep 2018                                         \n",
      "Time:                        17:53:53                                         \n",
      "No. Observations:                 500                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_1        0.0055      0.022      0.248      0.804      -0.038       0.049\n",
      "theta_2        1.0104      0.022     45.052      0.000       0.966       1.054\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#part c - GMM\n",
    "\n",
    "class part_c(GMM):\n",
    "    \"\"\"class for evaluating question 1 part c\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        kwds.setdefault('k_moms', 2)\n",
    "        kwds.setdefault('k_params',2)\n",
    "        super(part_c, self).__init__(*args, **kwds)\n",
    "    \n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=10000, **kwds):\n",
    "        if start_params == None:\n",
    "            start_params = np.array([.5, .5])\n",
    "        return super(part_c, self).fit(start_params=start_params,\n",
    "                                       maxiter=maxiter,  **kwds)\n",
    "    \n",
    "    \n",
    "    def momcond(self, params):\n",
    "        t1,t2 = params  #unwrap parameters\n",
    "        endog, exog = self.endog, self.exog.squeeze()\n",
    "        eps = endog - t1 - t2*exog \n",
    "        g = np.column_stack( (eps, eps*exog ))\n",
    "        return g \n",
    "\n",
    "    \n",
    "model_c = part_c(data1[0],data1[1], None)\n",
    "result_c = model_c.fit(maxiter=2, optim_method='nm', wargs=dict(centered=False))\n",
    "print(result_c.summary(xname=['theta_1', 'theta_2']))\n",
    "\n",
    "\n",
    "#sources:\n",
    "#https://github.com/josef-pkt/misc/blob/master/notebooks/ex_gmm_gamma.ipynb\n",
    "#https://www.statsmodels.org/dev/generated/statsmodels.sandbox.regression.gmm.GMM.html#statsmodels.sandbox.regression.gmm.GMM\n",
    "#https://gist.github.com/josef-pkt/6895915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
