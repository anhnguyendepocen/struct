{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from statsmodels.base.model import GenericLikelihoodModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.genfromtxt('data2.dat', delimiter='  ')\n",
    "data2 = data2.transpose()\n",
    "\n",
    "y = data2[0]\n",
    "x = sm.add_constant(data2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.381592\n",
      "         Iterations: 188\n",
      "         Function evaluations: 335\n",
      "                                part_b Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -138.16\n",
      "Model:                         part_b   AIC:                             278.3\n",
      "Method:            Maximum Likelihood   BIC:                             280.9\n",
      "Date:                Thu, 20 Sep 2018                                         \n",
      "Time:                        17:55:22                                         \n",
      "No. Observations:                 100                                         \n",
      "Df Residuals:                      99                                         \n",
      "Df Model:                           0                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             3.0660      0.187     16.377      0.000       2.699       3.433\n",
      "constant       1.0270      0.229      4.488      0.000       0.579       1.476\n",
      "sigma          0.9634      0.068     14.141      0.000       0.830       1.097\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#part b - MLE\n",
    "#http://www.statsmodels.org/0.6.1/examples/notebooks/generated/generic_mle.html\n",
    "#http://rlhick.people.wm.edu/posts/estimating-custom-mle.html\n",
    "\n",
    "\n",
    "class part_b(GenericLikelihoodModel):\n",
    "    \n",
    "    def nloglikeobs(self, params):\n",
    "        t1, t2, sigma = params\n",
    "        endog = self.endog\n",
    "        exog = self.exog.squeeze()\n",
    "        eps = np.log(endog) - t1 - exog**t2\n",
    "        return - norm(0,sigma).logpdf(eps).sum()\n",
    "    \n",
    "    def fit(self, start_params=None, maxiter=10000, maxfun=5000, **kwds):\n",
    "        # we have one additional parameter and we need to add it for summary\n",
    "        self.exog_names.append('constant')\n",
    "        self.exog_names.append('sigma')\n",
    "        if start_params == None:\n",
    "            # Reasonable starting values\n",
    "            start_params = np.append(np.zeros(self.exog.shape[1]), [.5,.5])\n",
    "        return super(part_b, self).fit(start_params=start_params, maxiter=maxiter, maxfun=maxfun, **kwds)\n",
    "\n",
    "    \n",
    "model_b = part_b(data2[0],data2[1])\n",
    "result_b = model_b.fit()\n",
    "print(result_b.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 52\n",
      "         Function evaluations: 98\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 22\n",
      "         Function evaluations: 45\n",
      "                                part_c Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Hansen J:                    1.697e-08\n",
      "Model:                         part_c   Prob (Hansen J):                   nan\n",
      "Method:                           GMM                                         \n",
      "Date:                Thu, 20 Sep 2018                                         \n",
      "Time:                        15:37:14                                         \n",
      "No. Observations:                 100                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "theta_1        3.0573      0.186     16.425      0.000       2.693       3.422\n",
      "theta_2        1.0394      0.216      4.814      0.000       0.616       1.463\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#part c - GMM\n",
    "#https://github.com/josef-pkt/misc/blob/master/notebooks/ex_gmm_gamma.ipynb\n",
    "#https://www.statsmodels.org/dev/generated/statsmodels.sandbox.regression.gmm.GMM.html#statsmodels.sandbox.regression.gmm.GMM\n",
    "#https://gist.github.com/josef-pkt/6895915\n",
    "\n",
    "\n",
    "class part_c(GMM):\n",
    "    def __init__(self, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        kwds.setdefault('k_moms', 2)\n",
    "        kwds.setdefault('k_params',2)\n",
    "        super(part_c, self).__init__(*args, **kwds)\n",
    "\n",
    "    def momcond(self, params):\n",
    "        t1,t2 = params   \n",
    "        #unwrap endog\n",
    "        endog = self.endog\n",
    "        exog = self.exog.squeeze()\n",
    "        eps =  np.log(endog) -t1 - exog**t2\n",
    "        g = np.column_stack( (eps, eps*exog ))\n",
    "        return g \n",
    "\n",
    "    \n",
    "model_c = part_c(data2[0],data2[1], None)\n",
    "beta0 = np.array([1, 1])\n",
    "model_c.set_param_names(['theta_1','theta_2'])\n",
    "result_c = model_c.fit(beta0, maxiter=2, optim_method='nm', wargs=dict(centered=False))\n",
    "print(result_c.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
