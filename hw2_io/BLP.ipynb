{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    \"\"\"pre-processing to calculate outside good shares\"\"\"\n",
    "    shares = data[['Market_ID',name]].copy()\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data = comp_outside_good(data,'Inside Good Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data(data):\n",
    "    \"\"\"simplify setting up data correctly\"\"\"\n",
    "    #set up x and y\n",
    "    y = data[['Inside Good Share','Outside Good Share']]\n",
    "    x =  data[['Network Score','Satisfaction Score','PPO','Premium']]\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def setup_hausman(data):\n",
    "    #calculate hausmann insturments\n",
    "    price = data['Premium']\n",
    "    mkt_dum = pd.get_dummies(data['Market_ID'],prefix='mkt',drop_first=True)\n",
    "    plan_dum = pd.get_dummies(data['Plan_ID'],prefix='plan',drop_first=True)\n",
    "    exog = np.array( data[['Network Score','Satisfaction Score', 'PPO']])\n",
    "    \n",
    "    #calc avg price in other markets\n",
    "    hausman_mod1 = sm.OLS(price, sm.add_constant(plan_dum))\n",
    "    hausman_fit1 = hausman_mod1.fit()\n",
    "    hausman_instr1 = hausman_fit1.fittedvalues\n",
    "    hausman_instr1 = np.array([hausman_instr1]).transpose()\n",
    "    \n",
    "    #no of competitors\n",
    "    BLP_instr = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "    BLP_instr =  pd.merge(data[['Market_ID','Plan_ID']],\n",
    "                        BLP_instr[['Plan_ID']], right_index=True, left_on = 'Market_ID')\n",
    "    BLP_instr = np.array([BLP_instr['Plan_ID_y']]).transpose()\n",
    "    \n",
    "    #average characteristics among competititors\n",
    "    BLP_instr2 = data[['Market_ID','Network Score','Satisfaction Score']].groupby('Market_ID').mean()\n",
    "    BLP_instr2 =  pd.merge(data[['Market_ID']],\n",
    "                        BLP_instr2[['Network Score','Satisfaction Score']], right_index=True, left_on = 'Market_ID')\n",
    "    BLP_instr2 = (np.array(BLP_instr2)[:,1:]*BLP_instr - exog[:,:-1])/(BLP_instr-1)\n",
    "    \n",
    "    #concat hausman instr with exog variables\n",
    "    instr = np.concatenate( (exog, hausman_instr1, BLP_instr2), axis =1 )\n",
    "    \n",
    "    return instr\n",
    "\n",
    "\n",
    "#pre process for testing\n",
    "x,y =  setup_data(data)\n",
    "z = setup_hausman(data)\n",
    "T =  np.linalg.inv( z.transpose().dot(z) ) #set up initial weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 16 3300\n"
     ]
    }
   ],
   "source": [
    "#set up useful global variables \n",
    "NMKTS = data['Market_ID'].nunique()\n",
    "NPLANS = data['Plan_ID'].nunique()\n",
    "NOBS = data['Plan_ID'].count()\n",
    "NSIM = 50\n",
    "\n",
    "theta1 = np.array([4,1.5,.7,-1.5])\n",
    "theta2 = np.array([2,2,1]) # initialize theta2 for testing purposes\n",
    "delta = np.ones(NOBS)*(-2)\n",
    "\n",
    "#print global variables\n",
    "print NMKTS,NPLANS,NOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up random draws v\n",
    "v = np.random.normal(size=(NSIM,3)) #same simulation for all markets\n",
    "np.savetxt(\"simulations.csv\", v, delimiter=\",\")\n",
    "\n",
    "#use same simulations each time\n",
    "v = np.genfromtxt('simulations.csv', delimiter=',')\n",
    "v = np.tile(v.reshape(NSIM,3,1) , (1,1,NOBS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating $\\delta_{jt}$, $\\xi_{jt}$\n",
    "\n",
    "The first part of the estimation involves calculating the mean utility with the BLP inversion and the mean unobservable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sim_s(data, v, delta, theta2):\n",
    "    \"\"\"calculate market share for each simulated consumer\"\"\"\n",
    "    \n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO']]).transpose()\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1,3300))\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() ) \n",
    "    \n",
    "    #sum up between markets\n",
    "    sim_exp['mkt_id'] = data['Market_ID']\n",
    "    sum_exp = sim_exp.groupby('mkt_id').sum() \n",
    "    sum_exp = pd.merge(data.copy()[['Market_ID']], sum_exp, \n",
    "                       right_index=True, left_on = 'Market_ID')\n",
    "    \n",
    "    #format so I can broadcast\n",
    "    sim_exp = np.array(sim_exp).transpose()[:-1]\n",
    "    sum_exp = np.array(sum_exp).transpose()[1:] + 1\n",
    "    \n",
    "    return sim_exp/sum_exp\n",
    "\n",
    "\n",
    "def cal_s(data, v, delta, theta2):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates individual choice probability first, then take sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*cal_sim_s(data, v, delta, theta2).sum(axis=0)\n",
    "    return shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_delta(data, v, theta2, error = 1e-3, maxiter = 500):\n",
    "    \"\"\"Calculate mean utility via contraction mapping\"\"\"\n",
    "\n",
    "    niter = 0\n",
    "    \n",
    "    #initialize loop parameters\n",
    "    delta = np.zeros(NOBS)\n",
    "    s = cal_s(data, v, delta, theta2)\n",
    "    diff = np.log(data['Inside Good Share']) - np.log(s)\n",
    "    \n",
    "    \n",
    "    while ((abs(diff).max() > 1e-6) #this is easier to converge\n",
    "           and (abs(diff).mean() > error) \n",
    "           and niter < maxiter):\n",
    "        \n",
    "        s = cal_s(data, v, delta, theta2)\n",
    "        diff = np.log(data['Inside Good Share']) - np.log(s)\n",
    "\n",
    "        if np.isnan(diff).sum():\n",
    "            raise Exception('nan in diffs')\n",
    "            \n",
    "        delta += diff\n",
    "        niter += 1\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_xi(data, delta, theta1):\n",
    "    \"\"\"Calculate xi with F.O.C\"\"\"\n",
    "    x,y =  setup_data(data)\n",
    "    xi = np.matmul(np.array(x),theta1)\n",
    "    xi = delta - np.matmul(np.array(x),theta1)\n",
    "    return  xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating  $\\theta_1,\\theta_2$\n",
    "\n",
    "Here $\\theta_1 = (\\alpha, \\beta)$\n",
    "\n",
    "I only solve GMM over $\\theta_2$, the non-linear parameters. $\\theta_1$ is calculated as a function of $\\delta$ using the formula from Nevo 2000\n",
    "\n",
    "$$\\hat{\\theta_1} = (X'Z V^{-1} Z'X)^{-1} X'Z V^{-1} Z' \\delta(\\hat{\\theta}_2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_theta1(data, delta, z, T):\n",
    "    \"\"\"  calculate theta_1 using FOCs \n",
    "    \n",
    "    (X1'Z T Z'X )^-1 X1'Z T Z' delta \"\"\"\n",
    "    \n",
    "    #set up variables\n",
    "    x,y =  setup_data(data)\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    \n",
    "    #build up to main equation\n",
    "    XtZ = X.transpose().dot(Z)\n",
    "    ZtX = Z.transpose().dot(X)\n",
    "        \n",
    "    first_exp = np.linalg.inv( XtZ.dot(T).dot(ZtX))\n",
    "    second_exp = XtZ.dot(T).dot(Z.transpose()).dot(delta)\n",
    "    theta1 = first_exp.dot(second_exp)\n",
    "    return theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 59\n",
      "         Function evaluations: 106\n",
      "[2.35030545 1.09668885 1.0389929 ]\n"
     ]
    }
   ],
   "source": [
    "def gmm_objective(theta2_init, data,  v, z,  T):\n",
    "    \"\"\"calculate the GMM objective and minimize it to find theta_2\n",
    "    \n",
    "    I use the formula from Nevo 2000: w' z phi-1 z' w, of theta2\"\"\"\n",
    "    \n",
    "    #set up variables\n",
    "    x,y =  setup_data(data)\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    \n",
    "    #do calculations\n",
    "    delta = cal_delta(data, v, theta2_init)\n",
    "    theta1 = cal_theta1(data, delta, z, T)\n",
    "    xi = cal_xi(data, delta, theta1)\n",
    "        \n",
    "    xitZ = xi.transpose().dot(Z)\n",
    "    Ztxi = Z.transpose().dot(xi)\n",
    "    return xitZ.dot(T).dot(Ztxi)\n",
    "    \n",
    "\n",
    "def calc_theta2(data, v, z, T, theta2_init,NM=True):\n",
    "    \"\"\"calculate theta2 using scipy\"\"\"\n",
    "    if NM:\n",
    "        theta2 = minimize(gmm_objective, theta2_init, args=(data,  v, z, T), method='Nelder-Mead',\n",
    "                      options={'maxiter':100, 'disp': True})\n",
    "    else:\n",
    "        theta2 = minimize(gmm_objective, theta2_init, args=(data,  v, z, T), method='BFGS',\n",
    "                      options={'maxiter':100, 'disp': True})\n",
    "    return abs(theta2.x)\n",
    "\n",
    "\n",
    "theta2_init = np.array([2,2,1])\n",
    "theta2_test = calc_theta2(data, v, z, T, theta2_init)\n",
    "print theta2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 59\n",
      "         Function evaluations: 106\n",
      "Warning: Maximum number of iterations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "theta2_init = np.array([2,2,1])\n",
    "\n",
    "def calc_theta(data, v, theta2_init, stages=2):\n",
    "    \"\"\"put everything together to calculate theta1 and theta2\"\"\"\n",
    "    #initialize theta\n",
    "    x,y =  setup_data(data)\n",
    "    z = setup_hausman(data)\n",
    "    \n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    theta2 = theta2_init \n",
    "    \n",
    "    #on first step, use consistent approximation of T\n",
    "    T =  np.linalg.inv( z.transpose().dot(z) )\n",
    "    for i in range(stages):  \n",
    "       \n",
    "        #on second use T using estimated xi\n",
    "        if i==1:\n",
    "            xi = cal_xi(data, delta, theta1)\n",
    "            xi =np.array([xi]).transpose()\n",
    "            T =  np.linalg.inv( Z.transpose().dot(xi).dot(xi.transpose()).dot(Z) )\n",
    "        \n",
    "        theta2 = calc_theta2(data, v, z, T, theta2)\n",
    "        delta = cal_delta(data, v, theta2)\n",
    "        theta1 = cal_theta1(data, delta, z, T)\n",
    "        \n",
    "    return theta1, theta2\n",
    "\n",
    "theta = calc_theta(data, v, theta2_init, stages=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Mean Coefficients \n",
      "------------------------------------------------------------------\n",
      "               0                   1         2        3\n",
      "0  Network Score  Satisfaction Score       PPO  Premium\n",
      "1        3.79293             1.95861  0.757348 -1.47437\n",
      "------------------------------------------------------------------\n",
      "Coefficients Variance\n",
      "------------------------------------------------------------------\n",
      "               0                   1        2        3\n",
      "0  Network Score  Satisfaction Score      PPO  Premium\n",
      "1        2.47703             1.15401  1.00765     None\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '------------------------------------------------------------------'\n",
    "print 'Mean Coefficients \\n------------------------------------------------------------------'\n",
    "labels1 = np.array(['Network Score','Satisfaction Score','PPO','Premium'])\n",
    "print pd.DataFrame([labels1, theta[0]])\n",
    "print '------------------------------------------------------------------'\n",
    "\n",
    "print 'Coefficients Variance'\n",
    "print '------------------------------------------------------------------'\n",
    "print pd.DataFrame([labels1, theta[1]])\n",
    "print '------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 3.79292846,  1.95860809,  0.75734848, -1.47436869]), array([2.47702906, 1.15401209, 1.00765258]))\n"
     ]
    }
   ],
   "source": [
    "#save xi and write to array for counterfactuals\n",
    "theta1_est, theta2_est = theta\n",
    "\n",
    "delta_est = cal_delta(data, v, theta2_est)\n",
    "xi_est = cal_xi(data, delta_est, theta1_est)\n",
    "\n",
    "np.savetxt(\"xi.csv\", xi_est, delimiter=\",\")\n",
    "\n",
    "print theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Standard Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_est = np.genfromtxt('xi.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5021.1258       4852.1624       2835.98        14187.78264965\n",
      "   -6720.05475434  -1731.98368468   -741.09270424]\n",
      " [  4852.1624       4699.4479       2761.          13718.10290336\n",
      "   -6516.68203394  -1679.88138559   -718.87113135]\n",
      " [  2835.98         2761.           3264.           8387.8559376\n",
      "   -4518.38608104  -1202.2355337    -533.02213833]\n",
      " [ 14187.78264966  13718.10290336   8387.8559376   40211.44573277\n",
      "  -19100.3816671   -4931.36843788  -2113.94108161]\n",
      " [  5010.9612281    4843.1040044    2846.08735714  14180.91738933\n",
      "   -6676.36153238  -1721.1326148    -736.43287084]\n",
      " [  4843.1040044    4680.01280929   2748.45621429  13704.74400926\n",
      "   -6448.20050992  -1662.23238569   -711.2147752 ]]\n"
     ]
    }
   ],
   "source": [
    "def calc_s_delta(data, v, theta, xi):\n",
    "    \"\"\"calculate derivate wrt delta\"\"\"\n",
    "    theta1,theta2 = theta\n",
    "    \n",
    "    delta = cal_delta(data, v, theta2)\n",
    "    \n",
    "    sim_shares = cal_sim_s(data, v, delta, theta2)\n",
    "    cross_deriv = np.zeros((NOBS,NOBS))\n",
    "    for sim_share in sim_shares:\n",
    "        sim_share = sim_share.reshape((NOBS,1))\n",
    "        cross_deriv = cross_deriv + sim_share.dot(sim_share.transpose())\n",
    "        \n",
    "    own = np.identity(NOBS)\n",
    "    cross = (1 - own)\n",
    "    own_deriv  = -(1-sim_shares) * sim_shares\n",
    "    own_deriv = own_deriv.sum(axis=0)\n",
    "    \n",
    "    sim_deriv = 1./(NSIM) * (cross_deriv*cross +own_deriv*own )\n",
    "    return sim_deriv\n",
    "  \n",
    "\n",
    "    return np.ones((NOBS,NOBS))\n",
    "\n",
    "\n",
    "def calc_s_sigma_k(k, data, v, theta, xi):\n",
    "    \"\"\"calculate derivate wrt delta\n",
    "    \n",
    "    \n",
    "    return type should by 3300 x 3\n",
    "    \"\"\"\n",
    "    theta1,theta2 = theta\n",
    "    delta = cal_delta(data, v, theta2)\n",
    "    sim_shares = cal_sim_s(data, v, delta, theta2)\n",
    "    x,y =  setup_data(data)\n",
    "    vk = v[:,k,:]\n",
    "    xk = np.array(x)[:,k]\n",
    "    \n",
    "    deriv_k = np.zeros(NOBS)\n",
    "    for s in range(NSIM): #THIS IS A BUG PLEASE FIX IT\n",
    "        \n",
    "        #sum up between markets\n",
    "        inner = pd.DataFrame( (xk*sim_shares[s]).transpose() )\n",
    "        inner['mkt_id'] = data['Market_ID']\n",
    "        inner = inner.groupby('mkt_id').sum()\n",
    "        inner = pd.merge(data.copy()[['Market_ID']], inner, \n",
    "            right_index=True, left_on = 'Market_ID')\n",
    "        inner = np.array(inner[0])\n",
    "        outer = vk[s]*sim_shares[s]*(xk - inner)\n",
    "\n",
    "        deriv_k = deriv_k + outer\n",
    "    \n",
    "    s_sigma  = 1./NSIM * deriv_k\n",
    "    return s_sigma \n",
    "\n",
    "\n",
    "\n",
    "def calc_s_sigma( data, v, theta, xi):\n",
    "    s_sigma = []\n",
    "    for k in range(3):\n",
    "        s_sigma_k = calc_s_sigma_k(k, data, v, theta, xi)\n",
    "        s_sigma.append( s_sigma_k )\n",
    "    s_sigma = np.array( s_sigma )\n",
    "    return s_sigma.transpose()\n",
    "\n",
    "\n",
    "\n",
    "def gradient(data, v, theta, xi):\n",
    "    \"\"\"function for analytically computing gradient\n",
    "    following Nevo's appendix\"\"\"\n",
    "    \n",
    "    xi =np.array([xi]).transpose()\n",
    "    x,y =  setup_data(data)\n",
    "    z = setup_hausman(data)\n",
    "    \n",
    "    #set up weight matrices\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    V = np.linalg.inv( Z.transpose().dot(xi).dot(xi.transpose()).dot(Z) )\n",
    "    \n",
    "    \n",
    "    #set up derivative matrix\n",
    "    s_delta = calc_s_delta(data, v, theta, xi)\n",
    "    s_sigma = calc_s_sigma(data, v, theta, xi)\n",
    "    D_theta2 = s_delta.dot(s_sigma)\n",
    "    D_theta1 = X # do not include prices as this is endogenous?\n",
    "    \n",
    "    D = np.concatenate( (D_theta1,D_theta2), axis=1)\n",
    "    \n",
    "    return (2*(D.transpose()).dot(z)).transpose()\n",
    "    \n",
    "\n",
    "gamma = gradient(data, v, theta, xi_est)\n",
    "\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 7)\n"
     ]
    }
   ],
   "source": [
    "print gamma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I have calculated standard errors using the formula $$(\\Gamma' A \\Gamma)^{-1}(\\Gamma' A V A \\Gamma)^{-1} (\\Gamma' A \\Gamma)^{-1}$$\n",
    "\n",
    "Where $\\Gamma$ is a numeric approximation of the gradient $A$ is the initial weighting matrix and $V$ is the covaraince matrix (also the optimal weight matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_standard_errors(theta, xi, data,  v):\n",
    "    #set up variables\n",
    "    xi =np.array([xi]).transpose()\n",
    "    x,y =  setup_data(data)\n",
    "    z = setup_hausman(data)\n",
    "    \n",
    "    #set up weight matrices\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    V = Z.transpose().dot(xi).dot(xi.transpose()).dot(Z)\n",
    "    A =  z.transpose().dot(z)\n",
    "    #G = gradient(theta, data,  v, z, h=1e-6)\n",
    "    G = gamma\n",
    "    GAG_inv =  np.linalg.inv( G.transpose().dot(A).dot(G) )\n",
    "    GAVAG = G.transpose().dot(A).dot(V).dot(A).dot(G)\n",
    "    return GAG_inv.dot(GAVAG).dot(GAG_inv)\n",
    "\n",
    "se = cal_standard_errors(theta, xi_est, data,  v)/NOBS\n",
    "\n",
    "se1 = np.diagonal(se)[:4]\n",
    "se2 = np.diagonal(se)[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the standard errors calculated using the formula. The are high from, rounding error from calculating the gradient numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Mean Coefficients (Standard Error) \n",
      "------------------------------------------------------------------\n",
      "               0                   1        2        3\n",
      "0  Network Score  Satisfaction Score      PPO  Premium\n",
      "1         34.769             195.378  12.0389 -3.51987\n",
      "------------------------------------------------------------------\n",
      "Coefficients Variance (Standard Error)\n",
      "------------------------------------------------------------------\n",
      "               0                   1       2        3\n",
      "0  Network Score  Satisfaction Score     PPO  Premium\n",
      "1       -7604.69             2739.24  452893     None\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '------------------------------------------------------------------'\n",
    "print 'Mean Coefficients (Standard Error) \\n------------------------------------------------------------------'\n",
    "labels1 = np.array(['Network Score','Satisfaction Score','PPO','Premium'])\n",
    "print pd.DataFrame([labels1, se1])\n",
    "print '------------------------------------------------------------------'\n",
    "\n",
    "print 'Coefficients Variance (Standard Error)'\n",
    "print '------------------------------------------------------------------'\n",
    "print pd.DataFrame([labels1,se2])\n",
    "print '------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
