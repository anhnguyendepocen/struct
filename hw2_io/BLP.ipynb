{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    \"\"\"pre-processing to calculate outside good shares\"\"\"\n",
    "    shares = data[['Market_ID',name]].copy()\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data = comp_outside_good(data,'Inside Good Share')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data(data):\n",
    "    \"\"\"simplify setting up data correctly\"\"\"\n",
    "    #set up x and y\n",
    "    y = data[['Inside Good Share','Outside Good Share']]\n",
    "    x =  data[['Network Score','Satisfaction Score','PPO','Premium']]\n",
    "    return x,y\n",
    "\n",
    "\n",
    "def setup_hausman(data):\n",
    "    #calculate hausmann insturments\n",
    "    price = data['Premium']\n",
    "    mkt_dum = pd.get_dummies(data['Market_ID'],prefix='mkt',drop_first=True)\n",
    "    plan_dum = pd.get_dummies(data['Plan_ID'],prefix='plan',drop_first=True)\n",
    "    exog = np.array( data[['Network Score','Satisfaction Score', 'PPO']])\n",
    "    \n",
    "    #calc avg price in other markets\n",
    "    hausman_mod1 = sm.OLS(price, sm.add_constant(plan_dum))\n",
    "    hausman_fit1 = hausman_mod1.fit()\n",
    "    hausman_instr1 = hausman_fit1.fittedvalues\n",
    "    hausman_instr1 = np.array([hausman_instr1]).transpose()\n",
    "    \n",
    "    #no of competitors\n",
    "    BLP_instr = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "    BLP_instr =  pd.merge(data[['Market_ID','Plan_ID']],\n",
    "                        BLP_instr[['Plan_ID']], right_index=True, left_on = 'Market_ID')\n",
    "    BLP_instr = np.array([BLP_instr['Plan_ID_y']]).transpose()\n",
    "    \n",
    "    #average characteristics among competititors\n",
    "    BLP_instr2 = data[['Market_ID','Network Score','Satisfaction Score']].groupby('Market_ID').mean()\n",
    "    BLP_instr2 =  pd.merge(data[['Market_ID']],\n",
    "                        BLP_instr2[['Network Score','Satisfaction Score']], right_index=True, left_on = 'Market_ID')\n",
    "    BLP_instr2 = (np.array(BLP_instr2)[:,1:]*BLP_instr - exog[:,:-1])/(BLP_instr-1)\n",
    "    \n",
    "    #concat hausman instr with exog variables\n",
    "    instr = np.concatenate( (exog, hausman_instr1, BLP_instr2), axis =1 )\n",
    "    \n",
    "    return instr\n",
    "\n",
    "\n",
    "#pre process for testing\n",
    "x,y =  setup_data(data)\n",
    "z = setup_hausman(data)\n",
    "T =  np.linalg.inv( z.transpose().dot(z) ) #set up initial weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 16 3300\n"
     ]
    }
   ],
   "source": [
    "#set up useful global variables \n",
    "NMKTS = data['Market_ID'].nunique()\n",
    "NPLANS = data['Plan_ID'].nunique()\n",
    "NOBS = data['Plan_ID'].count()\n",
    "NSIM = 50\n",
    "\n",
    "theta1 = np.array([4,1.5,.7,-1.5])\n",
    "theta2 = np.array([2,2,1]) # initialize theta2 for testing purposes\n",
    "delta = np.ones(NOBS)*(-2)\n",
    "\n",
    "#print global variables\n",
    "print NMKTS,NPLANS,NOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up random draws v\n",
    "v = np.random.normal(size=(NSIM,3)) #same simulation for all markets\n",
    "np.savetxt(\"simulations.csv\", v, delimiter=\",\")\n",
    "\n",
    "#use same simulations each time\n",
    "v = np.genfromtxt('simulations.csv', delimiter=',')\n",
    "v = np.tile(v.reshape(NSIM,3,1) , (1,1,NOBS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating $\\delta_{jt}$, $\\xi_{jt}$\n",
    "\n",
    "The first part of the estimation involves calculating the mean utility with the BLP inversion and the mean unobservable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sim_s(data, v, delta, theta2):\n",
    "    \"\"\"calculate market share for each simulated consumer\"\"\"\n",
    "    \n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO']]).transpose()\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1,3300))\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() ) \n",
    "    \n",
    "    #sum up between markets\n",
    "    sim_exp['mkt_id'] = data['Market_ID']\n",
    "    sum_exp = sim_exp.groupby('mkt_id').sum() \n",
    "    sum_exp = pd.merge(data.copy()[['Market_ID']], sum_exp, \n",
    "                       right_index=True, left_on = 'Market_ID')\n",
    "    \n",
    "    #format so I can broadcast\n",
    "    sim_exp = np.array(sim_exp).transpose()[:-1]\n",
    "    sum_exp = np.array(sum_exp).transpose()[1:] + 1\n",
    "    \n",
    "    return sim_exp/sum_exp\n",
    "\n",
    "\n",
    "def cal_s(data, v, delta, theta2):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates individual choice probability first, then take sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*cal_sim_s(data, v, delta, theta2).sum(axis=0)\n",
    "    return shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_delta(data, v, theta2, error = 1e-3, maxiter = 500):\n",
    "    \"\"\"Calculate mean utility via contraction mapping\"\"\"\n",
    "\n",
    "    niter = 0\n",
    "    \n",
    "    #initialize loop parameters\n",
    "    delta = np.zeros(NOBS)\n",
    "    s = cal_s(data, v, delta, theta2)\n",
    "    diff = np.log(data['Inside Good Share']) - np.log(s)\n",
    "    \n",
    "    \n",
    "    while ((abs(diff).max() > 1e-6) #this is easier to converge\n",
    "           and (abs(diff).mean() > error) \n",
    "           and niter < maxiter):\n",
    "        \n",
    "        s = cal_s(data, v, delta, theta2)\n",
    "        diff = np.log(data['Inside Good Share']) - np.log(s)\n",
    "\n",
    "        if np.isnan(diff).sum():\n",
    "            raise Exception('nan in diffs')\n",
    "            \n",
    "        delta += diff\n",
    "        niter += 1\n",
    "\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_xi(data, delta, theta1):\n",
    "    \"\"\"Calculate xi with F.O.C\"\"\"\n",
    "    x,y =  setup_data(data)\n",
    "    xi = np.matmul(np.array(x),theta1)\n",
    "    xi = delta - np.matmul(np.array(x),theta1)\n",
    "    return  xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating  $\\theta_1,\\theta_2$\n",
    "\n",
    "Here $\\theta_1 = (\\alpha, \\beta)$\n",
    "\n",
    "I only solve GMM over $\\theta_2$, the non-linear parameters. $\\theta_1$ is calculated as a function of $\\delta$ using the formula from Nevo 2000\n",
    "\n",
    "$$\\hat{\\theta_1} = (X'Z V^{-1} Z'X)^{-1} X'Z V^{-1} Z' \\delta(\\hat{\\theta}_2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_theta1(data, delta, z, T):\n",
    "    \"\"\"  calculate theta_1 using FOCs \n",
    "    \n",
    "    (X1'Z T Z'X )^-1 X1'Z T Z' delta \"\"\"\n",
    "    \n",
    "    #set up variables\n",
    "    x,y =  setup_data(data)\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    \n",
    "    #build up to main equation\n",
    "    XtZ = X.transpose().dot(Z)\n",
    "    ZtX = Z.transpose().dot(X)\n",
    "        \n",
    "    first_exp = np.linalg.inv( XtZ.dot(T).dot(ZtX))\n",
    "    second_exp = XtZ.dot(T).dot(Z.transpose()).dot(delta)\n",
    "    theta1 = first_exp.dot(second_exp)\n",
    "    return theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 57\n",
      "         Function evaluations: 106\n",
      "[1.67709242 1.65296753 1.17356529]\n"
     ]
    }
   ],
   "source": [
    "def gmm_objective(theta2_init, data,  v, z,  T):\n",
    "    \"\"\"calculate the GMM objective and minimize it to find theta_2\n",
    "    \n",
    "    I use the formula from Nevo 2000: w' z phi-1 z' w, of theta2\"\"\"\n",
    "    \n",
    "    #set up variables\n",
    "    x,y =  setup_data(data)\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    \n",
    "    #do calculations\n",
    "    delta = cal_delta(data, v, theta2_init)\n",
    "    theta1 = cal_theta1(data, delta, z, T)\n",
    "    xi = cal_xi(data, delta, theta1)\n",
    "        \n",
    "    xitZ = xi.transpose().dot(Z)\n",
    "    Ztxi = Z.transpose().dot(xi)\n",
    "    return xitZ.dot(T).dot(Ztxi)\n",
    "    \n",
    "\n",
    "def calc_theta2(data, v, z, T, theta2_init,NM=True):\n",
    "    \"\"\"calculate theta2 using scipy\"\"\"\n",
    "    if NM:\n",
    "        theta2 = minimize(gmm_objective, theta2_init, args=(data,  v, z, T), method='Nelder-Mead',\n",
    "                      options={'maxiter':100, 'disp': True})\n",
    "    else:\n",
    "        theta2 = minimize(gmm_objective, theta2_init, args=(data,  v, z, T), method='BFGS',\n",
    "                      options={'maxiter':100, 'disp': True})\n",
    "    return abs(theta2.x)\n",
    "\n",
    "\n",
    "theta2_init = np.array([2,2,1])\n",
    "theta2_test = calc_theta2(data, v, z, T, theta2_init)\n",
    "print theta2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 57\n",
      "         Function evaluations: 106\n"
     ]
    }
   ],
   "source": [
    "theta2_init = np.array([2,2,1])\n",
    "\n",
    "def calc_theta(data, v, theta2_init, stages=2):\n",
    "    \"\"\"put everything together to calculate theta1 and theta2\"\"\"\n",
    "    #initialize theta\n",
    "    x,y =  setup_data(data)\n",
    "    z = setup_hausman(data)\n",
    "    \n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    theta2 = theta2_init \n",
    "    \n",
    "    #on first step, use consistent approximation of T\n",
    "    T =  np.linalg.inv( z.transpose().dot(z) )\n",
    "    for i in range(stages):  \n",
    "       \n",
    "        #on second use T using estimated xi\n",
    "        if i==1:\n",
    "            xi = cal_xi(data, delta, theta1)\n",
    "            xi =np.array([xi]).transpose()\n",
    "            T =  np.linalg.inv( Z.transpose().dot(xi).dot(xi.transpose()).dot(Z) )\n",
    "        \n",
    "        theta2 = calc_theta2(data, v, z, T, theta2)\n",
    "        delta = cal_delta(data, v, theta2)\n",
    "        theta1 = cal_theta1(data, delta, z, T)\n",
    "        \n",
    "    return theta1, theta2\n",
    "\n",
    "theta = calc_theta(data, v, theta2_init, stages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Mean Coefficients \n",
      "------------------------------------------------------------------\n",
      "               0                   1         2        3\n",
      "0  Network Score  Satisfaction Score       PPO  Premium\n",
      "1         3.6309             1.98796  0.826909 -1.59932\n",
      "------------------------------------------------------------------\n",
      "Variance Coefficients\n",
      "------------------------------------------------------------------\n",
      "               0                   1        2        3\n",
      "0  Network Score  Satisfaction Score      PPO  Premium\n",
      "1        1.67709             1.65297  1.17357     None\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '------------------------------------------------------------------'\n",
    "print 'Mean Coefficients \\n------------------------------------------------------------------'\n",
    "labels1 = np.array(['Network Score','Satisfaction Score','PPO','Premium'])\n",
    "print pd.DataFrame([labels1, theta[0]])\n",
    "print '------------------------------------------------------------------'\n",
    "\n",
    "print 'Variance Coefficients'\n",
    "print '------------------------------------------------------------------'\n",
    "print pd.DataFrame([labels1, theta[1]])\n",
    "print '------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 3.63089602,  1.98795757,  0.826909  , -1.59931703]), array([1.67709242, 1.65296753, 1.17356529]))\n"
     ]
    }
   ],
   "source": [
    "#save xi and write to array for counterfactuals\n",
    "theta1_est, theta2_est = theta\n",
    "\n",
    "delta_est = cal_delta(data, v, theta2_est)\n",
    "xi_est = cal_xi(data, delta_est, theta1_est)\n",
    "\n",
    "np.savetxt(\"xi.csv\", xi_est, delimiter=\",\")\n",
    "\n",
    "print theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Standard Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theta1 = np.array([3.79292846,  1.95860809,  0.75734848, -1.47436869 ])\n",
    "#theta2 =  np.array([2.47702906, 1.15401209, 1.00765258])\n",
    "#xi_est = np.genfromtxt('xi.csv', delimiter=',')\n",
    "#theta = theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300, 4)\n",
      "(3300, 6)\n",
      "[[ -2510.5629      -2426.0812      -1417.99        -7093.89132483]\n",
      " [ -2426.0812      -2349.72395     -1380.5         -6859.05145168]\n",
      " [ -1417.99        -1380.5         -1632.          -4193.9279688 ]\n",
      " [ -7093.89132483  -6859.05145168  -4193.9279688  -20105.72286639]\n",
      " [ -2505.48061405  -2421.5520022   -1423.04367857  -7090.45869466]\n",
      " [ -2421.5520022   -2340.00640464  -1374.22810714  -6852.37200463]]\n"
     ]
    }
   ],
   "source": [
    "def same_mkt(data):\n",
    "    \"\"\"calculate if 2 products are in the same mkt\"\"\"\n",
    "    same_mkt = np.array([data['Market_ID']],dtype=np.float32 )\n",
    "    same_mkt = (same_mkt.transpose()).dot( 1/same_mkt)\n",
    "    same_mkt = np.equal(same_mkt,np.ones((NOBS,NOBS)) )\n",
    "    same_mkt = same_mkt.astype(np.float32)\n",
    "    return same_mkt\n",
    "    \n",
    "\n",
    "\n",
    "def calc_s_delta(data, v, theta, xi):\n",
    "    \"\"\"calculate derivate wrt delta\"\"\"\n",
    "    theta1,theta2 = theta\n",
    "    \n",
    "    delta = cal_delta(data, v, theta2)\n",
    "    \n",
    "    sim_shares = cal_sim_s(data, v, delta, theta2)\n",
    "    cross_deriv = np.zeros((NOBS,NOBS))\n",
    "    for sim_share in sim_shares:\n",
    "        sim_share = sim_share.reshape((NOBS,1))\n",
    "        cross_deriv = cross_deriv + sim_share.dot(sim_share.transpose())\n",
    "        \n",
    "    own = np.identity(NOBS)\n",
    "    cross = - (1 - own)*same_mkt(data)\n",
    "    \n",
    "    own_deriv  = (1-sim_shares) * sim_shares\n",
    "    own_deriv = own_deriv.sum(axis=0)\n",
    "    \n",
    "    sim_deriv = 1./(NSIM) * (cross_deriv*cross +own_deriv*own )\n",
    "    return sim_deriv\n",
    "  \n",
    "\n",
    "\n",
    "def calc_s_sigma_k(k, data, v, theta, xi):\n",
    "    \"\"\"calculate share derivate wrt delta\n",
    "    \n",
    "    \n",
    "    return type should by 3300 x 3\n",
    "    \"\"\"\n",
    "    theta1,theta2 = theta\n",
    "    delta = cal_delta(data, v, theta2)\n",
    "    sim_shares = cal_sim_s(data, v, delta, theta2)\n",
    "    x,y =  setup_data(data)\n",
    "    vk = v[:,k,:]\n",
    "    xk = np.array(x)[:,k]\n",
    "    \n",
    "    deriv_k = np.zeros(NOBS)\n",
    "    for s in range(NSIM):\n",
    "        \n",
    "        #sum up between markets\n",
    "        inner = pd.DataFrame( (xk*sim_shares[s]).transpose() )\n",
    "        inner['mkt_id'] = data['Market_ID']\n",
    "        inner = inner.groupby('mkt_id').sum()\n",
    "        inner = pd.merge(data.copy()[['Market_ID']], inner, \n",
    "            right_index=True, left_on = 'Market_ID')\n",
    "        inner = np.array(inner[0])\n",
    "        outer = vk[s]*sim_shares[s]*(xk - inner)\n",
    "\n",
    "        deriv_k = deriv_k + outer\n",
    "    \n",
    "    s_sigma  = 1./NSIM * deriv_k\n",
    "    return s_sigma \n",
    "\n",
    "\n",
    "\n",
    "def calc_s_sigma( data, v, theta, xi):\n",
    "    \"\"\"function for claculating share derivative wrt sigma\"\"\"\n",
    "    \n",
    "    s_sigma = []\n",
    "    for k in range(3):\n",
    "        s_sigma_k = calc_s_sigma_k(k, data, v, theta, xi)\n",
    "        s_sigma.append( s_sigma_k )\n",
    "    s_sigma = np.array( s_sigma )\n",
    "    return s_sigma.transpose()\n",
    "\n",
    "\n",
    "\n",
    "def gradient(data, v, theta, xi):\n",
    "    \"\"\"function for analytically computing gradient\n",
    "    following Nevo's appendix\"\"\"\n",
    "    \n",
    "    xi =np.array([xi]).transpose()\n",
    "    x,y =  setup_data(data)\n",
    "    z = setup_hausman(data)\n",
    "    \n",
    "    #set up weight matrices\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    \n",
    "    \n",
    "    #set up derivative matrix\n",
    "    #s_delta = calc_s_delta(data, v, theta, xi)\n",
    "    #s_delta = np.linalg.inv(s_delta)\n",
    "    #s_sigma = calc_s_sigma(data, v, theta, xi)\n",
    "    #D_theta2 = s_delta.dot(s_sigma)\n",
    "    D_theta1 = - X # do not include prices as this is endogenous?\n",
    "    D = D_theta1\n",
    "    \n",
    "    print D_theta1.shape\n",
    "    print z.shape\n",
    "    #D = np.concatenate( (D_theta1,D_theta2), axis=1)\n",
    "    \n",
    "    return ((D.transpose()).dot(Z)).transpose()\n",
    "    \n",
    "\n",
    "gamma = gradient(data, v, theta, xi_est)\n",
    "\n",
    "print gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2510.5629      -2426.0812      -1417.99        -7093.89132483]\n",
      " [ -2426.0812      -2349.72395     -1380.5         -6859.05145168]\n",
      " [ -1417.99        -1380.5         -1632.          -4193.9279688 ]\n",
      " [ -7093.89132483  -6859.05145168  -4193.9279688  -20105.72286639]\n",
      " [ -2505.48061405  -2421.5520022   -1423.04367857  -7090.45869466]\n",
      " [ -2421.5520022   -2340.00640464  -1374.22810714  -6852.37200463]]\n"
     ]
    }
   ],
   "source": [
    "print gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I have calculated standard errors using the formula $$(\\Gamma' A \\Gamma)^{-1}(\\Gamma' A V A \\Gamma)^{-1} (\\Gamma' A \\Gamma)^{-1}$$\n",
    "\n",
    "Where $\\Gamma$ is a numeric approximation of the gradient $A$ is the initial weighting matrix and $V$ is the covaraince matrix (also the optimal weight matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000121120491232\n",
      "0.00903527507642\n",
      "(3300, 4)\n",
      "(3300, 6)\n",
      "[[ 1.08900000e+07 -2.28881836e-05 -2.47955322e-05 -1.64841657e+06]\n",
      " [ 3.81469727e-05  1.08900000e+07  1.71661377e-05 -7.54412764e+05]\n",
      " [-6.67572021e-06 -9.53674316e-07  1.08900000e+07 -6.11148345e+05]\n",
      " [-1.64841657e+06 -7.54412764e+05 -6.11148345e+05  1.96913338e+07]]\n"
     ]
    }
   ],
   "source": [
    "def cal_standard_errors(theta, xi, data,  v):\n",
    "    #set up variables\n",
    "    print xi.mean()\n",
    "    print xi.var()\n",
    "    xi =np.array([xi]).transpose()\n",
    "\n",
    "    x,y =  setup_data(data)\n",
    "    z = setup_hausman(data)\n",
    "    \n",
    "    #set up weight matrices\n",
    "    X,Z = np.array(x), np.array(z)\n",
    "    #V =  Z.transpose().dot(xi).dot(xi.transpose() ).dot(Z)\n",
    "    V = np.identity(6)*(NOBS**2)\n",
    "\n",
    "    A =  np.linalg.inv( Z.transpose().dot(Z) )\n",
    "    G =  gradient(data, v, theta, xi)\n",
    "    #G = gamma\n",
    "    \n",
    "    GAG_inv =  np.linalg.inv( G.transpose().dot(A).dot(G) )\n",
    "    GAVAG = G.transpose().dot(A).dot(V).dot(A).dot(G)\n",
    "    print GAVAG\n",
    "    return GAG_inv.dot(GAVAG).dot(GAG_inv)\n",
    "    #return G.transpose().dot(A).dot(V).dot(A.transpose()).dot(G)\n",
    "\n",
    "se = np.sqrt ( abs (cal_standard_errors(theta, xi_est, data,  v) ) ) /NOBS\n",
    "\n",
    "se1 = np.diagonal(se)[:4]\n",
    "se2 = np.diagonal(se)[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the standard errors calculated using the formula. The are high from, rounding error from calculating the gradient numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Mean Coefficients (Standard Error) \n",
      "------------------------------------------------------------------\n",
      "               0                   1          2        3\n",
      "0  Network Score  Satisfaction Score        PPO  Premium\n",
      "1       0.554024            0.247768  0.0358193  0.15565\n",
      "------------------------------------------------------------------\n",
      "Coefficients Variance (Standard Error)\n",
      "------------------------------------------------------------------\n",
      "               0                   1     2        3\n",
      "0  Network Score  Satisfaction Score   PPO  Premium\n",
      "1           None                None  None     None\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print '------------------------------------------------------------------'\n",
    "print 'Mean Coefficients (Standard Error) \\n------------------------------------------------------------------'\n",
    "labels1 = np.array(['Network Score','Satisfaction Score','PPO','Premium'])\n",
    "print pd.DataFrame([labels1, se1])\n",
    "print '------------------------------------------------------------------'\n",
    "\n",
    "print 'Coefficients Variance (Standard Error)'\n",
    "print '------------------------------------------------------------------'\n",
    "print pd.DataFrame([labels1,se2])\n",
    "print '------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
