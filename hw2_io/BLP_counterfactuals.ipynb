{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    #pre-processing to calculate outside good shares\n",
    "    shares = data[['Market_ID',name]].copy()\n",
    "\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 16 3300\n"
     ]
    }
   ],
   "source": [
    "#set up useful global variables \n",
    "NMKTS = data['Market_ID'].nunique()\n",
    "NPLANS = data['Plan_ID'].nunique()\n",
    "NOBS = data['Plan_ID'].count()\n",
    "NSIM = 20\n",
    "\n",
    "#initialize theta1 and theta2 based on estimates\n",
    "theta1 = np.array([3.34952545,  1.95632696,  0.6506052 , -1.5642128])\n",
    "theta2 = np.array([1.43279579, 1.25336653, 0.50565619])\n",
    "xi = np.genfromtxt('xi.csv', delimiter=',')\n",
    "\n",
    "v0 = np.genfromtxt('simulations.csv', delimiter=',')\n",
    "v = np.tile(v0.reshape(NSIM,3,1) , (1,1,NOBS))\n",
    "\n",
    "#print global variables\n",
    "print NMKTS,NPLANS,NOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sim_s(data, v, xi, theta1, theta2):\n",
    "    \"\"\"calculate market share for each simulated consumer\"\"\"\n",
    "    \n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO', 'Premium']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1)\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    \n",
    "    x = (x.transpose()[:-1])\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, NOBS))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() , \n",
    "                           index= data.index ) \n",
    "    \n",
    "    #sum up between markets\n",
    "    sim_exp['mkt_id'] = data['Market_ID']\n",
    "    sum_exp = sim_exp.groupby('mkt_id').sum() \n",
    "    sum_exp = pd.merge(data.copy()[['Market_ID']], sum_exp, \n",
    "                       right_index=True, left_on = 'Market_ID')\n",
    "    \n",
    "    #format so I can broadcast\n",
    "    sim_exp = np.array(sim_exp).transpose()[:-1]\n",
    "    sum_exp = np.array(sum_exp).transpose()[1:] + 1\n",
    "    \n",
    "    return sim_exp/sum_exp\n",
    "\n",
    "def cal_s(data, v, xi, theta1, theta2):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates individual choice probability first, then take sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*cal_sim_s(data, v, xi, theta1, theta2).sum(axis=0)\n",
    "    return shares\n",
    "\n",
    "sim_s = cal_s(data, v, xi, theta1, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Elasticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_price_deriv(data, v, xi, theta1, theta2):\n",
    "    alpha = abs(theta1[-1])\n",
    "    \n",
    "    sim_shares = cal_sim_s(data, v, xi, theta1, theta2)\n",
    "    cross_deriv = np.zeros((NOBS,NOBS))\n",
    "    for sim_share in sim_shares:\n",
    "        sim_share = sim_share.reshape((NOBS,1))\n",
    "        cross_deriv = cross_deriv + sim_share.dot(sim_share.transpose())\n",
    "        \n",
    "    own = np.identity(NOBS)\n",
    "    cross = (1 - own)\n",
    "    own_deriv  = -(1-sim_shares) * sim_shares\n",
    "    own_deriv = own_deriv.sum(axis=0)\n",
    "    \n",
    "    sim_deriv = 1./(NSIM) * alpha * (cross_deriv*cross +own_deriv*own )\n",
    "    return sim_deriv\n",
    "\n",
    "\n",
    "def cal_price_elast(data, v, xi, theta1, theta2):\n",
    "\n",
    "    share = np.array(data['Inside Good Share'])\n",
    "    price = np.array([data['Premium']]).transpose()\n",
    "    deriv = cal_price_deriv(data, v, xi, theta1, theta2)\n",
    "    \n",
    "    return share.dot(1/price)*deriv\n",
    "\n",
    "elast = cal_price_elast(data, v, xi, theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -2.404092  0.254645  0.614399  0.448612  0.310901  0.399155  0.476252   \n",
      "1   0.254645 -1.545957  0.343568  0.256235  0.212894  0.281903  0.312730   \n",
      "2   0.614399  0.343568 -2.525627  0.443360  0.335651  0.435968  0.523575   \n",
      "3   0.448612  0.256235  0.443360 -2.086232  0.272076  0.379331  0.487807   \n",
      "4   0.310901  0.212894  0.335651  0.272076 -1.608848  0.272553  0.316079   \n",
      "5   0.399155  0.281903  0.435968  0.379331  0.272553 -1.962772  0.373036   \n",
      "6   0.476252  0.312730  0.523575  0.487807  0.316079  0.373036 -2.386800   \n",
      "7   0.435678  0.319254  0.405457  0.315309  0.262095  0.361852  0.381023   \n",
      "8   0.469018  0.251067  0.508879  0.449548  0.248591  0.340284  0.476122   \n",
      "9   0.242579  0.163055  0.247309  0.205309  0.188172  0.239659  0.251774   \n",
      "10  0.335056  0.242694  0.357978  0.298883  0.198456  0.294005  0.338927   \n",
      "11  0.559193  0.294964  0.547191  0.488212  0.292433  0.385220  0.520189   \n",
      "12  0.385246  0.236336  0.510660  0.342372  0.271456  0.379259  0.436222   \n",
      "13  0.357749  0.257789  0.382520  0.282559  0.290803  0.342145  0.366088   \n",
      "14  0.549654  0.329858  0.591005  0.515849  0.348372  0.362952  0.597022   \n",
      "15  0.341090  0.254820  0.420921  0.306557  0.312898  0.356590  0.389531   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.435678  0.469018  0.242579  0.335056  0.559193  0.385246  0.357749   \n",
      "1   0.319254  0.251067  0.163055  0.242694  0.294964  0.236336  0.257789   \n",
      "2   0.405457  0.508879  0.247309  0.357978  0.547191  0.510660  0.382520   \n",
      "3   0.315309  0.449548  0.205309  0.298883  0.488212  0.342372  0.282559   \n",
      "4   0.262095  0.248591  0.188172  0.198456  0.292433  0.271456  0.290803   \n",
      "5   0.361852  0.340284  0.239659  0.294005  0.385220  0.379259  0.342145   \n",
      "6   0.381023  0.476122  0.251774  0.338927  0.520189  0.436222  0.366088   \n",
      "7  -1.978465  0.324349  0.228513  0.296005  0.377727  0.281675  0.333327   \n",
      "8   0.324349 -2.111572  0.210013  0.327461  0.442638  0.385564  0.312384   \n",
      "9   0.228513  0.210013 -1.307818  0.204807  0.216673  0.229623  0.177530   \n",
      "10  0.296005  0.327461  0.204807 -1.669491  0.302411  0.287508  0.280558   \n",
      "11  0.377727  0.442638  0.216673  0.302411 -2.354175  0.397041  0.360153   \n",
      "12  0.281675  0.385564  0.229623  0.287508  0.397041 -1.937845  0.270293   \n",
      "13  0.333327  0.312384  0.177530  0.280558  0.360153  0.270293 -1.813340   \n",
      "14  0.413863  0.496747  0.262141  0.310852  0.554172  0.433520  0.377903   \n",
      "15  0.296630  0.345923  0.238476  0.288530  0.355762  0.305388  0.302173   \n",
      "\n",
      "          14        15  \n",
      "0   0.549654  0.341090  \n",
      "1   0.329858  0.254820  \n",
      "2   0.591005  0.420921  \n",
      "3   0.515849  0.306557  \n",
      "4   0.348372  0.312898  \n",
      "5   0.362952  0.356590  \n",
      "6   0.597022  0.389531  \n",
      "7   0.413863  0.296630  \n",
      "8   0.496747  0.345923  \n",
      "9   0.262141  0.238476  \n",
      "10  0.310852  0.288530  \n",
      "11  0.554172  0.355762  \n",
      "12  0.433520  0.305388  \n",
      "13  0.377903  0.302173  \n",
      "14 -2.506963  0.423828  \n",
      "15  0.423828 -1.853850  \n"
     ]
    }
   ],
   "source": [
    "#need to think about getting average elasticity\n",
    "\n",
    "def comp_avg_elasticity(data, v, xi, theta1, theta2):\n",
    "    elast = cal_price_elast(data, v, xi, theta1, theta2)\n",
    "    \n",
    "    #who cares about run time?\n",
    "    avg_elasticity = np.zeros((NPLANS,NPLANS))\n",
    "    \n",
    "    same_mkt = np.array([data['Market_ID']],dtype=np.float32 )\n",
    "    same_mkt = (same_mkt.transpose()).dot( 1/same_mkt)\n",
    "    same_mkt = np.equal(same_mkt,np.ones((NOBS,NOBS)) )\n",
    "    same_mkt = same_mkt.astype(np.float32)\n",
    "    \n",
    "    elast = elast*same_mkt\n",
    "    \n",
    "    \n",
    "    plan_mkt = np.array(data[['Plan_ID']])\n",
    "    for plan_j in range(1,NPLANS+1):\n",
    "        for plan_k in range(1,NPLANS+1):\n",
    "            data_k = data[ (data['Plan_ID'] == plan_k) ].index.values\n",
    "            data_j = data[ (data['Plan_ID'] == plan_j)].index.values\n",
    "            if len(data_k) >0 and len(data_j) > 0:\n",
    "                lenobs = 0\n",
    "                for ind_j in data_j:\n",
    "                    for ind_k in data_k:\n",
    "                        avg_elasticity[plan_j-1][plan_k-1] = (avg_elasticity[plan_j-1][plan_k-1]\n",
    "                                                               + elast[ind_j][ind_k]) \n",
    "                        lenobs = lenobs + same_mkt[ind_j][ind_k]\n",
    "                avg_elasticity[plan_j-1][plan_k-1] =  (avg_elasticity[plan_j-1][plan_k-1]\n",
    "                                                        /lenobs)\n",
    "                \n",
    "    return avg_elasticity\n",
    "                \n",
    "avg_elasticity = comp_avg_elasticity(data, v, xi, theta1, theta2)\n",
    "np.savetxt(\"elasticity.csv\", avg_elasticity, delimiter=\",\")\n",
    "print pd.DataFrame(avg_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markups\n",
    "\n",
    "How does the markup vary with market structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21928086540972883\n"
     ]
    }
   ],
   "source": [
    "def comp_markup(data, v, xi, theta1, theta2):\n",
    "    \n",
    "    shares = np.array(data['Inside Good Share'])\n",
    "    \n",
    "    #caclulate formula\n",
    "    own_deriv  = cal_price_deriv(data, v, xi, theta1, theta2)\n",
    "    own_deriv = np.diag(own_deriv)\n",
    "    \n",
    "    \n",
    "    #take inverse and calc markup\n",
    "    inv_deriv = 1/own_deriv\n",
    "    \n",
    "    markup = - inv_deriv*shares\n",
    "    return markup\n",
    "\n",
    "\n",
    "data['Markup'] = comp_markup(data, v, xi, theta1, theta2)\n",
    "data['Marginal Cost'] = data['Premium'] - data['Markup']\n",
    "data['Unobs'] = xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Markup\n",
      "Plan_ID          \n",
      "1        0.820045\n",
      "2        0.732974\n",
      "3        0.840634\n",
      "4        0.781211\n",
      "5        0.738904\n",
      "6        0.777593\n",
      "7        0.819460\n",
      "8        0.785513\n",
      "9        0.782057\n",
      "10       0.713782\n",
      "11       0.745086\n",
      "12       0.817716\n",
      "13       0.770790\n",
      "14       0.765512\n",
      "15       0.839426\n",
      "16       0.765007\n"
     ]
    }
   ],
   "source": [
    "print data[['Plan_ID','Markup']].groupby('Plan_ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Markup   R-squared:                       0.890\n",
      "Model:                            OLS   Adj. R-squared:                  0.889\n",
      "Method:                 Least Squares   F-statistic:                     4823.\n",
      "Date:                Sat, 03 Nov 2018   Prob (F-statistic):          1.94e-288\n",
      "Time:                        19:42:26   Log-Likelihood:                 1442.2\n",
      "No. Observations:                 600   AIC:                            -2880.\n",
      "Df Residuals:                     598   BIC:                            -2872.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9999      0.003    331.536      0.000       0.994       1.006\n",
      "Plan_ID       -0.0364      0.001    -69.446      0.000      -0.037      -0.035\n",
      "==============================================================================\n",
      "Omnibus:                      159.339   Durbin-Watson:                   0.139\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.526\n",
      "Skew:                           0.526   Prob(JB):                     2.38e-12\n",
      "Kurtosis:                       1.982   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mean_markup = data[['Market_ID','Markup']].groupby('Market_ID').mean()\n",
    "no_firms = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "\n",
    "model_q2 = sm.OLS(mean_markup,sm.add_constant(no_firms))\n",
    "result_q2 = model_q2.fit()\n",
    "print result_q2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Marginal Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Marginal Cost   R-squared:                       0.679\n",
      "Model:                            OLS   Adj. R-squared:                  0.678\n",
      "Method:                 Least Squares   F-statistic:                     2321.\n",
      "Date:                Sat, 03 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        19:42:27   Log-Likelihood:                 5059.9\n",
      "No. Observations:                3300   AIC:                        -1.011e+04\n",
      "Df Residuals:                    3296   BIC:                        -1.009e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  1.4339      0.021     68.820      0.000       1.393       1.475\n",
      "Network Score          0.2268      0.032      7.153      0.000       0.165       0.289\n",
      "Satisfaction Score    -0.0255      0.023     -1.108      0.268      -0.071       0.020\n",
      "PPO                    0.1523      0.002     82.616      0.000       0.149       0.156\n",
      "==============================================================================\n",
      "Omnibus:                     2157.201   Durbin-Watson:                   1.684\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            50491.753\n",
      "Skew:                           2.735   Prob(JB):                         0.00\n",
      "Kurtosis:                      21.366   Cond. No.                         69.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_q3 = sm.OLS(data['Marginal Cost'], \n",
    "                   sm.add_constant(data[['Network Score','Satisfaction Score','PPO']]))\n",
    "result_q3 = model_q3.fit()\n",
    "print result_q3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.000043\n",
      "1   -0.000050\n",
      "2   -0.000059\n",
      "Name: Marginal Cost, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def cal_mkt_sim_s(p, data, v, xi, theta1, theta2,nobs):\n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1[:-1]) + p*theta1[-1]\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    x = x.transpose()\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, nobs))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = np.exp(delta + (theta2*v*x).sum(axis=1)).transpose()\n",
    "    \n",
    "    return  (1./ (sim_exp.sum(axis=0) +1) ) * sim_exp\n",
    "\n",
    "\n",
    "def cal_mkt_s(p, data, v, xi, theta1, theta2,nobs):\n",
    "    shares = (1./NSIM)*cal_mkt_sim_s(p, data, v, xi, theta1, theta2,nobs).sum(axis=1)\n",
    "\n",
    "    return shares\n",
    "\n",
    "\n",
    "def cal_mkt_deriv(p, data, v, xi, theta1, theta2 , nobs):\n",
    "    alpha = abs(theta1[-1])\n",
    "    sim_shares = cal_mkt_sim_s(p, data, v, xi, theta1, theta2, nobs)\n",
    "    own_deriv  = -(1-sim_shares) * sim_shares\n",
    "    \n",
    "    own_deriv = own_deriv.sum(axis=1)\n",
    "    sim_deriv = 1./(NSIM) * alpha * (own_deriv)\n",
    "    \n",
    "    #print -0.2192\n",
    "    #print sim_deriv\n",
    "\n",
    "    return sim_deriv\n",
    "\n",
    "\n",
    "def comp_foc(p, data, v, xi, theta1, theta2, subs, nobs):\n",
    "    \n",
    "    shares =  cal_mkt_s(p, data, v, xi, theta1, theta2,  nobs)\n",
    "    #caclulate formula\n",
    "    \n",
    "    own_deriv  = cal_mkt_deriv(p, data, v, xi, theta1, theta2 , nobs)\n",
    "    inv_deriv = 1/own_deriv\n",
    "    \n",
    "    markup = - inv_deriv*shares\n",
    "    \n",
    "    \n",
    "    return markup - (p - data['Marginal Cost'] + subs)\n",
    "\n",
    "\n",
    "mkt_data = data.copy()[data['Market_ID'] == i]\n",
    "mkt_data['Marginal Costs'] = (mkt_data.copy()['Marginal Cost'] ) #apply subsidy\n",
    "mkt_obs = mkt_data['Plan_ID'].count()\n",
    "mkt_prices = np.array(mkt_data['Premium']).squeeze()\n",
    "mkt_v = np.tile(v0.reshape(NSIM,3,1) , (1,1,mkt_obs))\n",
    "mkt_xi = mkt_data['Unobs']\n",
    "\n",
    "\n",
    "print comp_foc(mkt_prices, mkt_data, mkt_v, mkt_xi, theta1, theta2, 0, mkt_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerically solve on a market by market basis\n",
    "new_prices = [[]] * NMKTS\n",
    "\n",
    "\n",
    "for i in range(1,NMKTS+1):\n",
    "    #set up mkt level variables\n",
    "    mkt_data = data.copy()[data['Market_ID'] == i]\n",
    "    mkt_data['Marginal Costs'] = (mkt_data.copy()['Marginal Cost'] ) #apply subsidy\n",
    "    mkt_obs = mkt_data['Plan_ID'].count()\n",
    "    mkt_prices = np.array(mkt_data['Premium']).squeeze()\n",
    "    mkt_v = np.tile(v0.reshape(NSIM,3,1) , (1,1,mkt_obs))\n",
    "    mkt_xi = mkt_data['Unobs']\n",
    "    \n",
    "    #calculate FOCs\n",
    "    mkt_new_prices = fsolve(comp_foc, mkt_prices, args= (mkt_data, mkt_v, mkt_xi,\n",
    "                                                         theta1, theta2, .25, mkt_obs) )\n",
    "    new_prices[i-1] = mkt_new_prices\n",
    "    \n",
    "\n",
    "#flatten result to 1d array\n",
    "new_prices = np.array([ p for  mkt_new_prices in new_prices for p in  mkt_new_prices ])\n",
    "\n",
    "#write to file\n",
    "np.savetxt('prices_blp.csv', new_prices, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid caclulating everytime\n",
    "new_prices = np.genfromtxt('prices_blp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Uninsurance rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside Good (Before Rebate): 0.134505918182\n",
      "Outside Good (After Rebate): 0.1067712938\n"
     ]
    }
   ],
   "source": [
    "#outside good shares\n",
    "\n",
    "cf_data = data.copy()\n",
    "data = comp_outside_good(data,'Inside Good Share')\n",
    "\n",
    "cf_data['Premium'] = new_prices\n",
    "cf_data['New Inside Good'] =  cal_s(cf_data, v, xi, theta1, theta2)\n",
    "cf_data = comp_outside_good(cf_data,'New Inside Good')\n",
    "\n",
    "#compare the mean outside good before and after the rebate. It decreases.\n",
    "print 'Outside Good (Before Rebate): %s'%data['Outside Good Share'].mean()\n",
    "print 'Outside Good (After Rebate): %s'%cf_data['Outside Good Share'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Change in Profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Enrollee (Before Rebate): 0.780581746388\n",
      "Per Enrollee (After Rebate): 0.78325433363\n"
     ]
    }
   ],
   "source": [
    "#profits per enrollee, comparision\n",
    "print 'Per Enrollee (Before Rebate): %s'%(data['Premium'] - cf_data['Marginal Cost']).mean()\n",
    "print 'Per Enrollee (After Rebate): %s'%(cf_data['Premium'] - cf_data['Marginal Cost'] + .25).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Change in Consumer Surplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_sim_exp(data, v, xi, theta1, theta2 , nobs):\n",
    "\n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO', 'Premium']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1)\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    x = (x.transpose()[:-1])\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, nobs))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() , \n",
    "                           index= data.index )\n",
    "    return sim_exp\n",
    "\n",
    "\n",
    "def comp_exp(data, v, xi, theta1, theta2 , nobs):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates individual choice probability first, then take sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*comp_sim_exp(data, v, xi, theta1, theta2, nobs).sum(axis=0)\n",
    "    return shares\n",
    "\n",
    "exp = comp_sim_exp(data, v, xi, theta1, theta2 , NOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24748710215045042\n"
     ]
    }
   ],
   "source": [
    "def comp_surplus(data, cf_data, v, xi, theta1, theta2 , nobs):\n",
    "    #compute exp(delta_j)\n",
    "    \n",
    "    alpha = abs(theta1[-1])\n",
    "    exp = comp_exp(data, v, xi, theta1, theta2 , nobs)\n",
    "    \n",
    "    cf_exp = comp_exp(cf_data, v, xi, theta1, theta2 , nobs)\n",
    "    \n",
    "    utility_ratio = cf_exp.sum()/exp.sum()\n",
    "    return 1/alpha * np.log( utility_ratio )\n",
    "\n",
    "\n",
    "print comp_surplus(data, cf_data, v, xi, theta1, theta2 , NOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
