{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    #pre-processing to calculate outside good shares\n",
    "    shares = data[['Market_ID',name]].copy()\n",
    "\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 16 3300\n"
     ]
    }
   ],
   "source": [
    "#set up useful global variables \n",
    "NMKTS = data['Market_ID'].nunique()\n",
    "NPLANS = data['Plan_ID'].nunique()\n",
    "NOBS = data['Plan_ID'].count()\n",
    "NSIM = 50\n",
    "\n",
    "#initialize theta1 and theta2 based on estimates\n",
    "theta1 = np.array([ 3.15820237,  1.65121504,  0.64728765, -1.08950616])\n",
    "theta2 =  np.array([2.32968109, 2.16972611, 0.81662519])\n",
    "xi = np.genfromtxt('xi.csv', delimiter=',')\n",
    "\n",
    "v = np.genfromtxt('simulations.csv', delimiter=',').reshape(NSIM,3,3300)\n",
    "\n",
    "#print global variables\n",
    "print NMKTS,NPLANS,NOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_same_mkt(data):\n",
    "    same_mkt = np.array([data['Market_ID']],dtype=np.float32 )\n",
    "    same_mkt = (same_mkt.transpose()).dot( 1/same_mkt)\n",
    "    same_mkt = np.equal(same_mkt,np.ones((NOBS,NOBS)) )\n",
    "    same_mkt = same_mkt.astype(np.float32)\n",
    "    return same_mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sim_s(data, v, xi, theta1, theta2):\n",
    "    \"\"\"calculate market share across each simulated consumer\n",
    "    \n",
    "    Note: we are not summing accross simulations when this is called\n",
    "    \n",
    "    Also note: this function takes different arguments than the \n",
    "    one from estimation\"\"\"\n",
    "    \n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO', 'Premium']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1)\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    \n",
    "    x = (x.transpose()[:-1])\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, NOBS))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() , \n",
    "                           index= data.index ) \n",
    "    \n",
    "    #sum up between markets\n",
    "    sim_exp['mkt_id'] = data['Market_ID']\n",
    "    sum_exp = sim_exp.groupby('mkt_id').sum() \n",
    "    sum_exp = pd.merge(data.copy()[['Market_ID']], sum_exp, \n",
    "                       right_index=True, left_on = 'Market_ID')\n",
    "    \n",
    "    #format so I can broadcast\n",
    "    sim_exp = np.array(sim_exp).transpose()[:-1]\n",
    "    sum_exp = np.array(sum_exp).transpose()[1:] + 1\n",
    "    \n",
    "    return sim_exp/sum_exp\n",
    "\n",
    "\n",
    "def cal_s(data, v, xi, theta1, theta2):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates choice probability in each simulation, \n",
    "    then takes the sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*cal_sim_s(data, v, xi, theta1, theta2)\n",
    "    shares = (1./NSIM)*cal_sim_s(data, v, xi, theta1, theta2).sum(axis=0)\n",
    "    return shares\n",
    "\n",
    "sim_s = cal_s(data, v, xi, theta1, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Elasticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_price_deriv(data, v, xi, theta1, theta2):\n",
    "    \"\"\"calculate own price derivative\"\"\" \n",
    "    alpha = abs(theta1[-1])\n",
    "    same_mkt = cal_same_mkt(data)\n",
    "    sim_shares = cal_sim_s(data, v, xi, theta1, theta2)\n",
    "    cross_deriv = np.zeros((NOBS,NOBS))\n",
    "    for sim_share in sim_shares:\n",
    "        sim_share = sim_share.reshape((NOBS,1))\n",
    "        cross_deriv = cross_deriv + sim_share.dot(sim_share.transpose())*same_mkt\n",
    "        \n",
    "    own = np.identity(NOBS)\n",
    "    cross = (1 - own)\n",
    "    own_deriv  = -(1-sim_shares) * sim_shares\n",
    "\n",
    "    own_deriv = own_deriv.sum(axis=0)\n",
    "    \n",
    "    sim_deriv = 1./(NSIM) * alpha * (cross_deriv*cross +own_deriv*own )\n",
    "    return sim_deriv\n",
    "\n",
    "\n",
    "def cal_price_elast(data, v, xi, theta1, theta2):\n",
    "    \"\"\"calculate the elasticity using the price derivative matrix\"\"\"\n",
    "    share = np.array([data['Inside Good Share']])\n",
    "    price = np.array([data['Premium']]).transpose()\n",
    "    deriv = cal_price_deriv(data, v, xi, theta1, theta2)\n",
    "    return (price).dot(1/share)*deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_avg_elasticity(data, v, xi, theta1, theta2):\n",
    "    \"\"\"figure out what the average elasticty between goods is\"\"\"\n",
    "    elast = cal_price_elast(data, v, xi, theta1, theta2)\n",
    "    \n",
    "    #who cares about run time?\n",
    "    avg_elasticity = np.zeros((NPLANS,NPLANS))\n",
    "    same_mkt = cal_same_mkt(data)\n",
    "    elast = elast\n",
    "    \n",
    "    \n",
    "    plan_mkt = np.array(data[['Plan_ID']])\n",
    "    for plan_j in range(1,NPLANS+1):\n",
    "        for plan_k in range(1,NPLANS+1):\n",
    "            data_k = data[ (data['Plan_ID'] == plan_k) ].index.values\n",
    "            data_j = data[ (data['Plan_ID'] == plan_j)].index.values\n",
    "            if len(data_k) >0 and len(data_j) > 0:\n",
    "                lenobs = 0\n",
    "                for ind_j in data_j:\n",
    "                    for ind_k in data_k:\n",
    "                        avg_elasticity[plan_j-1][plan_k-1] = (avg_elasticity[plan_j-1][plan_k-1]\n",
    "                                                               + elast[ind_j][ind_k]) \n",
    "                        lenobs = lenobs + same_mkt[ind_j][ind_k]\n",
    "                avg_elasticity[plan_j-1][plan_k-1] =  (avg_elasticity[plan_j-1][plan_k-1]\n",
    "                                                        /lenobs)\n",
    "                \n",
    "    return avg_elasticity\n",
    "                \n",
    "avg_elasticity = comp_avg_elasticity(data, v, xi, theta1, theta2)\n",
    "np.savetxt(\"elasticity.csv\", avg_elasticity, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the average cross price elasticities calculated using the random coefficients among the 16 plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -2.492264  0.466191  0.560306  0.563392  0.481553  0.493344  0.517168   \n",
      "1   0.205594 -2.505202  0.236450  0.237618  0.303568  0.301846  0.236140   \n",
      "2   0.604815  0.539695 -2.470747  0.586466  0.527039  0.528866  0.574588   \n",
      "3   0.416995  0.395443  0.400046 -2.517787  0.386871  0.396935  0.441552   \n",
      "4   0.240685  0.332397  0.236744  0.254490 -2.519823  0.314748  0.242538   \n",
      "5   0.309590  0.425489  0.316905  0.343587  0.410343 -2.322832  0.308082   \n",
      "6   0.502243  0.478123  0.508541  0.573823  0.476418  0.462339 -2.533480   \n",
      "7   0.347041  0.492499  0.332557  0.327373  0.430056  0.444087  0.333033   \n",
      "8   0.439049  0.387585  0.428355  0.488396  0.373164  0.383760  0.443882   \n",
      "9   0.183570  0.241364  0.171521  0.190233  0.254180  0.246180  0.186626   \n",
      "10  0.245003  0.344347  0.244190  0.263465  0.310051  0.326322  0.251096   \n",
      "11  0.544921  0.481930  0.531515  0.573617  0.458386  0.468117  0.540137   \n",
      "12  0.355177  0.346565  0.398765  0.386500  0.355441  0.376116  0.387462   \n",
      "13  0.289066  0.407257  0.290250  0.290232  0.414434  0.395660  0.298801   \n",
      "14  0.568847  0.531502  0.562668  0.613452  0.531685  0.481476  0.598794   \n",
      "15  0.272700  0.387389  0.294971  0.293853  0.410788  0.391856  0.297137   \n",
      "\n",
      "          7         8         9         10        11        12        13  \\\n",
      "0   0.492466  0.572954  0.485574  0.490011  0.560149  0.545011  0.485257   \n",
      "1   0.308531  0.232639  0.304274  0.321703  0.228467  0.242110  0.306594   \n",
      "2   0.498079  0.609874  0.501078  0.534122  0.585366  0.649935  0.517101   \n",
      "3   0.349557  0.481104  0.385385  0.396345  0.444505  0.452842  0.360839   \n",
      "4   0.293916  0.245394  0.339528  0.298940  0.233558  0.269699  0.330658   \n",
      "5   0.397074  0.322653  0.423087  0.415184  0.310506  0.358444  0.417918   \n",
      "6   0.447794  0.568412  0.475358  0.490159  0.524000  0.582508  0.468379   \n",
      "7  -2.472767  0.332699  0.444259  0.453801  0.335796  0.333537  0.445258   \n",
      "8   0.357115 -2.529008  0.400658  0.414339  0.424407  0.468191  0.377670   \n",
      "9   0.224965  0.193469 -2.600431  0.256190  0.170922  0.214315  0.225396   \n",
      "10  0.312867  0.273603  0.350606 -2.446189  0.236795  0.274456  0.328820   \n",
      "11  0.449792  0.538166  0.448583  0.474005 -2.523128  0.556204  0.472907   \n",
      "12  0.302817  0.417312  0.372100  0.366039  0.371198 -2.552597  0.323223   \n",
      "13  0.377980  0.301798  0.374598  0.402413  0.296369  0.303677 -2.406009   \n",
      "14  0.490375  0.600116  0.512969  0.489673  0.582875  0.609453  0.512312   \n",
      "15  0.348528  0.308075  0.406338  0.398854  0.285751  0.304533  0.371866   \n",
      "\n",
      "          14        15  \n",
      "0   0.533189  0.472432  \n",
      "1   0.227636  0.309058  \n",
      "2   0.584736  0.551149  \n",
      "3   0.438097  0.375489  \n",
      "4   0.244447  0.344397  \n",
      "5   0.288968  0.426146  \n",
      "6   0.537678  0.489380  \n",
      "7   0.333442  0.432284  \n",
      "8   0.428427  0.397490  \n",
      "9   0.180455  0.256903  \n",
      "10  0.232767  0.340364  \n",
      "11  0.529259  0.469956  \n",
      "12  0.368985  0.344929  \n",
      "13  0.292196  0.389920  \n",
      "14 -2.560032  0.530196  \n",
      "15  0.295773 -2.478609  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(avg_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markups\n",
    "\n",
    "How does the markup vary with market structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_markup(data, v, xi, theta1, theta2):\n",
    "    \"\"\"compute the markup implied by demand\n",
    "    from the Nash Betrand equilibrium\"\"\"\n",
    "    \n",
    "    shares = np.array(data['Inside Good Share'])\n",
    "    #caclulate formula\n",
    "    own_deriv  = cal_price_deriv(data, v, xi, theta1, theta2)\n",
    "    own_deriv = np.diag(own_deriv)\n",
    "    \n",
    "    #take inverse and calc markup\n",
    "    inv_deriv = 1/own_deriv\n",
    "    markup = - inv_deriv*shares\n",
    "    return markup\n",
    "\n",
    "\n",
    "data['Markup'] = comp_markup(data, v, xi, theta1, theta2)\n",
    "data['Marginal Cost'] = data['Premium'] - data['Markup']\n",
    "data['Unobs'] = xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we calculate the average markup per plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Markup\n",
      "Plan_ID          \n",
      "1        1.200935\n",
      "2        1.066559\n",
      "3        1.233132\n",
      "4        1.140333\n",
      "5        1.075550\n",
      "6        1.136478\n",
      "7        1.199869\n",
      "8        1.150914\n",
      "9        1.140497\n",
      "10       1.037810\n",
      "11       1.087632\n",
      "12       1.198169\n",
      "13       1.123580\n",
      "14       1.115016\n",
      "15       1.234100\n",
      "16       1.116287\n"
     ]
    }
   ],
   "source": [
    "print data[['Plan_ID','Markup']].groupby('Plan_ID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the more plans in a market, the lower the markup. This is the same as the previous homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Markup   R-squared:                       0.867\n",
      "Model:                            OLS   Adj. R-squared:                  0.867\n",
      "Method:                 Least Squares   F-statistic:                     3908.\n",
      "Date:                Mon, 12 Nov 2018   Prob (F-statistic):          2.02e-264\n",
      "Time:                        10:39:11   Log-Likelihood:                 1090.5\n",
      "No. Observations:                 600   AIC:                            -2177.\n",
      "Df Residuals:                     598   BIC:                            -2168.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4952      0.005    275.854      0.000       1.485       1.506\n",
      "Plan_ID       -0.0588      0.001    -62.511      0.000      -0.061      -0.057\n",
      "==============================================================================\n",
      "Omnibus:                       49.803   Durbin-Watson:                   0.415\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               60.750\n",
      "Skew:                           0.778   Prob(JB):                     6.43e-14\n",
      "Kurtosis:                       3.108   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mean_markup = data[['Market_ID','Markup']].groupby('Market_ID').mean()\n",
    "no_firms = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "\n",
    "model_q2 = sm.OLS(mean_markup,sm.add_constant(no_firms))\n",
    "result_q2 = model_q2.fit()\n",
    "print result_q2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Marginal Costs\n",
    "\n",
    "The following regression will show the relationship between Marginal costs and the plan characteristics. We can se it is increasing in all except satisfaction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Marginal Cost   R-squared:                       0.359\n",
      "Model:                            OLS   Adj. R-squared:                  0.358\n",
      "Method:                 Least Squares   F-statistic:                     614.2\n",
      "Date:                Mon, 12 Nov 2018   Prob (F-statistic):          4.08e-317\n",
      "Time:                        10:39:11   Log-Likelihood:                 3556.3\n",
      "No. Observations:                3300   AIC:                            -7105.\n",
      "Df Residuals:                    3296   BIC:                            -7080.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  1.3735      0.033     41.797      0.000       1.309       1.438\n",
      "Network Score          0.0400      0.050      0.800      0.424      -0.058       0.138\n",
      "Satisfaction Score    -0.1709      0.036     -4.702      0.000      -0.242      -0.100\n",
      "PPO                    0.1236      0.003     42.495      0.000       0.118       0.129\n",
      "==============================================================================\n",
      "Omnibus:                      397.071   Durbin-Watson:                   1.092\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4138.012\n",
      "Skew:                           0.045   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.485   Cond. No.                         69.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_q3 = sm.OLS(data['Marginal Cost'], \n",
    "                   sm.add_constant(data[['Network Score','Satisfaction Score','PPO']]))\n",
    "result_q3 = model_q3.fit()\n",
    "print result_q3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Counterfactuals\n",
    "\n",
    "The code below is designed to recompute the Nash Betrand Equilibrium in each market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mkt_sim_s(p, data, v, xi, theta1, theta2,nobs):\n",
    "    \"\"\"only calculate sims within the same market\n",
    "    will use this when recalculating the FOCs\"\"\"\n",
    "    \n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1[:-1]) + p*theta1[-1]\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    x = x.transpose()\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, nobs))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = np.exp(delta + (theta2*v*x).sum(axis=1)).transpose()\n",
    "    \n",
    "    return  (1./ (sim_exp.sum(axis=0) +1) ) * sim_exp\n",
    "\n",
    "\n",
    "def cal_mkt_s(p, data, v, xi, theta1, theta2,nobs):\n",
    "    \"\"\"calc market share within the same market\"\"\"\n",
    "    shares = (1./NSIM)*cal_mkt_sim_s(p, data, v, xi, theta1, theta2,nobs).sum(axis=1)\n",
    "\n",
    "    return shares\n",
    "\n",
    "\n",
    "def cal_mkt_deriv(p, data, v, xi, theta1, theta2 , nobs):\n",
    "    \"\"\"calculate price derivative, but only in the same market\"\"\"\n",
    "    alpha = abs(theta1[-1])\n",
    "    sim_shares = cal_mkt_sim_s(p, data, v, xi, theta1, theta2, nobs)\n",
    "    own_deriv  = -(1-sim_shares) * sim_shares\n",
    "    \n",
    "    own_deriv = own_deriv.sum(axis=1)\n",
    "    sim_deriv = 1./(NSIM) * alpha * (own_deriv)\n",
    "\n",
    "    return sim_deriv\n",
    "\n",
    "\n",
    "def comp_foc(p, data, v, xi, theta1, theta2, subs, nobs):\n",
    "    \"\"\"compute the first order condition (market by market)\"\"\"\n",
    "    shares =  cal_mkt_s(p, data, v, xi, theta1, theta2,  nobs)\n",
    "    #caclulate formula\n",
    "    own_deriv  = cal_mkt_deriv(p, data, v, xi, theta1, theta2 , nobs)\n",
    "    inv_deriv = 1/own_deriv\n",
    "    markup = - inv_deriv*shares\n",
    "    return markup - (p - data['Marginal Cost'] + subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerically solve on a market by market basis\n",
    "new_prices = [[]] * NMKTS\n",
    "\n",
    "\n",
    "for i in range(1,NMKTS+1):\n",
    "    #set up mkt level variables\n",
    "    mkt_data = data.copy()[data['Market_ID'] == i]\n",
    "    \n",
    "    mkt_data['Marginal Costs'] = (mkt_data.copy()['Marginal Cost'] ) #apply subsidy\n",
    "    mkt_obs = mkt_data['Plan_ID'].count()\n",
    "    mkt_prices = np.array(mkt_data['Premium']).squeeze()\n",
    "    mkt_xi = mkt_data['Unobs']\n",
    "    \n",
    "    #get the right simulation draws\n",
    "    first_ind = mkt_data.index.values[0]\n",
    "    last_ind = mkt_data.index.values[-1] + 1\n",
    "    mkt_v = v[:,:,first_ind:last_ind]\n",
    "    \n",
    "    #calculate FOCs\n",
    "    mkt_new_prices = fsolve(comp_foc, mkt_prices, args= (mkt_data, mkt_v, mkt_xi,\n",
    "                                                         theta1, theta2, .25, mkt_obs) )\n",
    "    new_prices[i-1] = mkt_new_prices\n",
    "    \n",
    "\n",
    "#flatten result to 1d array\n",
    "new_prices = np.array([ p for  mkt_new_prices in new_prices for p in  mkt_new_prices ])\n",
    "\n",
    "#write to file\n",
    "np.savetxt('prices_blp.csv', new_prices, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid caclulating everytime\n",
    "new_prices = np.genfromtxt('prices_blp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Uninsurance rate\n",
    "\n",
    "Below we calcualte how much the uninsurance rate delcined after the the subsidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside Good (Before Rebate): 0.134505918182\n",
      "Outside Good (After Rebate): 0.118173319137\n"
     ]
    }
   ],
   "source": [
    "#outside good shares\n",
    "\n",
    "cf_data = data.copy()\n",
    "data = comp_outside_good(data,'Inside Good Share')\n",
    "\n",
    "cf_data['Premium'] = new_prices\n",
    "cf_data['New Inside Good'] =  cal_s(cf_data, v, xi, theta1, theta2)\n",
    "cf_data = comp_outside_good(cf_data,'New Inside Good')\n",
    "\n",
    "#compare the mean outside good before and after the rebate. It decreases.\n",
    "print 'Outside Good (Before Rebate): %s'%data['Outside Good Share'].mean()\n",
    "print 'Outside Good (After Rebate): %s'%cf_data['Outside Good Share'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Change in Profits\n",
    "Below we ecalculate the change in profits per enrollee after the rebate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Enrollee (Before Rebate): 1.14041233609\n",
      "Per Enrollee (After Rebate): 1.1421989598\n"
     ]
    }
   ],
   "source": [
    "#profits per enrollee, comparision\n",
    "print 'Per Enrollee (Before Rebate): %s'%(data['Premium'] - cf_data['Marginal Cost']).mean()\n",
    "print 'Per Enrollee (After Rebate): %s'%(cf_data['Premium'] - cf_data['Marginal Cost'] + .25).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Change in Consumer Surplus\n",
    "\n",
    "Below we calculate the change in consumer surplus using the formula in Train. Specifically, we use:\n",
    "\n",
    "$$\\Delta E(CS_n)  = \\dfrac{1}{\\alpha} [ln(\\sum_j ln( e^{\\delta^1_{ji}} ) - ln(e^{\\delta^0_{ji}}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_sim_exp(data, v, xi, theta1, theta2):\n",
    "    \"\"\"simulate utility in every market\"\"\"\n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO', 'Premium']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1)\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    x = (x.transpose()[:-1])\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, NOBS))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() , \n",
    "                           index= data.index )\n",
    "    return sim_exp\n",
    "\n",
    "\n",
    "def comp_exp(data, v, xi, theta1, theta2):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates individual choice probability first, then take sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*comp_sim_exp(data, v, xi, theta1, theta2 ).sum(axis=1)\n",
    "    return shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in consumer surplus: 0.2493774901778668\n"
     ]
    }
   ],
   "source": [
    "def comp_surplus(data, cf_data, v, xi, theta1, theta2 ):\n",
    "    \"\"\" compute exp(delta_j) to compute the change in consumer surplus \"\"\"\n",
    "    \n",
    "    alpha = abs(theta1[-1])\n",
    "    exp = comp_exp(data, v, xi, theta1, theta2)\n",
    "    \n",
    "    cf_exp = comp_exp(cf_data, v, xi, theta1, theta2 )\n",
    "    \n",
    "    utility_ratio = cf_exp.sum()/exp.sum()\n",
    "    return 1/alpha * np.log( utility_ratio )\n",
    "\n",
    "\n",
    "print 'Change in consumer surplus: %s'%comp_surplus(data, cf_data, v, xi, theta1, theta2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surplus and market structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.689\n",
      "Model:                            OLS   Adj. R-squared:                  0.688\n",
      "Method:                 Least Squares   F-statistic:                     1322.\n",
      "Date:                Mon, 12 Nov 2018   Prob (F-statistic):          1.34e-153\n",
      "Time:                        10:39:54   Log-Likelihood:                 2980.5\n",
      "No. Observations:                 600   AIC:                            -5957.\n",
      "Df Residuals:                     598   BIC:                            -5948.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2395      0.000   1031.209      0.000       0.239       0.240\n",
      "Plan_ID        0.0015   4.03e-05     36.358      0.000       0.001       0.002\n",
      "==============================================================================\n",
      "Omnibus:                       21.104   Durbin-Watson:                   1.458\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               50.918\n",
      "Skew:                           0.025   Prob(JB):                     8.77e-12\n",
      "Kurtosis:                       4.426   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "def sum_by_mkt(inner, data):\n",
    "    \"\"\"function for summing utility by market\"\"\"\n",
    "    inner['mkt_id'] = data['Market_ID']\n",
    "    inner = inner.groupby('mkt_id').sum()\n",
    "    return inner\n",
    "\n",
    "\n",
    "def comp_surplus_mkt(data, cf_data, v, xi, theta1, theta2 ):\n",
    "    \"\"\"compute the change in consumer surplus on a \n",
    "    per market basis \"\"\"\n",
    "    alpha = abs(theta1[-1])\n",
    "    \n",
    "    #compute surplus change by market\n",
    "    exp = comp_exp(data, v, xi, theta1, theta2 )\n",
    "    exp = sum_by_mkt(exp, data)\n",
    "    cf_exp = comp_exp(cf_data, v, xi, theta1, theta2 )\n",
    "    cf_exp = sum_by_mkt(cf_exp, data)\n",
    "    \n",
    "    utility_ratio = np.array(cf_exp/exp)\n",
    "    return 1/alpha * np.log( utility_ratio )\n",
    "    \n",
    "    \n",
    "\n",
    "mkt_surplus = comp_surplus_mkt(data, cf_data, v, xi, theta1, theta2 )\n",
    "no_firms = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "\n",
    "model_q4 = sm.OLS(mkt_surplus,sm.add_constant(no_firms))\n",
    "result_q4 = model_q4.fit()\n",
    "print result_q4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the table above, we can see that surplus is increasing with the number of firms in each market. This is because when there are more firms, the rebate is passed more directly to consumers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "The answers are roughly the same between BLP and the logit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
