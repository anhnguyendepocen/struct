{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_outside_good(data,name):\n",
    "    #pre-processing to calculate outside good shares\n",
    "    shares = data[['Market_ID',name]].copy()\n",
    "\n",
    "    group_shares = shares.groupby('Market_ID').sum()\n",
    "    group_shares['Outside Good Share'] = 1 - group_shares[name]\n",
    "\n",
    "    data = pd.merge(data,group_shares[['Outside Good Share']], \n",
    "                right_index=True, left_on = 'Market_ID')\n",
    "    return data\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 16 3300\n"
     ]
    }
   ],
   "source": [
    "#set up useful global variables \n",
    "NMKTS = data['Market_ID'].nunique()\n",
    "NPLANS = data['Plan_ID'].nunique()\n",
    "NOBS = data['Plan_ID'].count()\n",
    "NSIM = 50\n",
    "\n",
    "#initialize theta1 and theta2 based on estimates\n",
    "theta1 = np.array([3.79292846,  1.95860809,  0.75734848, -1.47436869 ])\n",
    "theta2 =  np.array([2.47702906, 1.15401209, 1.00765258])\n",
    "xi = np.genfromtxt('xi.csv', delimiter=',')\n",
    "\n",
    "v0 = np.genfromtxt('simulations.csv', delimiter=',')\n",
    "v = np.tile(v0.reshape(NSIM,3,1) , (1,1,NOBS))\n",
    "\n",
    "#print global variables\n",
    "print NMKTS,NPLANS,NOBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_same_mkt(data):\n",
    "    same_mkt = np.array([data['Market_ID']],dtype=np.float32 )\n",
    "    same_mkt = (same_mkt.transpose()).dot( 1/same_mkt)\n",
    "    same_mkt = np.equal(same_mkt,np.ones((NOBS,NOBS)) )\n",
    "    same_mkt = same_mkt.astype(np.float32)\n",
    "    return same_mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sim_s(data, v, xi, theta1, theta2):\n",
    "    \"\"\"calculate market share across each simulated consumer\n",
    "    \n",
    "    Note: we are not summing accross consumers when this is called\n",
    "    \n",
    "    Also note: this function takes different arguments than the \n",
    "    one from estimation\"\"\"\n",
    "    \n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO', 'Premium']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1)\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    \n",
    "    x = (x.transpose()[:-1])\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, NOBS))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() , \n",
    "                           index= data.index ) \n",
    "    \n",
    "    #sum up between markets\n",
    "    sim_exp['mkt_id'] = data['Market_ID']\n",
    "    sum_exp = sim_exp.groupby('mkt_id').sum() \n",
    "    sum_exp = pd.merge(data.copy()[['Market_ID']], sum_exp, \n",
    "                       right_index=True, left_on = 'Market_ID')\n",
    "    \n",
    "    #format so I can broadcast\n",
    "    sim_exp = np.array(sim_exp).transpose()[:-1]\n",
    "    sum_exp = np.array(sum_exp).transpose()[1:] + 1\n",
    "    \n",
    "    return sim_exp/sum_exp\n",
    "\n",
    "\n",
    "def cal_s(data, v, xi, theta1, theta2):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates choice probability in each simulation, \n",
    "    then takes the sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*cal_sim_s(data, v, xi, theta1, theta2)\n",
    "    shares = (1./NSIM)*cal_sim_s(data, v, xi, theta1, theta2).sum(axis=0)\n",
    "    return shares\n",
    "\n",
    "sim_s = cal_s(data, v, xi, theta1, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Elasticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n",
      "[[-2.92605277  0.76400122  0.57909378 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.13900628 -2.44754321  0.87149389 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.26016957  1.27207397 -2.13299913 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.          0.         ... -3.56039465  0.30233522\n",
      "   0.35700305]\n",
      " [ 0.          0.          0.         ...  0.32592397 -2.96134151\n",
      "   0.32779493]\n",
      " [ 0.          0.          0.         ...  0.51562516  0.43917422\n",
      "  -3.20069863]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cal_price_deriv(data, v, xi, theta1, theta2):\n",
    "    \"\"\"calculate own price derivative\"\"\" \n",
    "    alpha = abs(theta1[-1])\n",
    "    same_mkt = cal_same_mkt(data)\n",
    "    sim_shares = cal_sim_s(data, v, xi, theta1, theta2)\n",
    "    cross_deriv = np.zeros((NOBS,NOBS))\n",
    "    for sim_share in sim_shares:\n",
    "        sim_share = sim_share.reshape((NOBS,1))\n",
    "        cross_deriv = cross_deriv + sim_share.dot(sim_share.transpose())*same_mkt\n",
    "        \n",
    "    own = np.identity(NOBS)\n",
    "    cross = (1 - own)\n",
    "    own_deriv  = -(1-sim_shares) * sim_shares\n",
    "\n",
    "    own_deriv = own_deriv.sum(axis=0)\n",
    "    \n",
    "    sim_deriv = 1./(NSIM) * alpha * (cross_deriv*cross +own_deriv*own )\n",
    "    return sim_deriv\n",
    "\n",
    "\n",
    "def cal_price_elast(data, v, xi, theta1, theta2):\n",
    "    \"\"\"calculate the elasticity using the price derivative matrix\"\"\"\n",
    "    \n",
    "    share = np.array([data['Inside Good Share']])\n",
    "    price = np.array([data['Premium']]).transpose()\n",
    "    deriv = cal_price_deriv(data, v, xi, theta1, theta2)\n",
    "    return (price).dot(1/share)*deriv\n",
    "\n",
    "elast = cal_price_elast(data, v, xi, theta1, theta2)\n",
    "print elast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_avg_elasticity(data, v, xi, theta1, theta2):\n",
    "    \"\"\"figure out what the average elasticty between goods is\"\"\"\n",
    "    elast = cal_price_elast(data, v, xi, theta1, theta2)\n",
    "    \n",
    "    #who cares about run time?\n",
    "    avg_elasticity = np.zeros((NPLANS,NPLANS))\n",
    "    \n",
    "    elast = elast\n",
    "    \n",
    "    \n",
    "    plan_mkt = np.array(data[['Plan_ID']])\n",
    "    for plan_j in range(1,NPLANS+1):\n",
    "        for plan_k in range(1,NPLANS+1):\n",
    "            data_k = data[ (data['Plan_ID'] == plan_k) ].index.values\n",
    "            data_j = data[ (data['Plan_ID'] == plan_j)].index.values\n",
    "            if len(data_k) >0 and len(data_j) > 0:\n",
    "                lenobs = 0\n",
    "                for ind_j in data_j:\n",
    "                    for ind_k in data_k:\n",
    "                        avg_elasticity[plan_j-1][plan_k-1] = (avg_elasticity[plan_j-1][plan_k-1]\n",
    "                                                               + elast[ind_j][ind_k]) \n",
    "                        lenobs = lenobs + same_mkt[ind_j][ind_k]\n",
    "                avg_elasticity[plan_j-1][plan_k-1] =  (avg_elasticity[plan_j-1][plan_k-1]\n",
    "                                                        /lenobs)\n",
    "                \n",
    "    return avg_elasticity\n",
    "                \n",
    "avg_elasticity = comp_avg_elasticity(data, v, xi, theta1, theta2)\n",
    "np.savetxt(\"elasticity.csv\", avg_elasticity, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the average cross price elasticities calculated using the random coefficients among the 16 plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2          3          4          5   \\\n",
      "0  -44.142074   4.229599  12.128709   8.949837   5.220670   6.673555   \n",
      "1    4.229599 -28.811290   5.734812   4.271177   4.247828   5.590400   \n",
      "2   12.128709   5.734812 -46.457238   8.876038   5.673209   7.346797   \n",
      "3    8.949837   4.271177   8.876038 -38.343670   4.589591   6.329595   \n",
      "4    5.220670   4.247828   5.673209   4.589591 -30.003201   5.425510   \n",
      "5    6.673555   5.590400   7.346797   6.329595   5.425510 -36.514769   \n",
      "6    9.405518   5.198366  10.349210   9.750692   5.324438   6.272727   \n",
      "7    7.356074   6.269100   6.881948   5.285341   5.197053   7.142302   \n",
      "8    9.438004   4.175607  10.063152   9.050425   4.190293   5.710544   \n",
      "9    4.084806   3.275628   4.203350   3.465120   3.761349   4.736849   \n",
      "10   5.557813   4.853855   5.989162   4.960306   3.985310   5.820759   \n",
      "11  11.020038   4.929080  10.801377   9.730867   4.980816   6.479405   \n",
      "12   7.517452   3.964241   9.986908   6.816183   4.595642   6.298611   \n",
      "13   6.078417   5.112169   6.550025   4.810929   5.730082   6.742369   \n",
      "14  10.950360   5.451227  11.663968  10.170598   5.823850   6.115974   \n",
      "15   5.690411   5.108819   7.083786   5.135243   6.158672   7.044161   \n",
      "\n",
      "           6          7          8          9          10         11  \\\n",
      "0    9.405518   7.356074   9.438004   4.084806   5.557813  11.020038   \n",
      "1    5.198366   6.269100   4.175607   3.275628   4.853855   4.929080   \n",
      "2   10.349210   6.881948  10.063152   4.203350   5.989162  10.801377   \n",
      "3    9.750692   5.285341   9.050425   3.465120   4.960306   9.730867   \n",
      "4    5.324438   5.197053   4.190293   3.761349   3.985310   4.980816   \n",
      "5    6.272727   7.142302   5.710544   4.736849   5.820759   6.479405   \n",
      "6  -43.786070   6.434325   9.485919   4.242607   5.602977  10.291472   \n",
      "7    6.434325 -36.733837   5.454748   4.526740   5.855428   6.387313   \n",
      "8    9.485919   5.454748 -38.853615   3.559803   5.438563   8.741574   \n",
      "9    4.242607   4.526740   3.559803 -24.423111   4.092771   3.683821   \n",
      "10   5.602977   5.855428   5.438563   4.092771 -31.069561   5.063281   \n",
      "11  10.291472   6.387313   8.741574   3.683821   5.063281 -43.502802   \n",
      "12   8.615829   4.707408   7.679953   3.895399   4.807943   7.834592   \n",
      "13   6.263324   6.598637   5.314513   3.556333   5.539331   6.171208   \n",
      "14  11.760354   6.971709   9.803598   4.410699   5.144437  10.906968   \n",
      "15   6.533698   5.889469   5.796477   4.719555   5.773914   5.987667   \n",
      "\n",
      "           12         13         14         15  \n",
      "0    7.517452   6.078417  10.950360   5.690411  \n",
      "1    3.964241   5.112169   5.451227   5.108819  \n",
      "2    9.986908   6.550025  11.663968   7.083786  \n",
      "3    6.816183   4.810929  10.170598   5.135243  \n",
      "4    4.595642   5.730082   5.823850   6.158672  \n",
      "5    6.298611   6.742369   6.115974   7.044161  \n",
      "6    8.615829   6.263324  11.760354   6.533698  \n",
      "7    4.707408   6.598637   6.971709   5.889469  \n",
      "8    7.679953   5.314513   9.803598   5.796477  \n",
      "9    3.895399   3.556333   4.410699   4.719555  \n",
      "10   4.807943   5.539331   5.144437   5.773914  \n",
      "11   7.834592   6.171208  10.906968   5.987667  \n",
      "12 -35.589024   4.566921   8.570032   5.087016  \n",
      "13   4.566921 -33.783581   6.459675   5.961876  \n",
      "14   8.570032   6.459675 -45.920104   7.084526  \n",
      "15   5.087016   5.961876   7.084526 -34.503467  \n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(avg_elasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markups\n",
    "\n",
    "How does the markup vary with market structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_markup(data, v, xi, theta1, theta2):\n",
    "    \n",
    "    shares = np.array(data['Inside Good Share'])\n",
    "    #caclulate formula\n",
    "    own_deriv  = cal_price_deriv(data, v, xi, theta1, theta2)\n",
    "    own_deriv = np.diag(own_deriv)\n",
    "    \n",
    "    #take inverse and calc markup\n",
    "    inv_deriv = 1/own_deriv\n",
    "    markup = - inv_deriv*shares\n",
    "    return markup\n",
    "\n",
    "\n",
    "data['Markup'] = comp_markup(data, v, xi, theta1, theta2)\n",
    "data['Marginal Cost'] = data['Premium'] - data['Markup']\n",
    "data['Unobs'] = xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we calculate the average markup per plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Markup\n",
      "Plan_ID          \n",
      "1        0.892770\n",
      "2        0.786449\n",
      "3        0.913874\n",
      "4        0.849613\n",
      "5        0.792455\n",
      "6        0.836131\n",
      "7        0.893042\n",
      "8        0.846347\n",
      "9        0.849672\n",
      "10       0.764218\n",
      "11       0.800794\n",
      "12       0.885903\n",
      "13       0.837991\n",
      "14       0.821563\n",
      "15       0.917050\n",
      "16       0.821938\n"
     ]
    }
   ],
   "source": [
    "print data[['Plan_ID','Markup']].groupby('Plan_ID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the more plans in a market, the lower the markup. This is the same as the previous homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Markup   R-squared:                       0.858\n",
      "Model:                            OLS   Adj. R-squared:                  0.858\n",
      "Method:                 Least Squares   F-statistic:                     3621.\n",
      "Date:                Sun, 11 Nov 2018   Prob (F-statistic):          6.89e-256\n",
      "Time:                        10:42:37   Log-Likelihood:                 1251.3\n",
      "No. Observations:                 600   AIC:                            -2499.\n",
      "Df Residuals:                     598   BIC:                            -2490.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1051      0.004    266.550      0.000       1.097       1.113\n",
      "Plan_ID       -0.0433      0.001    -60.176      0.000      -0.045      -0.042\n",
      "==============================================================================\n",
      "Omnibus:                       50.578   Durbin-Watson:                   0.586\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.318\n",
      "Skew:                           0.771   Prob(JB):                     4.84e-14\n",
      "Kurtosis:                       3.274   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mean_markup = data[['Market_ID','Markup']].groupby('Market_ID').mean()\n",
    "no_firms = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "\n",
    "model_q2 = sm.OLS(mean_markup,sm.add_constant(no_firms))\n",
    "result_q2 = model_q2.fit()\n",
    "print result_q2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Marginal Costs\n",
    "\n",
    "The following regression will show the relationship between Marginal costs and the plan characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Marginal Cost   R-squared:                       0.534\n",
      "Model:                            OLS   Adj. R-squared:                  0.533\n",
      "Method:                 Least Squares   F-statistic:                     1258.\n",
      "Date:                Sun, 11 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        10:42:37   Log-Likelihood:                 4406.3\n",
      "No. Observations:                3300   AIC:                            -8805.\n",
      "Df Residuals:                    3296   BIC:                            -8780.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                  1.4380      0.025     56.614      0.000       1.388       1.488\n",
      "Network Score          0.1797      0.039      4.649      0.000       0.104       0.256\n",
      "Satisfaction Score    -0.0478      0.028     -1.701      0.089      -0.103       0.007\n",
      "PPO                    0.1371      0.002     60.985      0.000       0.133       0.141\n",
      "==============================================================================\n",
      "Omnibus:                      994.480   Durbin-Watson:                   1.499\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16185.372\n",
      "Skew:                           0.992   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.667   Cond. No.                         69.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model_q3 = sm.OLS(data['Marginal Cost'], \n",
    "                   sm.add_constant(data[['Network Score','Satisfaction Score','PPO']]))\n",
    "result_q3 = model_q3.fit()\n",
    "print result_q3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mkt_sim_s(p, data, v, xi, theta1, theta2,nobs):\n",
    "    \"\"\"only calculate sims within the same market\n",
    "    will use this when recalculating the FOCs\"\"\"\n",
    "    \n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1[:-1]) + p*theta1[-1]\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    x = x.transpose()\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, nobs))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = np.exp(delta + (theta2*v*x).sum(axis=1)).transpose()\n",
    "    \n",
    "    return  (1./ (sim_exp.sum(axis=0) +1) ) * sim_exp\n",
    "\n",
    "\n",
    "def cal_mkt_s(p, data, v, xi, theta1, theta2,nobs):\n",
    "    \"\"\"calc market share within the same market\"\"\"\n",
    "    shares = (1./NSIM)*cal_mkt_sim_s(p, data, v, xi, theta1, theta2,nobs).sum(axis=1)\n",
    "\n",
    "    return shares\n",
    "\n",
    "\n",
    "def cal_mkt_deriv(p, data, v, xi, theta1, theta2 , nobs):\n",
    "    \"\"\"calculate price derivative, but only in the same market\"\"\"\n",
    "    alpha = abs(theta1[-1])\n",
    "    sim_shares = cal_mkt_sim_s(p, data, v, xi, theta1, theta2, nobs)\n",
    "    own_deriv  = -(1-sim_shares) * sim_shares\n",
    "    \n",
    "    own_deriv = own_deriv.sum(axis=1)\n",
    "    sim_deriv = 1./(NSIM) * alpha * (own_deriv)\n",
    "\n",
    "    return sim_deriv\n",
    "\n",
    "\n",
    "def comp_foc(p, data, v, xi, theta1, theta2, subs, nobs):\n",
    "    \"\"\"compute the first order condition (market by market)\"\"\"\n",
    "    shares =  cal_mkt_s(p, data, v, xi, theta1, theta2,  nobs)\n",
    "    #caclulate formula\n",
    "    own_deriv  = cal_mkt_deriv(p, data, v, xi, theta1, theta2 , nobs)\n",
    "    inv_deriv = 1/own_deriv\n",
    "    markup = - inv_deriv*shares\n",
    "    return markup - (p - data['Marginal Cost'] + subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerically solve on a market by market basis\n",
    "new_prices = [[]] * NMKTS\n",
    "\n",
    "\n",
    "for i in range(1,NMKTS+1):\n",
    "    #set up mkt level variables\n",
    "    mkt_data = data.copy()[data['Market_ID'] == i]\n",
    "    mkt_data['Marginal Costs'] = (mkt_data.copy()['Marginal Cost'] ) #apply subsidy\n",
    "    mkt_obs = mkt_data['Plan_ID'].count()\n",
    "    mkt_prices = np.array(mkt_data['Premium']).squeeze()\n",
    "    mkt_v = np.tile(v0.reshape(NSIM,3,1) , (1,1,mkt_obs))\n",
    "    mkt_xi = mkt_data['Unobs']\n",
    "    \n",
    "    #calculate FOCs\n",
    "    mkt_new_prices = fsolve(comp_foc, mkt_prices, args= (mkt_data, mkt_v, mkt_xi,\n",
    "                                                         theta1, theta2, .25, mkt_obs) )\n",
    "    new_prices[i-1] = mkt_new_prices\n",
    "    \n",
    "\n",
    "#flatten result to 1d array\n",
    "new_prices = np.array([ p for  mkt_new_prices in new_prices for p in  mkt_new_prices ])\n",
    "\n",
    "#write to file\n",
    "np.savetxt('prices_blp.csv', new_prices, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid caclulating everytime\n",
    "new_prices = np.genfromtxt('prices_blp.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Uninsurance rate\n",
    "\n",
    "Below we calcualte how much the uninsurance rate delcined after the the subsidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside Good (Before Rebate): 0.134505918182\n",
      "Outside Good (After Rebate): 0.107288544577\n"
     ]
    }
   ],
   "source": [
    "#outside good shares\n",
    "\n",
    "cf_data = data.copy()\n",
    "data = comp_outside_good(data,'Inside Good Share')\n",
    "\n",
    "cf_data['Premium'] = new_prices\n",
    "cf_data['New Inside Good'] =  cal_s(cf_data, v, xi, theta1, theta2)\n",
    "cf_data = comp_outside_good(cf_data,'New Inside Good')\n",
    "\n",
    "#compare the mean outside good before and after the rebate. It decreases.\n",
    "print 'Outside Good (Before Rebate): %s'%data['Outside Good Share'].mean()\n",
    "print 'Outside Good (After Rebate): %s'%cf_data['Outside Good Share'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Change in Profits\n",
    "Below we ecalculate the change in profits per enrollee after the rebate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Enrollee (Before Rebate): 0.843850773635\n",
      "Per Enrollee (After Rebate): 0.847090861972\n"
     ]
    }
   ],
   "source": [
    "#profits per enrollee, comparision\n",
    "print 'Per Enrollee (Before Rebate): %s'%(data['Premium'] - cf_data['Marginal Cost']).mean()\n",
    "print 'Per Enrollee (After Rebate): %s'%(cf_data['Premium'] - cf_data['Marginal Cost'] + .25).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Change in Consumer Surplus\n",
    "\n",
    "Below we calculate the change in consumer surplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_sim_exp(data, v, xi, theta1, theta2):\n",
    "    \"\"\"simulate utility in every market\"\"\"\n",
    "    #copy x and delta for simulations using tiling\n",
    "    x =  np.array(data.copy()[['Network Score','Satisfaction Score','PPO', 'Premium']])\n",
    "    delta = xi + np.matmul(np.array(x),theta1)\n",
    "    delta  = np.tile( delta  ,(NSIM,1))\n",
    "    \n",
    "    x = (x.transpose()[:-1])\n",
    "    x  = np.tile(x,(NSIM,1,1))\n",
    "    theta2 = np.tile( np.array([theta2]).transpose()  ,(NSIM,1, NOBS))\n",
    "    \n",
    "    #add to calcualte market shares\n",
    "    sim_exp = pd.DataFrame( np.exp(delta + (theta2*v*x).sum(axis=1)).transpose() , \n",
    "                           index= data.index )\n",
    "    return sim_exp\n",
    "\n",
    "\n",
    "def comp_exp(data, v, xi, theta1, theta2):\n",
    "    \"\"\"Calculate market share\n",
    "    Calculates individual choice probability first, then take sum\"\"\"\n",
    "    \n",
    "    shares = (1./NSIM)*comp_sim_exp(data, v, xi, theta1, theta2 ).sum(axis=1)\n",
    "    return shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in consumer surplus: 0.24700632946140574\n"
     ]
    }
   ],
   "source": [
    "def comp_surplus(data, cf_data, v, xi, theta1, theta2 ):\n",
    "    \"\"\" compute exp(delta_j) to compute the change in consumer surplus \"\"\"\n",
    "    \n",
    "    alpha = abs(theta1[-1])\n",
    "    exp = comp_exp(data, v, xi, theta1, theta2)\n",
    "    \n",
    "    cf_exp = comp_exp(cf_data, v, xi, theta1, theta2 )\n",
    "    \n",
    "    utility_ratio = cf_exp.sum()/exp.sum()\n",
    "    return 1/alpha * np.log( utility_ratio )\n",
    "\n",
    "\n",
    "print 'Change in consumer surplus: %s'%comp_surplus(data, cf_data, v, xi, theta1, theta2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surplus and market structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.859\n",
      "Model:                            OLS   Adj. R-squared:                  0.859\n",
      "Method:                 Least Squares   F-statistic:                     3643.\n",
      "Date:                Sun, 11 Nov 2018   Prob (F-statistic):          1.48e-256\n",
      "Time:                        11:07:26   Log-Likelihood:                 3163.4\n",
      "No. Observations:                 600   AIC:                            -6323.\n",
      "Df Residuals:                     598   BIC:                            -6314.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2360      0.000   1378.319      0.000       0.236       0.236\n",
      "Plan_ID        0.0018   2.97e-05     60.357      0.000       0.002       0.002\n",
      "==============================================================================\n",
      "Omnibus:                       28.390   Durbin-Watson:                   0.524\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.840\n",
      "Skew:                          -0.538   Prob(JB):                     2.01e-07\n",
      "Kurtosis:                       2.728   Cond. No.                         20.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "def sum_by_mkt(inner, data):\n",
    "    \"\"\"function for summing utility by market\"\"\"\n",
    "    inner['mkt_id'] = data['Market_ID']\n",
    "    inner = inner.groupby('mkt_id').sum()\n",
    "    return inner\n",
    "\n",
    "\n",
    "def comp_surplus_mkt(data, cf_data, v, xi, theta1, theta2 ):\n",
    "    \"\"\"compute the change in consumer surplus on a \n",
    "    per market basis \"\"\"\n",
    "    alpha = abs(theta1[-1])\n",
    "    \n",
    "    #compute surplus change by market\n",
    "    exp = comp_exp(data, v, xi, theta1, theta2 )\n",
    "    exp = sum_by_mkt(exp, data)\n",
    "    cf_exp = comp_exp(cf_data, v, xi, theta1, theta2 )\n",
    "    cf_exp = sum_by_mkt(cf_exp, data)\n",
    "    \n",
    "    utility_ratio = np.array(cf_exp/exp)\n",
    "    return 1/alpha * np.log( utility_ratio )\n",
    "    \n",
    "    \n",
    "\n",
    "mkt_surplus = comp_surplus_mkt(data, cf_data, v, xi, theta1, theta2 )\n",
    "no_firms = data[['Market_ID','Plan_ID']].groupby('Market_ID').count()\n",
    "\n",
    "model_q4 = sm.OLS(mkt_surplus,sm.add_constant(no_firms))\n",
    "result_q4 = model_q4.fit()\n",
    "print result_q4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the table above, we can see that surplus is increasing with the number of firms in each market. This is because when there are more firms, the rebate is passed more directly to consumers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "The answers are roughly the same between BLP and the logit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
