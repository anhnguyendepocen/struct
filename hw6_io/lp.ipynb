{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy\n",
    "\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata('chile.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata = data.copy()\n",
    "\n",
    "ldata[['routput', 'totlab', 'renerg','realmats',\n",
    "       'rcapstock']] = np.log(data[['routput','totlab', 'renerg','realmats','rcapstock']])\n",
    "\n",
    "ldata = ldata.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ldata['routput'],ldata[['renerg','totlab']],ldata[['rcapstock','realmats']],ldata[['id','year']]\n",
    "\n",
    "def np_resids(y,x):\n",
    "    \"\"\"residuals from lasso\"\"\"\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=7)\n",
    "    x_poly = poly.fit_transform(x)\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    clf.fit(x_poly, y) \n",
    "    resid = y-clf.predict(x_poly)\n",
    "    return resid\n",
    "\n",
    "#print np_resids(ldata['routput'],ldata[['rcapstock','realmats']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.191\n",
      "Model:                            OLS   Adj. R-squared:                  0.191\n",
      "Method:                 Least Squares   F-statistic:                     2445.\n",
      "Date:                Mon, 13 May 2019   Prob (F-statistic):               0.00\n",
      "Time:                        18:28:03   Log-Likelihood:                -3003.4\n",
      "No. Observations:               20717   AIC:                             6011.\n",
      "Df Residuals:                   20715   BIC:                             6027.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "renerg         0.0837      0.002     38.705      0.000       0.079       0.088\n",
      "totlab         0.1680      0.004     45.382      0.000       0.161       0.175\n",
      "==============================================================================\n",
      "Omnibus:                     5908.594   Durbin-Watson:                   1.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            41747.119\n",
      "Skew:                           1.186   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.538   Cond. No.                         1.85\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "def robinson(dta):\n",
    "    \"\"\"y is dependent variable\n",
    "    x has parametric coefficients\n",
    "    z is nonparameteric variables\"\"\"\n",
    "    \n",
    "    y,x,z,label = dta\n",
    "    \n",
    "    y_resid = np_resids(y,z)\n",
    "    x_resid = []\n",
    "    for col in x.columns:\n",
    "        resid = np_resids(x[col],z)\n",
    "        x_resid.append(resid)\n",
    "    x_resid = np.array(x_resid).transpose()\n",
    "    x_resid = pd.DataFrame(data=x_resid,columns=x.columns)\n",
    "    return sm.OLS(np.array(y_resid),x_resid)\n",
    "\n",
    "    \n",
    "stage1 = robinson(d)\n",
    "stage1_res = stage1.fit()\n",
    "print stage1_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07214819, -0.20580687,  0.28069225, ...,  0.32109226,\n",
       "        0.22290829, -0.59066547])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stage2obj(zparams, xparams, dta):\n",
    "    \n",
    "    y,x,z,label = dta\n",
    "    t = label['year']\n",
    "    #period1 = np.tile((1979<=t) & (t<=1981),z.shape[1]+1).reshape(z.shape[0],z.shape[1]+1)\n",
    "    #period2 = np.tile((1982<=t) & (t<=1983),z.shape[1]+1).reshape(z.shape[0],z.shape[1]+1)\n",
    "    #period3 = np.tile((1984<=t) & (t<=1986),z.shape[1]+1).reshape(z.shape[0],z.shape[1]+1)\n",
    "    \n",
    "    #compute value added to production by z\n",
    "    xparams_tile = np.tile(xparams,x.shape[0]).reshape(x.shape[0],x.shape[1])\n",
    "    zvalue = y - (xparams_tile*x).sum(axis=1) \n",
    "    \n",
    "    #compute predict value added ahead of time\n",
    "    zcons = sm.add_constant(z)\n",
    "    #z_period = np.concatenate((zcons*period1,zcons*period2,zcons*period3),axis=1)\n",
    "    #zvalue_predict = sm.OLS(zvalue,z_period).fit().fittedvalues\n",
    "    zvalue_predict = sm.OLS(zvalue,z).fit().fittedvalues\n",
    "    \n",
    "    #use the difference to learn the shock to production\n",
    "    zparams_tile = np.tile(zparams,z.shape[0]).reshape(z.shape[0],z.shape[1])\n",
    "    \n",
    "    #calc shock (mostly formating correctly)\n",
    "    shock = zvalue - (zparams_tile*z).sum(axis=1)\n",
    "    shock = np.array(shock).reshape((shock.shape[0],1))\n",
    "    \n",
    "    shocklag = zvalue_predict - (zparams_tile*z).sum(axis=1)\n",
    "    shocklag = np.array(shocklag).reshape((shocklag.shape[0],1))\n",
    "    \n",
    "    shocklag = np.concatenate((shocklag,label[['id','year']]),axis=1)\n",
    "    shocklag = pd.DataFrame(shocklag,columns=['shock2','id','year'])\n",
    "    shocklag = shocklag.set_index(['id','year'])\n",
    "    shocklag = shocklag.groupby('id').shift(1)\n",
    "    \n",
    "    \n",
    "    #clean 'exogenous' portion of production\n",
    "    both_shocks = np.concatenate((shocklag,shock),axis=1)\n",
    "    both_shocks = both_shocks[~np.isnan(both_shocks).any(axis=1)]\n",
    "    shocklag = both_shocks[:,0].reshape(both_shocks.shape[0],1)\n",
    "    npshocklag = np.concatenate((shocklag,shocklag**2,shocklag**3),axis=1)\n",
    "    npshocklag = sm.add_constant(npshocklag)\n",
    "    \n",
    "    return sm.OLS(both_shocks[:,1],npshocklag).fit().resid\n",
    "    \n",
    "    \n",
    "d = ldata['routput'],ldata[['renerg','totlab']],ldata[['rcapstock','realmats']],ldata[['id','year']]\n",
    "\n",
    "stage2obj(np.array([.5,.5]),np.array([.0837,.1680]),d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000081\n",
      "         Iterations: 19\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000792\n",
      "         Iterations: 13\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001166\n",
      "         Iterations: 6\n",
      "         Function evaluations: 10\n",
      "         Gradient evaluations: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001188\n",
      "         Iterations: 1\n",
      "         Function evaluations: 3\n",
      "         Gradient evaluations: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001188\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n",
      "                                  LP Results                                  \n",
      "==============================================================================\n",
      "Dep. Variable:                routput   Hansen J:                        21.43\n",
      "Model:                             LP   Prob (Hansen J):              2.22e-05\n",
      "Method:                           GMM                                         \n",
      "Date:                Mon, 13 May 2019                                         \n",
      "Time:                        18:28:18                                         \n",
      "No. Observations:               20717                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "rcapstock      0.0776      0.040      1.916      0.055      -0.002       0.157\n",
      "realmats       1.0609      0.132      8.029      0.000       0.802       1.320\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "class LP(GMM):\n",
    "    \n",
    "    def __init__(self, dta, stage1_params, *args, **kwds):\n",
    "        # set appropriate counts for moment conditions and parameters\n",
    "        y,x,z,label = dta\n",
    "        super(LP, self).__init__(y,x,z, z.shape[1] +x.shape[1],*args, **kwds)\n",
    "        self.endog = y\n",
    "        self.exog = x\n",
    "        self.instr = z\n",
    "        self.ids = label\n",
    "        self.stage1_params = stage1_params\n",
    "        \n",
    "        \n",
    "        #self up a lag variable\n",
    "        exogs = np.concatenate((x, z, label[['id','year']]),axis=1)\n",
    "        colnames = ['x'+str(i) for i in range(self.nmoms)]\n",
    "        colnames = colnames + ['id','year']\n",
    "        exogs = pd.DataFrame(exogs,columns= colnames )\n",
    "        exogs = exogs .set_index(['id','year'])\n",
    "        exogs = exogs .groupby('id').shift(1)\n",
    "        \n",
    "        self.exoglag = exogs.dropna()\n",
    "        self.data.xnames = [col for col in z.columns]\n",
    "        \n",
    "    def momcond(self, params):\n",
    "        d = self.endog, self.exog, self.instr, self.ids\n",
    "        resids = stage2obj(params, self.stage1_params , d)\n",
    "        resids_tile = np.repeat(resids,self.nmoms)\n",
    "        resids_tile = resids_tile.reshape((resids.shape[0],self.nmoms))\n",
    "        return resids_tile*self.exoglag\n",
    "        \n",
    "    \n",
    "\n",
    "lpmodel = LP(d,np.array([.0837,.1680]))\n",
    "lpresult = lpmodel.fit(np.array([.5,.5]))\n",
    "print lpresult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
